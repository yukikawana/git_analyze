Using TensorFlow backend.
2017-10-26 12:47:17.687637: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-10-26 12:47:17.687672: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-10-26 12:47:17.687681: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-10-26 12:47:17.687688: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-10-26 12:47:17.687695: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-10-26 12:47:17.791674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-10-26 12:47:17.791950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: GeForce GTX 1080
major: 6 minor: 1 memoryClockRate (GHz) 1.7335
pciBusID 0000:01:00.0
Total memory: 7.92GiB
Free memory: 7.54GiB
2017-10-26 12:47:17.791968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 
2017-10-26 12:47:17.791977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y 
2017-10-26 12:47:17.791986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)
Iteration: 1, named_losses: [('ActivationMax Loss', -0.28099355),
 ('L-6.0 Norm Loss', 0.022572614),
 ('TV(2.0) Loss', 6.4754267)], overall loss: 6.21700572968
Iteration: 2, named_losses: [('ActivationMax Loss', -0.43814069),
 ('L-6.0 Norm Loss', 0.022365242),
 ('TV(2.0) Loss', 3.3796022)], overall loss: 2.96382665634
Iteration: 3, named_losses: [('ActivationMax Loss', -0.66040641),
 ('L-6.0 Norm Loss', 0.022261124),
 ('TV(2.0) Loss', 1.9585716)], overall loss: 1.32042622566
Iteration: 4, named_losses: [('ActivationMax Loss', -0.6031763),
 ('L-6.0 Norm Loss', 0.022209501),
 ('TV(2.0) Loss', 1.3208326)], overall loss: 0.739865839481
Iteration: 5, named_losses: [('ActivationMax Loss', -0.61873692),
 ('L-6.0 Norm Loss', 0.022186497),
 ('TV(2.0) Loss', 1.010107)], overall loss: 0.41355663538
Iteration: 6, named_losses: [('ActivationMax Loss', -0.71522534),
 ('L-6.0 Norm Loss', 0.022170145),
 ('TV(2.0) Loss', 0.82170922)], overall loss: 0.128654003143
Iteration: 7, named_losses: [('ActivationMax Loss', -0.78952122),
 ('L-6.0 Norm Loss', 0.022155726),
 ('TV(2.0) Loss', 0.67238456)], overall loss: -0.0949809551239
Iteration: 8, named_losses: [('ActivationMax Loss', -0.86050224),
 ('L-6.0 Norm Loss', 0.022145368),
 ('TV(2.0) Loss', 0.56363469)], overall loss: -0.274722158909
Iteration: 9, named_losses: [('ActivationMax Loss', -0.9851948),
 ('L-6.0 Norm Loss', 0.022135602),
 ('TV(2.0) Loss', 0.47666416)], overall loss: -0.486395031214
Iteration: 10, named_losses: [('ActivationMax Loss', -1.0006194),
 ('L-6.0 Norm Loss', 0.022127278),
 ('TV(2.0) Loss', 0.40378061)], overall loss: -0.574711561203
Iteration: 11, named_losses: [('ActivationMax Loss', -1.0433365),
 ('L-6.0 Norm Loss', 0.022120763),
 ('TV(2.0) Loss', 0.35263714)], overall loss: -0.668578624725
Iteration: 12, named_losses: [('ActivationMax Loss', -0.96323544),
 ('L-6.0 Norm Loss', 0.022116473),
 ('TV(2.0) Loss', 0.31925452)], overall loss: -0.621864438057
Iteration: 13, named_losses: [('ActivationMax Loss', -1.0093021),
 ('L-6.0 Norm Loss', 0.022113586),
 ('TV(2.0) Loss', 0.2959176)], overall loss: -0.691270947456
Iteration: 14, named_losses: [('ActivationMax Loss', -1.0701481),
 ('L-6.0 Norm Loss', 0.022111315),
 ('TV(2.0) Loss', 0.27852723)], overall loss: -0.769509553909
Iteration: 15, named_losses: [('ActivationMax Loss', -1.0700479),
 ('L-6.0 Norm Loss', 0.022108637),
 ('TV(2.0) Loss', 0.2593073)], overall loss: -0.788631916046
Iteration: 16, named_losses: [('ActivationMax Loss', -1.0554267),
 ('L-6.0 Norm Loss', 0.022107046),
 ('TV(2.0) Loss', 0.25181499)], overall loss: -0.781504750252
Iteration: 17, named_losses: [('ActivationMax Loss', -1.0525166),
 ('L-6.0 Norm Loss', 0.022106534),
 ('TV(2.0) Loss', 0.24331999)], overall loss: -0.787090063095
Iteration: 18, named_losses: [('ActivationMax Loss', -1.0698142),
 ('L-6.0 Norm Loss', 0.022105169),
 ('TV(2.0) Loss', 0.23705932)], overall loss: -0.810649633408
Iteration: 19, named_losses: [('ActivationMax Loss', -1.0860606),
 ('L-6.0 Norm Loss', 0.022104997),
 ('TV(2.0) Loss', 0.23246428)], overall loss: -0.831491351128
Iteration: 20, named_losses: [('ActivationMax Loss', -1.1563125),
 ('L-6.0 Norm Loss', 0.022104328),
 ('TV(2.0) Loss', 0.22853968)], overall loss: -0.905668377876
Iteration: 21, named_losses: [('ActivationMax Loss', -1.0944901),
 ('L-6.0 Norm Loss', 0.022104628),
 ('TV(2.0) Loss', 0.2257935)], overall loss: -0.846591949463
Iteration: 22, named_losses: [('ActivationMax Loss', -1.1686214),
 ('L-6.0 Norm Loss', 0.022104587),
 ('TV(2.0) Loss', 0.22411248)], overall loss: -0.922404289246
Iteration: 23, named_losses: [('ActivationMax Loss', -1.1653717),
 ('L-6.0 Norm Loss', 0.022106161),
 ('TV(2.0) Loss', 0.22412348)], overall loss: -0.919142007828
Iteration: 24, named_losses: [('ActivationMax Loss', -1.2151792),
 ('L-6.0 Norm Loss', 0.022105463),
 ('TV(2.0) Loss', 0.22297141)], overall loss: -0.970102310181
Iteration: 25, named_losses: [('ActivationMax Loss', -1.1564384),
 ('L-6.0 Norm Loss', 0.022106592),
 ('TV(2.0) Loss', 0.22205667)], overall loss: -0.912275016308
Iteration: 26, named_losses: [('ActivationMax Loss', -1.1961247),
 ('L-6.0 Norm Loss', 0.022106908),
 ('TV(2.0) Loss', 0.22285165)], overall loss: -0.951166152954
Iteration: 27, named_losses: [('ActivationMax Loss', -1.2360829),
 ('L-6.0 Norm Loss', 0.022108657),
 ('TV(2.0) Loss', 0.22333916)], overall loss: -0.990635097027
Iteration: 28, named_losses: [('ActivationMax Loss', -1.2706048),
 ('L-6.0 Norm Loss', 0.022109225),
 ('TV(2.0) Loss', 0.22191882)], overall loss: -1.02657675743
Iteration: 29, named_losses: [('ActivationMax Loss', -1.249597),
 ('L-6.0 Norm Loss', 0.022109969),
 ('TV(2.0) Loss', 0.2220102)], overall loss: -1.00547671318
Iteration: 30, named_losses: [('ActivationMax Loss', -1.2152541),
 ('L-6.0 Norm Loss', 0.022111092),
 ('TV(2.0) Loss', 0.22276518)], overall loss: -0.970377802849
Iteration: 31, named_losses: [('ActivationMax Loss', -1.2712041),
 ('L-6.0 Norm Loss', 0.022111505),
 ('TV(2.0) Loss', 0.22403486)], overall loss: -1.02505767345
Iteration: 32, named_losses: [('ActivationMax Loss', -1.2131672),
 ('L-6.0 Norm Loss', 0.022112692),
 ('TV(2.0) Loss', 0.22643425)], overall loss: -0.964620232582
Iteration: 33, named_losses: [('ActivationMax Loss', -1.2484295),
 ('L-6.0 Norm Loss', 0.022113768),
 ('TV(2.0) Loss', 0.22769694)], overall loss: -0.998618781567
Iteration: 34, named_losses: [('ActivationMax Loss', -1.1556447),
 ('L-6.0 Norm Loss', 0.022115178),
 ('TV(2.0) Loss', 0.23002429)], overall loss: -0.903505146503
Iteration: 35, named_losses: [('ActivationMax Loss', -1.3005679),
 ('L-6.0 Norm Loss', 0.022116436),
 ('TV(2.0) Loss', 0.23071037)], overall loss: -1.04774105549
Iteration: 36, named_losses: [('ActivationMax Loss', -1.2297065),
 ('L-6.0 Norm Loss', 0.022117058),
 ('TV(2.0) Loss', 0.23017211)], overall loss: -0.97741740942
Iteration: 37, named_losses: [('ActivationMax Loss', -1.2572191),
 ('L-6.0 Norm Loss', 0.022118026),
 ('TV(2.0) Loss', 0.23128098)], overall loss: -1.00382018089
Iteration: 38, named_losses: [('ActivationMax Loss', -1.3043098),
 ('L-6.0 Norm Loss', 0.022119908),
 ('TV(2.0) Loss', 0.23284896)], overall loss: -1.04934096336
Iteration: 39, named_losses: [('ActivationMax Loss', -1.3153852),
 ('L-6.0 Norm Loss', 0.022121191),
 ('TV(2.0) Loss', 0.23274446)], overall loss: -1.06051957607
Iteration: 40, named_losses: [('ActivationMax Loss', -1.3111131),
 ('L-6.0 Norm Loss', 0.022122178),
 ('TV(2.0) Loss', 0.23308572)], overall loss: -1.05590522289
Iteration: 41, named_losses: [('ActivationMax Loss', -1.3242168),
 ('L-6.0 Norm Loss', 0.022124093),
 ('TV(2.0) Loss', 0.23441814)], overall loss: -1.06767463684
Iteration: 42, named_losses: [('ActivationMax Loss', -1.3401291),
 ('L-6.0 Norm Loss', 0.022125069),
 ('TV(2.0) Loss', 0.23590437)], overall loss: -1.08209967613
Iteration: 43, named_losses: [('ActivationMax Loss', -1.3689015),
 ('L-6.0 Norm Loss', 0.022125144),
 ('TV(2.0) Loss', 0.2363041)], overall loss: -1.1104722023
Iteration: 44, named_losses: [('ActivationMax Loss', -1.3036997),
 ('L-6.0 Norm Loss', 0.022126347),
 ('TV(2.0) Loss', 0.2369507)], overall loss: -1.04462265968
Iteration: 45, named_losses: [('ActivationMax Loss', -1.407162),
 ('L-6.0 Norm Loss', 0.0221278),
 ('TV(2.0) Loss', 0.236981)], overall loss: -1.14805316925
Iteration: 46, named_losses: [('ActivationMax Loss', -1.3851662),
 ('L-6.0 Norm Loss', 0.022127926),
 ('TV(2.0) Loss', 0.23784639)], overall loss: -1.12519192696
Iteration: 47, named_losses: [('ActivationMax Loss', -1.3733045),
 ('L-6.0 Norm Loss', 0.022128765),
 ('TV(2.0) Loss', 0.23839277)], overall loss: -1.11278295517
Iteration: 48, named_losses: [('ActivationMax Loss', -1.3805376),
 ('L-6.0 Norm Loss', 0.022129556),
 ('TV(2.0) Loss', 0.23823713)], overall loss: -1.12017095089
Iteration: 49, named_losses: [('ActivationMax Loss', -1.4085522),
 ('L-6.0 Norm Loss', 0.022130052),
 ('TV(2.0) Loss', 0.23775811)], overall loss: -1.14866399765
Iteration: 50, named_losses: [('ActivationMax Loss', -1.4267009),
 ('L-6.0 Norm Loss', 0.022131294),
 ('TV(2.0) Loss', 0.23809014)], overall loss: -1.16647946835
Iteration: 51, named_losses: [('ActivationMax Loss', -1.4058892),
 ('L-6.0 Norm Loss', 0.02213181),
 ('TV(2.0) Loss', 0.23669188)], overall loss: -1.14706552029
Iteration: 52, named_losses: [('ActivationMax Loss', -1.3542153),
 ('L-6.0 Norm Loss', 0.02213278),
 ('TV(2.0) Loss', 0.23738043)], overall loss: -1.0947021246
Iteration: 53, named_losses: [('ActivationMax Loss', -1.3838235),
 ('L-6.0 Norm Loss', 0.022133712),
 ('TV(2.0) Loss', 0.2362278)], overall loss: -1.12546205521
Iteration: 54, named_losses: [('ActivationMax Loss', -1.3801448),
 ('L-6.0 Norm Loss', 0.022134304),
 ('TV(2.0) Loss', 0.23749927)], overall loss: -1.12051129341
Iteration: 55, named_losses: [('ActivationMax Loss', -1.4432871),
 ('L-6.0 Norm Loss', 0.022135207),
 ('TV(2.0) Loss', 0.23716657)], overall loss: -1.18398535252
Iteration: 56, named_losses: [('ActivationMax Loss', -1.4091352),
 ('L-6.0 Norm Loss', 0.02213503),
 ('TV(2.0) Loss', 0.2369846)], overall loss: -1.15001559258
Iteration: 57, named_losses: [('ActivationMax Loss', -1.3661612),
 ('L-6.0 Norm Loss', 0.022137199),
 ('TV(2.0) Loss', 0.23836371)], overall loss: -1.10566031933
Iteration: 58, named_losses: [('ActivationMax Loss', -1.4520099),
 ('L-6.0 Norm Loss', 0.022137256),
 ('TV(2.0) Loss', 0.23910314)], overall loss: -1.19076943398
Iteration: 59, named_losses: [('ActivationMax Loss', -1.4488682),
 ('L-6.0 Norm Loss', 0.022137521),
 ('TV(2.0) Loss', 0.23878576)], overall loss: -1.18794488907
Iteration: 60, named_losses: [('ActivationMax Loss', -1.4386718),
 ('L-6.0 Norm Loss', 0.022138515),
 ('TV(2.0) Loss', 0.23816457)], overall loss: -1.17836880684
Iteration: 61, named_losses: [('ActivationMax Loss', -1.4345845),
 ('L-6.0 Norm Loss', 0.022138225),
 ('TV(2.0) Loss', 0.2386705)], overall loss: -1.17377579212
Iteration: 62, named_losses: [('ActivationMax Loss', -1.471029),
 ('L-6.0 Norm Loss', 0.022139039),
 ('TV(2.0) Loss', 0.23796977)], overall loss: -1.21092021465
Iteration: 63, named_losses: [('ActivationMax Loss', -1.4118555),
 ('L-6.0 Norm Loss', 0.02213913),
 ('TV(2.0) Loss', 0.23734632)], overall loss: -1.15237009525
Iteration: 64, named_losses: [('ActivationMax Loss', -1.4587481),
 ('L-6.0 Norm Loss', 0.022139892),
 ('TV(2.0) Loss', 0.23788394)], overall loss: -1.19872426987
Iteration: 65, named_losses: [('ActivationMax Loss', -1.4195936),
 ('L-6.0 Norm Loss', 0.022140969),
 ('TV(2.0) Loss', 0.237978)], overall loss: -1.15947461128
Iteration: 66, named_losses: [('ActivationMax Loss', -1.4744179),
 ('L-6.0 Norm Loss', 0.022140795),
 ('TV(2.0) Loss', 0.23618497)], overall loss: -1.21609222889
Iteration: 67, named_losses: [('ActivationMax Loss', -1.5115056),
 ('L-6.0 Norm Loss', 0.022141445),
 ('TV(2.0) Loss', 0.23646154)], overall loss: -1.25290262699
Iteration: 68, named_losses: [('ActivationMax Loss', -1.427616),
 ('L-6.0 Norm Loss', 0.022140466),
 ('TV(2.0) Loss', 0.23450126)], overall loss: -1.17097425461
Iteration: 69, named_losses: [('ActivationMax Loss', -1.4756498),
 ('L-6.0 Norm Loss', 0.022141032),
 ('TV(2.0) Loss', 0.23464152)], overall loss: -1.21886730194
Iteration: 70, named_losses: [('ActivationMax Loss', -1.4702538),
 ('L-6.0 Norm Loss', 0.022141997),
 ('TV(2.0) Loss', 0.23366717)], overall loss: -1.2144446373
Iteration: 71, named_losses: [('ActivationMax Loss', -1.5039883),
 ('L-6.0 Norm Loss', 0.022143181),
 ('TV(2.0) Loss', 0.23302862)], overall loss: -1.24881649017
Iteration: 72, named_losses: [('ActivationMax Loss', -1.4796083),
 ('L-6.0 Norm Loss', 0.022142569),
 ('TV(2.0) Loss', 0.23370974)], overall loss: -1.22375607491
Iteration: 73, named_losses: [('ActivationMax Loss', -1.4472253),
 ('L-6.0 Norm Loss', 0.022144035),
 ('TV(2.0) Loss', 0.23285951)], overall loss: -1.19222176075
Iteration: 74, named_losses: [('ActivationMax Loss', -1.5065478),
 ('L-6.0 Norm Loss', 0.022143906),
 ('TV(2.0) Loss', 0.23355603)], overall loss: -1.25084781647
Iteration: 75, named_losses: [('ActivationMax Loss', -1.4744983),
 ('L-6.0 Norm Loss', 0.022144359),
 ('TV(2.0) Loss', 0.23331779)], overall loss: -1.21903610229
Iteration: 76, named_losses: [('ActivationMax Loss', -1.4947512),
 ('L-6.0 Norm Loss', 0.022144301),
 ('TV(2.0) Loss', 0.23297909)], overall loss: -1.23962783813
Iteration: 77, named_losses: [('ActivationMax Loss', -1.46797),
 ('L-6.0 Norm Loss', 0.022145569),
 ('TV(2.0) Loss', 0.23146765)], overall loss: -1.21435678005
Iteration: 78, named_losses: [('ActivationMax Loss', -1.515716),
 ('L-6.0 Norm Loss', 0.022144577),
 ('TV(2.0) Loss', 0.23148073)], overall loss: -1.26209068298
Iteration: 79, named_losses: [('ActivationMax Loss', -1.5092869),
 ('L-6.0 Norm Loss', 0.022145692),
 ('TV(2.0) Loss', 0.22928649)], overall loss: -1.25785470009
Iteration: 80, named_losses: [('ActivationMax Loss', -1.4814688),
 ('L-6.0 Norm Loss', 0.022145061),
 ('TV(2.0) Loss', 0.22848068)], overall loss: -1.23084306717
Iteration: 81, named_losses: [('ActivationMax Loss', -1.4313325),
 ('L-6.0 Norm Loss', 0.022145581),
 ('TV(2.0) Loss', 0.22756161)], overall loss: -1.181625247
Iteration: 82, named_losses: [('ActivationMax Loss', -1.4796293),
 ('L-6.0 Norm Loss', 0.022146804),
 ('TV(2.0) Loss', 0.22788057)], overall loss: -1.22960186005
Iteration: 83, named_losses: [('ActivationMax Loss', -1.5281303),
 ('L-6.0 Norm Loss', 0.022146767),
 ('TV(2.0) Loss', 0.22748628)], overall loss: -1.27849721909
Iteration: 84, named_losses: [('ActivationMax Loss', -1.5299858),
 ('L-6.0 Norm Loss', 0.022147048),
 ('TV(2.0) Loss', 0.22770277)], overall loss: -1.28013598919
Iteration: 85, named_losses: [('ActivationMax Loss', -1.4012589),
 ('L-6.0 Norm Loss', 0.022147093),
 ('TV(2.0) Loss', 0.2272716)], overall loss: -1.15184032917
Iteration: 86, named_losses: [('ActivationMax Loss', -1.4830279),
 ('L-6.0 Norm Loss', 0.022147762),
 ('TV(2.0) Loss', 0.22719271)], overall loss: -1.23368740082
Iteration: 87, named_losses: [('ActivationMax Loss', -1.4722788),
 ('L-6.0 Norm Loss', 0.022148674),
 ('TV(2.0) Loss', 0.22621265)], overall loss: -1.22391748428
Iteration: 88, named_losses: [('ActivationMax Loss', -1.4599897),
 ('L-6.0 Norm Loss', 0.022148194),
 ('TV(2.0) Loss', 0.22588567)], overall loss: -1.21195578575
Iteration: 89, named_losses: [('ActivationMax Loss', -1.5140127),
 ('L-6.0 Norm Loss', 0.022149324),
 ('TV(2.0) Loss', 0.22458977)], overall loss: -1.26727366447
Iteration: 90, named_losses: [('ActivationMax Loss', -1.523654),
 ('L-6.0 Norm Loss', 0.022149667),
 ('TV(2.0) Loss', 0.2261247)], overall loss: -1.27537965775
Iteration: 91, named_losses: [('ActivationMax Loss', -1.5607172),
 ('L-6.0 Norm Loss', 0.02215052),
 ('TV(2.0) Loss', 0.22622812)], overall loss: -1.31233859062
Iteration: 92, named_losses: [('ActivationMax Loss', -1.5161979),
 ('L-6.0 Norm Loss', 0.022150412),
 ('TV(2.0) Loss', 0.22443594)], overall loss: -1.26961159706
Iteration: 93, named_losses: [('ActivationMax Loss', -1.4911356),
 ('L-6.0 Norm Loss', 0.022150498),
 ('TV(2.0) Loss', 0.22310394)], overall loss: -1.24588108063
Iteration: 94, named_losses: [('ActivationMax Loss', -1.448825),
 ('L-6.0 Norm Loss', 0.022150604),
 ('TV(2.0) Loss', 0.22373469)], overall loss: -1.20293962955
Iteration: 95, named_losses: [('ActivationMax Loss', -1.5170629),
 ('L-6.0 Norm Loss', 0.0221509),
 ('TV(2.0) Loss', 0.22361414)], overall loss: -1.27129793167
Iteration: 96, named_losses: [('ActivationMax Loss', -1.5081811),
 ('L-6.0 Norm Loss', 0.022151599),
 ('TV(2.0) Loss', 0.22352168)], overall loss: -1.26250779629
Iteration: 97, named_losses: [('ActivationMax Loss', -1.4440638),
 ('L-6.0 Norm Loss', 0.022151493),
 ('TV(2.0) Loss', 0.22426233)], overall loss: -1.19764995575
Iteration: 98, named_losses: [('ActivationMax Loss', -1.421067),
 ('L-6.0 Norm Loss', 0.022152765),
 ('TV(2.0) Loss', 0.22532751)], overall loss: -1.17358672619
Iteration: 99, named_losses: [('ActivationMax Loss', -1.4933249),
 ('L-6.0 Norm Loss', 0.0221541),
 ('TV(2.0) Loss', 0.22726019)], overall loss: -1.24391055107
Iteration: 100, named_losses: [('ActivationMax Loss', -1.504306),
 ('L-6.0 Norm Loss', 0.022153631),
 ('TV(2.0) Loss', 0.22633952)], overall loss: -1.25581288338
Iteration: 101, named_losses: [('ActivationMax Loss', -1.5086272),
 ('L-6.0 Norm Loss', 0.022154137),
 ('TV(2.0) Loss', 0.2259696)], overall loss: -1.2605035305
Iteration: 102, named_losses: [('ActivationMax Loss', -1.4863083),
 ('L-6.0 Norm Loss', 0.022153908),
 ('TV(2.0) Loss', 0.22552122)], overall loss: -1.23863327503
Iteration: 103, named_losses: [('ActivationMax Loss', -1.4779189),
 ('L-6.0 Norm Loss', 0.022155359),
 ('TV(2.0) Loss', 0.22721536)], overall loss: -1.22854804993
Iteration: 104, named_losses: [('ActivationMax Loss', -1.50725),
 ('L-6.0 Norm Loss', 0.022155812),
 ('TV(2.0) Loss', 0.22832836)], overall loss: -1.25676584244
Iteration: 105, named_losses: [('ActivationMax Loss', -1.4495353),
 ('L-6.0 Norm Loss', 0.022155922),
 ('TV(2.0) Loss', 0.22695228)], overall loss: -1.20042705536
Iteration: 106, named_losses: [('ActivationMax Loss', -1.4635134),
 ('L-6.0 Norm Loss', 0.022156797),
 ('TV(2.0) Loss', 0.22650863)], overall loss: -1.21484792233
Iteration: 107, named_losses: [('ActivationMax Loss', -1.5295377),
 ('L-6.0 Norm Loss', 0.022157386),
 ('TV(2.0) Loss', 0.22656161)], overall loss: -1.28081870079
Iteration: 108, named_losses: [('ActivationMax Loss', -1.4938515),
 ('L-6.0 Norm Loss', 0.022157656),
 ('TV(2.0) Loss', 0.22437136)], overall loss: -1.24732255936
Iteration: 109, named_losses: [('ActivationMax Loss', -1.5165313),
 ('L-6.0 Norm Loss', 0.022156108),
 ('TV(2.0) Loss', 0.22392261)], overall loss: -1.2704526186
Iteration: 110, named_losses: [('ActivationMax Loss', -1.5192587),
 ('L-6.0 Norm Loss', 0.022158153),
 ('TV(2.0) Loss', 0.22440065)], overall loss: -1.27269995213
Iteration: 111, named_losses: [('ActivationMax Loss', -1.5456785),
 ('L-6.0 Norm Loss', 0.022158064),
 ('TV(2.0) Loss', 0.22415577)], overall loss: -1.29936468601
Iteration: 112, named_losses: [('ActivationMax Loss', -1.456841),
 ('L-6.0 Norm Loss', 0.022157732),
 ('TV(2.0) Loss', 0.22452229)], overall loss: -1.21016097069
Iteration: 113, named_losses: [('ActivationMax Loss', -1.5551454),
 ('L-6.0 Norm Loss', 0.022157311),
 ('TV(2.0) Loss', 0.22417423)], overall loss: -1.30881381035
Iteration: 114, named_losses: [('ActivationMax Loss', -1.539905),
 ('L-6.0 Norm Loss', 0.022157712),
 ('TV(2.0) Loss', 0.22161579)], overall loss: -1.29613149166
Iteration: 115, named_losses: [('ActivationMax Loss', -1.5232663),
 ('L-6.0 Norm Loss', 0.022157934),
 ('TV(2.0) Loss', 0.22045654)], overall loss: -1.28065180779
Iteration: 116, named_losses: [('ActivationMax Loss', -1.5495064),
 ('L-6.0 Norm Loss', 0.022157675),
 ('TV(2.0) Loss', 0.22059046)], overall loss: -1.30675828457
Iteration: 117, named_losses: [('ActivationMax Loss', -1.5322757),
 ('L-6.0 Norm Loss', 0.022158174),
 ('TV(2.0) Loss', 0.21891344)], overall loss: -1.29120409489
Iteration: 118, named_losses: [('ActivationMax Loss', -1.4960525),
 ('L-6.0 Norm Loss', 0.02215893),
 ('TV(2.0) Loss', 0.21892427)], overall loss: -1.25496923923
Iteration: 119, named_losses: [('ActivationMax Loss', -1.4799625),
 ('L-6.0 Norm Loss', 0.022158157),
 ('TV(2.0) Loss', 0.21911336)], overall loss: -1.23869097233
Iteration: 120, named_losses: [('ActivationMax Loss', -1.5408787),
 ('L-6.0 Norm Loss', 0.022159044),
 ('TV(2.0) Loss', 0.21956277)], overall loss: -1.29915678501
Iteration: 121, named_losses: [('ActivationMax Loss', -1.4250247),
 ('L-6.0 Norm Loss', 0.022159439),
 ('TV(2.0) Loss', 0.21841556)], overall loss: -1.1844496727
Iteration: 122, named_losses: [('ActivationMax Loss', -1.4529588),
 ('L-6.0 Norm Loss', 0.022159686),
 ('TV(2.0) Loss', 0.21909057)], overall loss: -1.21170854568
Iteration: 123, named_losses: [('ActivationMax Loss', -1.5051594),
 ('L-6.0 Norm Loss', 0.022160904),
 ('TV(2.0) Loss', 0.21932785)], overall loss: -1.26367068291
Iteration: 124, named_losses: [('ActivationMax Loss', -1.43331),
 ('L-6.0 Norm Loss', 0.022160942),
 ('TV(2.0) Loss', 0.22034368)], overall loss: -1.19080543518
Iteration: 125, named_losses: [('ActivationMax Loss', -1.5297353),
 ('L-6.0 Norm Loss', 0.022161258),
 ('TV(2.0) Loss', 0.22028735)], overall loss: -1.28728675842
Iteration: 126, named_losses: [('ActivationMax Loss', -1.4855424),
 ('L-6.0 Norm Loss', 0.022160921),
 ('TV(2.0) Loss', 0.21890585)], overall loss: -1.24447572231
Iteration: 127, named_losses: [('ActivationMax Loss', -1.4360042),
 ('L-6.0 Norm Loss', 0.022161271),
 ('TV(2.0) Loss', 0.22001556)], overall loss: -1.19382739067
Iteration: 128, named_losses: [('ActivationMax Loss', -1.4998578),
 ('L-6.0 Norm Loss', 0.02216181),
 ('TV(2.0) Loss', 0.21993732)], overall loss: -1.2577586174
Iteration: 129, named_losses: [('ActivationMax Loss', -1.5442064),
 ('L-6.0 Norm Loss', 0.022162676),
 ('TV(2.0) Loss', 0.22082643)], overall loss: -1.30121731758
Iteration: 130, named_losses: [('ActivationMax Loss', -1.5027121),
 ('L-6.0 Norm Loss', 0.022162713),
 ('TV(2.0) Loss', 0.2195797)], overall loss: -1.26096975803
Iteration: 131, named_losses: [('ActivationMax Loss', -1.5015087),
 ('L-6.0 Norm Loss', 0.0221634),
 ('TV(2.0) Loss', 0.22036889)], overall loss: -1.2589764595
Iteration: 132, named_losses: [('ActivationMax Loss', -1.484951),
 ('L-6.0 Norm Loss', 0.022162525),
 ('TV(2.0) Loss', 0.21945667)], overall loss: -1.24333178997
Iteration: 133, named_losses: [('ActivationMax Loss', -1.5092016),
 ('L-6.0 Norm Loss', 0.022163354),
 ('TV(2.0) Loss', 0.22052868)], overall loss: -1.26650953293
Iteration: 134, named_losses: [('ActivationMax Loss', -1.4594965),
 ('L-6.0 Norm Loss', 0.022163603),
 ('TV(2.0) Loss', 0.22102053)], overall loss: -1.21631228924
Iteration: 135, named_losses: [('ActivationMax Loss', -1.5266664),
 ('L-6.0 Norm Loss', 0.022164643),
 ('TV(2.0) Loss', 0.22193196)], overall loss: -1.28256988525
Iteration: 136, named_losses: [('ActivationMax Loss', -1.5722939),
 ('L-6.0 Norm Loss', 0.022164278),
 ('TV(2.0) Loss', 0.22224143)], overall loss: -1.32788825035
Iteration: 137, named_losses: [('ActivationMax Loss', -1.5419552),
 ('L-6.0 Norm Loss', 0.022165183),
 ('TV(2.0) Loss', 0.22156249)], overall loss: -1.2982275486
Iteration: 138, named_losses: [('ActivationMax Loss', -1.5085697),
 ('L-6.0 Norm Loss', 0.02216465),
 ('TV(2.0) Loss', 0.22039734)], overall loss: -1.26600766182
Iteration: 139, named_losses: [('ActivationMax Loss', -1.531812),
 ('L-6.0 Norm Loss', 0.022164861),
 ('TV(2.0) Loss', 0.21933773)], overall loss: -1.29030942917
Iteration: 140, named_losses: [('ActivationMax Loss', -1.5186168),
 ('L-6.0 Norm Loss', 0.022165887),
 ('TV(2.0) Loss', 0.22018394)], overall loss: -1.27626693249
Iteration: 141, named_losses: [('ActivationMax Loss', -1.520149),
 ('L-6.0 Norm Loss', 0.022166224),
 ('TV(2.0) Loss', 0.22084087)], overall loss: -1.27714180946
Iteration: 142, named_losses: [('ActivationMax Loss', -1.5239351),
 ('L-6.0 Norm Loss', 0.022166334),
 ('TV(2.0) Loss', 0.22104408)], overall loss: -1.28072464466
Iteration: 143, named_losses: [('ActivationMax Loss', -1.5323343),
 ('L-6.0 Norm Loss', 0.022166373),
 ('TV(2.0) Loss', 0.221765)], overall loss: -1.288402915
Iteration: 144, named_losses: [('ActivationMax Loss', -1.4961839),
 ('L-6.0 Norm Loss', 0.022166019),
 ('TV(2.0) Loss', 0.22124375)], overall loss: -1.25277411938
Iteration: 145, named_losses: [('ActivationMax Loss', -1.5178361),
 ('L-6.0 Norm Loss', 0.022167003),
 ('TV(2.0) Loss', 0.22014377)], overall loss: -1.2755253315
Iteration: 146, named_losses: [('ActivationMax Loss', -1.5136992),
 ('L-6.0 Norm Loss', 0.022167658),
 ('TV(2.0) Loss', 0.22163269)], overall loss: -1.26989877224
Iteration: 147, named_losses: [('ActivationMax Loss', -1.4941493),
 ('L-6.0 Norm Loss', 0.022167927),
 ('TV(2.0) Loss', 0.22137067)], overall loss: -1.25061070919
Iteration: 148, named_losses: [('ActivationMax Loss', -1.5426782),
 ('L-6.0 Norm Loss', 0.022168051),
 ('TV(2.0) Loss', 0.2217799)], overall loss: -1.29873025417
Iteration: 149, named_losses: [('ActivationMax Loss', -1.4918442),
 ('L-6.0 Norm Loss', 0.022168089),
 ('TV(2.0) Loss', 0.22144675)], overall loss: -1.24822938442
Iteration: 150, named_losses: [('ActivationMax Loss', -1.5124218),
 ('L-6.0 Norm Loss', 0.022168336),
 ('TV(2.0) Loss', 0.22068985)], overall loss: -1.26956367493
Iteration: 151, named_losses: [('ActivationMax Loss', -1.5546917),
 ('L-6.0 Norm Loss', 0.022168698),
 ('TV(2.0) Loss', 0.22156538)], overall loss: -1.310957551
Iteration: 152, named_losses: [('ActivationMax Loss', -1.5168535),
 ('L-6.0 Norm Loss', 0.022167709),
 ('TV(2.0) Loss', 0.2196375)], overall loss: -1.27504825592
Iteration: 153, named_losses: [('ActivationMax Loss', -1.5138478),
 ('L-6.0 Norm Loss', 0.022168795),
 ('TV(2.0) Loss', 0.21955694)], overall loss: -1.2721221447
Iteration: 154, named_losses: [('ActivationMax Loss', -1.5603399),
 ('L-6.0 Norm Loss', 0.022167981),
 ('TV(2.0) Loss', 0.21816342)], overall loss: -1.32000863552
Iteration: 155, named_losses: [('ActivationMax Loss', -1.5223805),
 ('L-6.0 Norm Loss', 0.022168363),
 ('TV(2.0) Loss', 0.21753006)], overall loss: -1.2826820612
Iteration: 156, named_losses: [('ActivationMax Loss', -1.5390704),
 ('L-6.0 Norm Loss', 0.022168867),
 ('TV(2.0) Loss', 0.21788222)], overall loss: -1.2990193367
Iteration: 157, named_losses: [('ActivationMax Loss', -1.536491),
 ('L-6.0 Norm Loss', 0.022169467),
 ('TV(2.0) Loss', 0.21874966)], overall loss: -1.29557192326
Iteration: 158, named_losses: [('ActivationMax Loss', -1.5516292),
 ('L-6.0 Norm Loss', 0.022169074),
 ('TV(2.0) Loss', 0.21835102)], overall loss: -1.31110906601
Iteration: 159, named_losses: [('ActivationMax Loss', -1.5063674),
 ('L-6.0 Norm Loss', 0.022168625),
 ('TV(2.0) Loss', 0.21759687)], overall loss: -1.26660192013
Iteration: 160, named_losses: [('ActivationMax Loss', -1.547261),
 ('L-6.0 Norm Loss', 0.022169586),
 ('TV(2.0) Loss', 0.21888462)], overall loss: -1.3062068224
Iteration: 161, named_losses: [('ActivationMax Loss', -1.5511349),
 ('L-6.0 Norm Loss', 0.022169273),
 ('TV(2.0) Loss', 0.21857618)], overall loss: -1.31038951874
Iteration: 162, named_losses: [('ActivationMax Loss', -1.5170381),
 ('L-6.0 Norm Loss', 0.022169225),
 ('TV(2.0) Loss', 0.21798313)], overall loss: -1.27688574791
Iteration: 163, named_losses: [('ActivationMax Loss', -1.519871),
 ('L-6.0 Norm Loss', 0.022169871),
 ('TV(2.0) Loss', 0.21629821)], overall loss: -1.28140294552
Iteration: 164, named_losses: [('ActivationMax Loss', -1.4954929),
 ('L-6.0 Norm Loss', 0.022169787),
 ('TV(2.0) Loss', 0.2175685)], overall loss: -1.25575459003
Iteration: 165, named_losses: [('ActivationMax Loss', -1.5373216),
 ('L-6.0 Norm Loss', 0.022170329),
 ('TV(2.0) Loss', 0.21723853)], overall loss: -1.29791271687
Iteration: 166, named_losses: [('ActivationMax Loss', -1.4850308),
 ('L-6.0 Norm Loss', 0.022170367),
 ('TV(2.0) Loss', 0.21665289)], overall loss: -1.24620747566
Iteration: 167, named_losses: [('ActivationMax Loss', -1.4728861),
 ('L-6.0 Norm Loss', 0.022170844),
 ('TV(2.0) Loss', 0.2159557)], overall loss: -1.23475944996
Iteration: 168, named_losses: [('ActivationMax Loss', -1.4370034),
 ('L-6.0 Norm Loss', 0.022170916),
 ('TV(2.0) Loss', 0.21571249)], overall loss: -1.19912004471
Iteration: 169, named_losses: [('ActivationMax Loss', -1.4991097),
 ('L-6.0 Norm Loss', 0.022171224),
 ('TV(2.0) Loss', 0.21727055)], overall loss: -1.25966787338
Iteration: 170, named_losses: [('ActivationMax Loss', -1.5141814),
 ('L-6.0 Norm Loss', 0.022172492),
 ('TV(2.0) Loss', 0.21815848)], overall loss: -1.27385044098
Iteration: 171, named_losses: [('ActivationMax Loss', -1.5473857),
 ('L-6.0 Norm Loss', 0.022171445),
 ('TV(2.0) Loss', 0.21835519)], overall loss: -1.30685901642
Iteration: 172, named_losses: [('ActivationMax Loss', -1.5276814),
 ('L-6.0 Norm Loss', 0.022172168),
 ('TV(2.0) Loss', 0.21820951)], overall loss: -1.28729963303
Iteration: 173, named_losses: [('ActivationMax Loss', -1.5583179),
 ('L-6.0 Norm Loss', 0.022172231),
 ('TV(2.0) Loss', 0.21823046)], overall loss: -1.31791520119
Iteration: 174, named_losses: [('ActivationMax Loss', -1.4945325),
 ('L-6.0 Norm Loss', 0.022172946),
 ('TV(2.0) Loss', 0.21639112)], overall loss: -1.2559684515
Iteration: 175, named_losses: [('ActivationMax Loss', -1.5559325),
 ('L-6.0 Norm Loss', 0.022172602),
 ('TV(2.0) Loss', 0.21629293)], overall loss: -1.31746697426
Iteration: 176, named_losses: [('ActivationMax Loss', -1.5482086),
 ('L-6.0 Norm Loss', 0.022172539),
 ('TV(2.0) Loss', 0.21507347)], overall loss: -1.31096255779
Iteration: 177, named_losses: [('ActivationMax Loss', -1.5405877),
 ('L-6.0 Norm Loss', 0.022172403),
 ('TV(2.0) Loss', 0.21474552)], overall loss: -1.30366969109
Iteration: 178, named_losses: [('ActivationMax Loss', -1.4470586),
 ('L-6.0 Norm Loss', 0.022172498),
 ('TV(2.0) Loss', 0.21533628)], overall loss: -1.20954978466
Iteration: 179, named_losses: [('ActivationMax Loss', -1.4180048),
 ('L-6.0 Norm Loss', 0.022173416),
 ('TV(2.0) Loss', 0.21650314)], overall loss: -1.1793282032
Iteration: 180, named_losses: [('ActivationMax Loss', -1.4541301),
 ('L-6.0 Norm Loss', 0.022172974),
 ('TV(2.0) Loss', 0.21720549)], overall loss: -1.21475160122
Iteration: 181, named_losses: [('ActivationMax Loss', -1.4974554),
 ('L-6.0 Norm Loss', 0.022173639),
 ('TV(2.0) Loss', 0.21911813)], overall loss: -1.25616359711
Iteration: 182, named_losses: [('ActivationMax Loss', -1.4964573),
 ('L-6.0 Norm Loss', 0.022174157),
 ('TV(2.0) Loss', 0.21965703)], overall loss: -1.2546261549
Iteration: 183, named_losses: [('ActivationMax Loss', -1.5050462),
 ('L-6.0 Norm Loss', 0.022174496),
 ('TV(2.0) Loss', 0.22001402)], overall loss: -1.26285779476
Iteration: 184, named_losses: [('ActivationMax Loss', -1.4986897),
 ('L-6.0 Norm Loss', 0.022174569),
 ('TV(2.0) Loss', 0.21917953)], overall loss: -1.25733554363
Iteration: 185, named_losses: [('ActivationMax Loss', -1.5260512),
 ('L-6.0 Norm Loss', 0.022175401),
 ('TV(2.0) Loss', 0.22088718)], overall loss: -1.28298854828
Iteration: 186, named_losses: [('ActivationMax Loss', -1.5518167),
 ('L-6.0 Norm Loss', 0.022175156),
 ('TV(2.0) Loss', 0.21956331)], overall loss: -1.31007814407
Iteration: 187, named_losses: [('ActivationMax Loss', -1.4761815),
 ('L-6.0 Norm Loss', 0.022175662),
 ('TV(2.0) Loss', 0.21956035)], overall loss: -1.23444545269
Iteration: 188, named_losses: [('ActivationMax Loss', -1.5199299),
 ('L-6.0 Norm Loss', 0.022176394),
 ('TV(2.0) Loss', 0.21990362)], overall loss: -1.27784991264
Iteration: 189, named_losses: [('ActivationMax Loss', -1.5561179),
 ('L-6.0 Norm Loss', 0.022175536),
 ('TV(2.0) Loss', 0.21974792)], overall loss: -1.31419444084
Iteration: 190, named_losses: [('ActivationMax Loss', -1.4879091),
 ('L-6.0 Norm Loss', 0.022176083),
 ('TV(2.0) Loss', 0.21909986)], overall loss: -1.24663317204
Iteration: 191, named_losses: [('ActivationMax Loss', -1.5440979),
 ('L-6.0 Norm Loss', 0.022175439),
 ('TV(2.0) Loss', 0.21718229)], overall loss: -1.30474019051
Iteration: 192, named_losses: [('ActivationMax Loss', -1.5630429),
 ('L-6.0 Norm Loss', 0.022175552),
 ('TV(2.0) Loss', 0.21748638)], overall loss: -1.32338094711
Iteration: 193, named_losses: [('ActivationMax Loss', -1.5051862),
 ('L-6.0 Norm Loss', 0.022174297),
 ('TV(2.0) Loss', 0.21676159)], overall loss: -1.26625037193
Iteration: 194, named_losses: [('ActivationMax Loss', -1.5606148),
 ('L-6.0 Norm Loss', 0.022174917),
 ('TV(2.0) Loss', 0.21590972)], overall loss: -1.32253015041
Iteration: 195, named_losses: [('ActivationMax Loss', -1.5684232),
 ('L-6.0 Norm Loss', 0.022175649),
 ('TV(2.0) Loss', 0.21605331)], overall loss: -1.33019423485
Iteration: 196, named_losses: [('ActivationMax Loss', -1.5988505),
 ('L-6.0 Norm Loss', 0.022175128),
 ('TV(2.0) Loss', 0.21558061)], overall loss: -1.36109483242
Iteration: 197, named_losses: [('ActivationMax Loss', -1.5318546),
 ('L-6.0 Norm Loss', 0.022174478),
 ('TV(2.0) Loss', 0.21332429)], overall loss: -1.29635584354
Iteration: 198, named_losses: [('ActivationMax Loss', -1.4991595),
 ('L-6.0 Norm Loss', 0.022174936),
 ('TV(2.0) Loss', 0.21322715)], overall loss: -1.26375734806
Iteration: 199, named_losses: [('ActivationMax Loss', -1.5393653),
 ('L-6.0 Norm Loss', 0.022174761),
 ('TV(2.0) Loss', 0.21415989)], overall loss: -1.30303072929
Iteration: 200, named_losses: [('ActivationMax Loss', -1.5465744),
 ('L-6.0 Norm Loss', 0.022175558),
 ('TV(2.0) Loss', 0.21494243)], overall loss: -1.30945634842
Iteration: 201, named_losses: [('ActivationMax Loss', -1.5055245),
 ('L-6.0 Norm Loss', 0.022174627),
 ('TV(2.0) Loss', 0.21405911)], overall loss: -1.26929080486
Iteration: 202, named_losses: [('ActivationMax Loss', -1.4533616),
 ('L-6.0 Norm Loss', 0.022175606),
 ('TV(2.0) Loss', 0.21434924)], overall loss: -1.21683681011
Iteration: 203, named_losses: [('ActivationMax Loss', -1.480226),
 ('L-6.0 Norm Loss', 0.022175469),
 ('TV(2.0) Loss', 0.2146281)], overall loss: -1.24342250824
Iteration: 204, named_losses: [('ActivationMax Loss', -1.4615524),
 ('L-6.0 Norm Loss', 0.022175521),
 ('TV(2.0) Loss', 0.21620342)], overall loss: -1.2231733799
Iteration: 205, named_losses: [('ActivationMax Loss', -1.5342455),
 ('L-6.0 Norm Loss', 0.022176318),
 ('TV(2.0) Loss', 0.21522523)], overall loss: -1.29684400558
Iteration: 206, named_losses: [('ActivationMax Loss', -1.5230286),
 ('L-6.0 Norm Loss', 0.02217575),
 ('TV(2.0) Loss', 0.2163403)], overall loss: -1.28451251984
Iteration: 207, named_losses: [('ActivationMax Loss', -1.5486253),
 ('L-6.0 Norm Loss', 0.022176646),
 ('TV(2.0) Loss', 0.21589732)], overall loss: -1.31055140495
Iteration: 208, named_losses: [('ActivationMax Loss', -1.5618039),
 ('L-6.0 Norm Loss', 0.022175992),
 ('TV(2.0) Loss', 0.21528538)], overall loss: -1.32434248924
Iteration: 209, named_losses: [('ActivationMax Loss', -1.5619648),
 ('L-6.0 Norm Loss', 0.022176085),
 ('TV(2.0) Loss', 0.21568055)], overall loss: -1.32410812378
Iteration: 210, named_losses: [('ActivationMax Loss', -1.5364112),
 ('L-6.0 Norm Loss', 0.022176133),
 ('TV(2.0) Loss', 0.21407467)], overall loss: -1.30016040802
Iteration: 211, named_losses: [('ActivationMax Loss', -1.5584395),
 ('L-6.0 Norm Loss', 0.022176437),
 ('TV(2.0) Loss', 0.21419552)], overall loss: -1.32206761837
Iteration: 212, named_losses: [('ActivationMax Loss', -1.55932),
 ('L-6.0 Norm Loss', 0.022176262),
 ('TV(2.0) Loss', 0.21352884)], overall loss: -1.32361483574
Iteration: 213, named_losses: [('ActivationMax Loss', -1.5636867),
 ('L-6.0 Norm Loss', 0.022177042),
 ('TV(2.0) Loss', 0.21465576)], overall loss: -1.32685387135
Iteration: 214, named_losses: [('ActivationMax Loss', -1.5292449),
 ('L-6.0 Norm Loss', 0.022176534),
 ('TV(2.0) Loss', 0.21409504)], overall loss: -1.29297339916
Iteration: 215, named_losses: [('ActivationMax Loss', -1.5710768),
 ('L-6.0 Norm Loss', 0.022176916),
 ('TV(2.0) Loss', 0.21362899)], overall loss: -1.33527088165
Iteration: 216, named_losses: [('ActivationMax Loss', -1.5485953),
 ('L-6.0 Norm Loss', 0.022176869),
 ('TV(2.0) Loss', 0.21326263)], overall loss: -1.3131557703
Iteration: 217, named_losses: [('ActivationMax Loss', -1.5441997),
 ('L-6.0 Norm Loss', 0.022176262),
 ('TV(2.0) Loss', 0.21476585)], overall loss: -1.30725765228
Iteration: 218, named_losses: [('ActivationMax Loss', -1.5643957),
 ('L-6.0 Norm Loss', 0.022177035),
 ('TV(2.0) Loss', 0.21440889)], overall loss: -1.32780981064
Iteration: 219, named_losses: [('ActivationMax Loss', -1.5505959),
 ('L-6.0 Norm Loss', 0.022176832),
 ('TV(2.0) Loss', 0.21517338)], overall loss: -1.31324565411
Iteration: 220, named_losses: [('ActivationMax Loss', -1.5531409),
 ('L-6.0 Norm Loss', 0.022177137),
 ('TV(2.0) Loss', 0.21439952)], overall loss: -1.31656432152
Iteration: 221, named_losses: [('ActivationMax Loss', -1.5875688),
 ('L-6.0 Norm Loss', 0.022176689),
 ('TV(2.0) Loss', 0.21514043)], overall loss: -1.35025155544
Iteration: 222, named_losses: [('ActivationMax Loss', -1.4532541),
 ('L-6.0 Norm Loss', 0.022176936),
 ('TV(2.0) Loss', 0.21417287)], overall loss: -1.21690428257
Iteration: 223, named_losses: [('ActivationMax Loss', -1.5314276),
 ('L-6.0 Norm Loss', 0.022177309),
 ('TV(2.0) Loss', 0.21418248)], overall loss: -1.29506778717
Iteration: 224, named_losses: [('ActivationMax Loss', -1.5404558),
 ('L-6.0 Norm Loss', 0.022177564),
 ('TV(2.0) Loss', 0.21504967)], overall loss: -1.30322861671
Iteration: 225, named_losses: [('ActivationMax Loss', -1.5413276),
 ('L-6.0 Norm Loss', 0.022176471),
 ('TV(2.0) Loss', 0.21462417)], overall loss: -1.30452692509
Iteration: 226, named_losses: [('ActivationMax Loss', -1.5542488),
 ('L-6.0 Norm Loss', 0.022177067),
 ('TV(2.0) Loss', 0.21348701)], overall loss: -1.31858468056
Iteration: 227, named_losses: [('ActivationMax Loss', -1.5695528),
 ('L-6.0 Norm Loss', 0.022177836),
 ('TV(2.0) Loss', 0.21407288)], overall loss: -1.33330202103
Iteration: 228, named_losses: [('ActivationMax Loss', -1.5371525),
 ('L-6.0 Norm Loss', 0.022177204),
 ('TV(2.0) Loss', 0.21251482)], overall loss: -1.30246043205
Iteration: 229, named_losses: [('ActivationMax Loss', -1.5392475),
 ('L-6.0 Norm Loss', 0.022177123),
 ('TV(2.0) Loss', 0.21255577)], overall loss: -1.30451464653
Iteration: 230, named_losses: [('ActivationMax Loss', -1.5116498),
 ('L-6.0 Norm Loss', 0.022178607),
 ('TV(2.0) Loss', 0.212842)], overall loss: -1.27662920952
Iteration: 231, named_losses: [('ActivationMax Loss', -1.5645424),
 ('L-6.0 Norm Loss', 0.022177519),
 ('TV(2.0) Loss', 0.21188872)], overall loss: -1.33047616482
Iteration: 232, named_losses: [('ActivationMax Loss', -1.5471423),
 ('L-6.0 Norm Loss', 0.022178054),
 ('TV(2.0) Loss', 0.2111032)], overall loss: -1.31386101246
Iteration: 233, named_losses: [('ActivationMax Loss', -1.552511),
 ('L-6.0 Norm Loss', 0.022178052),
 ('TV(2.0) Loss', 0.21227945)], overall loss: -1.31805348396
Iteration: 234, named_losses: [('ActivationMax Loss', -1.5790997),
 ('L-6.0 Norm Loss', 0.022177657),
 ('TV(2.0) Loss', 0.21188763)], overall loss: -1.34503436089
Iteration: 235, named_losses: [('ActivationMax Loss', -1.5383041),
 ('L-6.0 Norm Loss', 0.022178221),
 ('TV(2.0) Loss', 0.21220203)], overall loss: -1.30392384529
Iteration: 236, named_losses: [('ActivationMax Loss', -1.5130258),
 ('L-6.0 Norm Loss', 0.022177257),
 ('TV(2.0) Loss', 0.21244925)], overall loss: -1.27839922905
Iteration: 237, named_losses: [('ActivationMax Loss', -1.5253066),
 ('L-6.0 Norm Loss', 0.022177426),
 ('TV(2.0) Loss', 0.21316619)], overall loss: -1.28996288776
Iteration: 238, named_losses: [('ActivationMax Loss', -1.5629842),
 ('L-6.0 Norm Loss', 0.022177791),
 ('TV(2.0) Loss', 0.21298398)], overall loss: -1.32782244682
Iteration: 239, named_losses: [('ActivationMax Loss', -1.5525982),
 ('L-6.0 Norm Loss', 0.022177352),
 ('TV(2.0) Loss', 0.21304138)], overall loss: -1.31737947464
Iteration: 240, named_losses: [('ActivationMax Loss', -1.5727566),
 ('L-6.0 Norm Loss', 0.022178169),
 ('TV(2.0) Loss', 0.21420419)], overall loss: -1.33637428284
Iteration: 241, named_losses: [('ActivationMax Loss', -1.4892133),
 ('L-6.0 Norm Loss', 0.022178784),
 ('TV(2.0) Loss', 0.21274757)], overall loss: -1.25428700447
Iteration: 242, named_losses: [('ActivationMax Loss', -1.5061798),
 ('L-6.0 Norm Loss', 0.022177575),
 ('TV(2.0) Loss', 0.21443687)], overall loss: -1.26956534386
Iteration: 243, named_losses: [('ActivationMax Loss', -1.5419291),
 ('L-6.0 Norm Loss', 0.02217765),
 ('TV(2.0) Loss', 0.21396464)], overall loss: -1.30578684807
Iteration: 244, named_losses: [('ActivationMax Loss', -1.5921489),
 ('L-6.0 Norm Loss', 0.022177706),
 ('TV(2.0) Loss', 0.2135798)], overall loss: -1.3563914299
Iteration: 245, named_losses: [('ActivationMax Loss', -1.5659769),
 ('L-6.0 Norm Loss', 0.022177549),
 ('TV(2.0) Loss', 0.21196648)], overall loss: -1.33183276653
Iteration: 246, named_losses: [('ActivationMax Loss', -1.5505368),
 ('L-6.0 Norm Loss', 0.022177862),
 ('TV(2.0) Loss', 0.21292305)], overall loss: -1.31543588638
Iteration: 247, named_losses: [('ActivationMax Loss', -1.5267962),
 ('L-6.0 Norm Loss', 0.022178592),
 ('TV(2.0) Loss', 0.21268922)], overall loss: -1.29192829132
Iteration: 248, named_losses: [('ActivationMax Loss', -1.5083858),
 ('L-6.0 Norm Loss', 0.022178262),
 ('TV(2.0) Loss', 0.21330434)], overall loss: -1.27290320396
Iteration: 249, named_losses: [('ActivationMax Loss', -1.5420334),
 ('L-6.0 Norm Loss', 0.022178296),
 ('TV(2.0) Loss', 0.21180636)], overall loss: -1.30804872513
Iteration: 250, named_losses: [('ActivationMax Loss', -1.5607713),
 ('L-6.0 Norm Loss', 0.022178698),
 ('TV(2.0) Loss', 0.21239358)], overall loss: -1.32619905472
Iteration: 251, named_losses: [('ActivationMax Loss', -1.5816329),
 ('L-6.0 Norm Loss', 0.022178097),
 ('TV(2.0) Loss', 0.21218923)], overall loss: -1.34726560116
Iteration: 252, named_losses: [('ActivationMax Loss', -1.5721884),
 ('L-6.0 Norm Loss', 0.022178326),
 ('TV(2.0) Loss', 0.21143852)], overall loss: -1.33857154846
Iteration: 253, named_losses: [('ActivationMax Loss', -1.5736861),
 ('L-6.0 Norm Loss', 0.022178749),
 ('TV(2.0) Loss', 0.21208315)], overall loss: -1.33942425251
Iteration: 254, named_losses: [('ActivationMax Loss', -1.5971305),
 ('L-6.0 Norm Loss', 0.022179579),
 ('TV(2.0) Loss', 0.21071489)], overall loss: -1.3642359972
Iteration: 255, named_losses: [('ActivationMax Loss', -1.5662856),
 ('L-6.0 Norm Loss', 0.022178859),
 ('TV(2.0) Loss', 0.21121225)], overall loss: -1.33289444447
Iteration: 256, named_losses: [('ActivationMax Loss', -1.5691357),
 ('L-6.0 Norm Loss', 0.022179257),
 ('TV(2.0) Loss', 0.21076727)], overall loss: -1.33618915081
Iteration: 257, named_losses: [('ActivationMax Loss', -1.550215),
 ('L-6.0 Norm Loss', 0.022178989),
 ('TV(2.0) Loss', 0.21210493)], overall loss: -1.31593108177
Iteration: 258, named_losses: [('ActivationMax Loss', -1.5808588),
 ('L-6.0 Norm Loss', 0.022179309),
 ('TV(2.0) Loss', 0.21174142)], overall loss: -1.34693801403
Iteration: 259, named_losses: [('ActivationMax Loss', -1.522828),
 ('L-6.0 Norm Loss', 0.02217925),
 ('TV(2.0) Loss', 0.2113664)], overall loss: -1.28928232193
Iteration: 260, named_losses: [('ActivationMax Loss', -1.515517),
 ('L-6.0 Norm Loss', 0.022179948),
 ('TV(2.0) Loss', 0.21208817)], overall loss: -1.28124880791
Iteration: 261, named_losses: [('ActivationMax Loss', -1.4689741),
 ('L-6.0 Norm Loss', 0.022179354),
 ('TV(2.0) Loss', 0.21248153)], overall loss: -1.23431324959
Iteration: 262, named_losses: [('ActivationMax Loss', -1.4895319),
 ('L-6.0 Norm Loss', 0.022180045),
 ('TV(2.0) Loss', 0.21164112)], overall loss: -1.25571072102
Iteration: 263, named_losses: [('ActivationMax Loss', -1.510437),
 ('L-6.0 Norm Loss', 0.022180833),
 ('TV(2.0) Loss', 0.21190082)], overall loss: -1.27635538578
Iteration: 264, named_losses: [('ActivationMax Loss', -1.5480224),
 ('L-6.0 Norm Loss', 0.022180721),
 ('TV(2.0) Loss', 0.21228743)], overall loss: -1.31355428696
Iteration: 265, named_losses: [('ActivationMax Loss', -1.5129924),
 ('L-6.0 Norm Loss', 0.022181753),
 ('TV(2.0) Loss', 0.21257825)], overall loss: -1.27823233604
Iteration: 266, named_losses: [('ActivationMax Loss', -1.5643532),
 ('L-6.0 Norm Loss', 0.022181088),
 ('TV(2.0) Loss', 0.21246423)], overall loss: -1.32970798016
Iteration: 267, named_losses: [('ActivationMax Loss', -1.5587622),
 ('L-6.0 Norm Loss', 0.022181824),
 ('TV(2.0) Loss', 0.21275838)], overall loss: -1.32382190228
Iteration: 268, named_losses: [('ActivationMax Loss', -1.4776108),
 ('L-6.0 Norm Loss', 0.022181084),
 ('TV(2.0) Loss', 0.21222547)], overall loss: -1.24320435524
Iteration: 269, named_losses: [('ActivationMax Loss', -1.521787),
 ('L-6.0 Norm Loss', 0.02218225),
 ('TV(2.0) Loss', 0.2120112)], overall loss: -1.28759360313
Iteration: 270, named_losses: [('ActivationMax Loss', -1.5645036),
 ('L-6.0 Norm Loss', 0.022180986),
 ('TV(2.0) Loss', 0.21163678)], overall loss: -1.33068573475
Iteration: 271, named_losses: [('ActivationMax Loss', -1.5536113),
 ('L-6.0 Norm Loss', 0.022181161),
 ('TV(2.0) Loss', 0.2100091)], overall loss: -1.32142102718
Iteration: 272, named_losses: [('ActivationMax Loss', -1.5500479),
 ('L-6.0 Norm Loss', 0.02218125),
 ('TV(2.0) Loss', 0.21029496)], overall loss: -1.31757164001
Iteration: 273, named_losses: [('ActivationMax Loss', -1.5301274),
 ('L-6.0 Norm Loss', 0.022181718),
 ('TV(2.0) Loss', 0.21053161)], overall loss: -1.29741406441
Iteration: 274, named_losses: [('ActivationMax Loss', -1.594846),
 ('L-6.0 Norm Loss', 0.022182127),
 ('TV(2.0) Loss', 0.21115692)], overall loss: -1.36150693893
Iteration: 275, named_losses: [('ActivationMax Loss', -1.5413951),
 ('L-6.0 Norm Loss', 0.022181887),
 ('TV(2.0) Loss', 0.21093486)], overall loss: -1.30827832222
Iteration: 276, named_losses: [('ActivationMax Loss', -1.5152519),
 ('L-6.0 Norm Loss', 0.022182535),
 ('TV(2.0) Loss', 0.21153262)], overall loss: -1.28153669834
Iteration: 277, named_losses: [('ActivationMax Loss', -1.5797634),
 ('L-6.0 Norm Loss', 0.022181876),
 ('TV(2.0) Loss', 0.21161272)], overall loss: -1.34596884251
Iteration: 278, named_losses: [('ActivationMax Loss', -1.5842738),
 ('L-6.0 Norm Loss', 0.022182267),
 ('TV(2.0) Loss', 0.21032627)], overall loss: -1.351765275
Iteration: 279, named_losses: [('ActivationMax Loss', -1.6011811),
 ('L-6.0 Norm Loss', 0.02218174),
 ('TV(2.0) Loss', 0.21018289)], overall loss: -1.36881649494
Iteration: 280, named_losses: [('ActivationMax Loss', -1.5493937),
 ('L-6.0 Norm Loss', 0.022181783),
 ('TV(2.0) Loss', 0.20876823)], overall loss: -1.31844365597
Iteration: 281, named_losses: [('ActivationMax Loss', -1.5840288),
 ('L-6.0 Norm Loss', 0.02218166),
 ('TV(2.0) Loss', 0.20960662)], overall loss: -1.35224056244
Iteration: 282, named_losses: [('ActivationMax Loss', -1.5914766),
 ('L-6.0 Norm Loss', 0.022181779),
 ('TV(2.0) Loss', 0.20926219)], overall loss: -1.36003255844
Iteration: 283, named_losses: [('ActivationMax Loss', -1.5470716),
 ('L-6.0 Norm Loss', 0.02218155),
 ('TV(2.0) Loss', 0.20886396)], overall loss: -1.31602609158
Iteration: 284, named_losses: [('ActivationMax Loss', -1.5427074),
 ('L-6.0 Norm Loss', 0.022181038),
 ('TV(2.0) Loss', 0.20821634)], overall loss: -1.3123100996
Iteration: 285, named_losses: [('ActivationMax Loss', -1.5512676),
 ('L-6.0 Norm Loss', 0.022181422),
 ('TV(2.0) Loss', 0.2074427)], overall loss: -1.32164359093
Iteration: 286, named_losses: [('ActivationMax Loss', -1.5542736),
 ('L-6.0 Norm Loss', 0.022180779),
 ('TV(2.0) Loss', 0.20778453)], overall loss: -1.32430827618
Iteration: 287, named_losses: [('ActivationMax Loss', -1.5364485),
 ('L-6.0 Norm Loss', 0.022181449),
 ('TV(2.0) Loss', 0.20868169)], overall loss: -1.30558538437
Iteration: 288, named_losses: [('ActivationMax Loss', -1.5536263),
 ('L-6.0 Norm Loss', 0.022181692),
 ('TV(2.0) Loss', 0.20984067)], overall loss: -1.32160389423
Iteration: 289, named_losses: [('ActivationMax Loss', -1.537277),
 ('L-6.0 Norm Loss', 0.022182597),
 ('TV(2.0) Loss', 0.21077532)], overall loss: -1.3043191433
Iteration: 290, named_losses: [('ActivationMax Loss', -1.5519696),
 ('L-6.0 Norm Loss', 0.022181638),
 ('TV(2.0) Loss', 0.21094412)], overall loss: -1.31884384155
Iteration: 291, named_losses: [('ActivationMax Loss', -1.528778),
 ('L-6.0 Norm Loss', 0.022182982),
 ('TV(2.0) Loss', 0.21143304)], overall loss: -1.29516196251
Iteration: 292, named_losses: [('ActivationMax Loss', -1.5345738),
 ('L-6.0 Norm Loss', 0.022181848),
 ('TV(2.0) Loss', 0.21154556)], overall loss: -1.30084633827
Iteration: 293, named_losses: [('ActivationMax Loss', -1.544477),
 ('L-6.0 Norm Loss', 0.022182405),
 ('TV(2.0) Loss', 0.21051061)], overall loss: -1.3117839098
Iteration: 294, named_losses: [('ActivationMax Loss', -1.5660081),
 ('L-6.0 Norm Loss', 0.022182548),
 ('TV(2.0) Loss', 0.21106477)], overall loss: -1.33276069164
Iteration: 295, named_losses: [('ActivationMax Loss', -1.5774909),
 ('L-6.0 Norm Loss', 0.02218261),
 ('TV(2.0) Loss', 0.21060754)], overall loss: -1.34470081329
Iteration: 296, named_losses: [('ActivationMax Loss', -1.5296416),
 ('L-6.0 Norm Loss', 0.022183042),
 ('TV(2.0) Loss', 0.210803)], overall loss: -1.2966555357
Iteration: 297, named_losses: [('ActivationMax Loss', -1.5634815),
 ('L-6.0 Norm Loss', 0.022183264),
 ('TV(2.0) Loss', 0.21153124)], overall loss: -1.32976686954
Iteration: 298, named_losses: [('ActivationMax Loss', -1.5430973),
 ('L-6.0 Norm Loss', 0.022182548),
 ('TV(2.0) Loss', 0.21105316)], overall loss: -1.30986154079
Iteration: 299, named_losses: [('ActivationMax Loss', -1.548808),
 ('L-6.0 Norm Loss', 0.022183176),
 ('TV(2.0) Loss', 0.21209182)], overall loss: -1.31453299522
Iteration: 300, named_losses: [('ActivationMax Loss', -1.5598234),
 ('L-6.0 Norm Loss', 0.022182696),
 ('TV(2.0) Loss', 0.21108955)], overall loss: -1.32655119896
Iteration: 301, named_losses: [('ActivationMax Loss', -1.5675166),
 ('L-6.0 Norm Loss', 0.02218294),
 ('TV(2.0) Loss', 0.2103924)], overall loss: -1.33494126797
Iteration: 302, named_losses: [('ActivationMax Loss', -1.5539433),
 ('L-6.0 Norm Loss', 0.022182316),
 ('TV(2.0) Loss', 0.20910665)], overall loss: -1.32265424728
Iteration: 303, named_losses: [('ActivationMax Loss', -1.5799091),
 ('L-6.0 Norm Loss', 0.022182165),
 ('TV(2.0) Loss', 0.20777418)], overall loss: -1.34995281696
Iteration: 304, named_losses: [('ActivationMax Loss', -1.576488),
 ('L-6.0 Norm Loss', 0.022181667),
 ('TV(2.0) Loss', 0.20821361)], overall loss: -1.34609282017
Iteration: 305, named_losses: [('ActivationMax Loss', -1.557952),
 ('L-6.0 Norm Loss', 0.022181757),
 ('TV(2.0) Loss', 0.20900679)], overall loss: -1.3267635107
Iteration: 306, named_losses: [('ActivationMax Loss', -1.5829754),
 ('L-6.0 Norm Loss', 0.022181872),
 ('TV(2.0) Loss', 0.20998575)], overall loss: -1.35080778599
Iteration: 307, named_losses: [('ActivationMax Loss', -1.5535157),
 ('L-6.0 Norm Loss', 0.022181803),
 ('TV(2.0) Loss', 0.20959781)], overall loss: -1.32173609734
Iteration: 308, named_losses: [('ActivationMax Loss', -1.5660956),
 ('L-6.0 Norm Loss', 0.022182411),
 ('TV(2.0) Loss', 0.21142027)], overall loss: -1.33249282837
Iteration: 309, named_losses: [('ActivationMax Loss', -1.4875063),
 ('L-6.0 Norm Loss', 0.022181982),
 ('TV(2.0) Loss', 0.21017954)], overall loss: -1.25514471531
Iteration: 310, named_losses: [('ActivationMax Loss', -1.4910481),
 ('L-6.0 Norm Loss', 0.022182882),
 ('TV(2.0) Loss', 0.21197449)], overall loss: -1.25689065456
Iteration: 311, named_losses: [('ActivationMax Loss', -1.554597),
 ('L-6.0 Norm Loss', 0.022184096),
 ('TV(2.0) Loss', 0.21300359)], overall loss: -1.31940925121
Iteration: 312, named_losses: [('ActivationMax Loss', -1.5451035),
 ('L-6.0 Norm Loss', 0.022183387),
 ('TV(2.0) Loss', 0.21241921)], overall loss: -1.31050086021
Iteration: 313, named_losses: [('ActivationMax Loss', -1.5826141),
 ('L-6.0 Norm Loss', 0.022183368),
 ('TV(2.0) Loss', 0.21246536)], overall loss: -1.34796524048
Iteration: 314, named_losses: [('ActivationMax Loss', -1.5921804),
 ('L-6.0 Norm Loss', 0.022184009),
 ('TV(2.0) Loss', 0.21209781)], overall loss: -1.35789859295
Iteration: 315, named_losses: [('ActivationMax Loss', -1.5815222),
 ('L-6.0 Norm Loss', 0.022183172),
 ('TV(2.0) Loss', 0.21011129)], overall loss: -1.34922778606
Iteration: 316, named_losses: [('ActivationMax Loss', -1.5446951),
 ('L-6.0 Norm Loss', 0.022184081),
 ('TV(2.0) Loss', 0.21144356)], overall loss: -1.31106746197
Iteration: 317, named_losses: [('ActivationMax Loss', -1.5675501),
 ('L-6.0 Norm Loss', 0.022183498),
 ('TV(2.0) Loss', 0.21093814)], overall loss: -1.3344284296
Iteration: 318, named_losses: [('ActivationMax Loss', -1.5476596),
 ('L-6.0 Norm Loss', 0.0221835),
 ('TV(2.0) Loss', 0.21202908)], overall loss: -1.3134469986
Iteration: 319, named_losses: [('ActivationMax Loss', -1.5577006),
 ('L-6.0 Norm Loss', 0.022184206),
 ('TV(2.0) Loss', 0.21088491)], overall loss: -1.32463145256
Iteration: 320, named_losses: [('ActivationMax Loss', -1.5268),
 ('L-6.0 Norm Loss', 0.022184525),
 ('TV(2.0) Loss', 0.21250565)], overall loss: -1.29210984707
Iteration: 321, named_losses: [('ActivationMax Loss', -1.5773116),
 ('L-6.0 Norm Loss', 0.02218442),
 ('TV(2.0) Loss', 0.21257979)], overall loss: -1.34254741669
Iteration: 322, named_losses: [('ActivationMax Loss', -1.516959),
 ('L-6.0 Norm Loss', 0.02218388),
 ('TV(2.0) Loss', 0.21171844)], overall loss: -1.28305661678
Iteration: 323, named_losses: [('ActivationMax Loss', -1.5506659),
 ('L-6.0 Norm Loss', 0.022184163),
 ('TV(2.0) Loss', 0.21190067)], overall loss: -1.31658101082
Iteration: 324, named_losses: [('ActivationMax Loss', -1.5627534),
 ('L-6.0 Norm Loss', 0.022184664),
 ('TV(2.0) Loss', 0.21086748)], overall loss: -1.32970130444
Iteration: 325, named_losses: [('ActivationMax Loss', -1.5073191),
 ('L-6.0 Norm Loss', 0.022183727),
 ('TV(2.0) Loss', 0.21152976)], overall loss: -1.2736055851
Iteration: 326, named_losses: [('ActivationMax Loss', -1.5516986),
 ('L-6.0 Norm Loss', 0.022184543),
 ('TV(2.0) Loss', 0.20972608)], overall loss: -1.31978797913
Iteration: 327, named_losses: [('ActivationMax Loss', -1.5943714),
 ('L-6.0 Norm Loss', 0.022184417),
 ('TV(2.0) Loss', 0.2102796)], overall loss: -1.36190748215
Iteration: 328, named_losses: [('ActivationMax Loss', -1.5435194),
 ('L-6.0 Norm Loss', 0.022185419),
 ('TV(2.0) Loss', 0.20829208)], overall loss: -1.31304180622
Iteration: 329, named_losses: [('ActivationMax Loss', -1.5616949),
 ('L-6.0 Norm Loss', 0.022184275),
 ('TV(2.0) Loss', 0.20886888)], overall loss: -1.33064174652
Iteration: 330, named_losses: [('ActivationMax Loss', -1.5522034),
 ('L-6.0 Norm Loss', 0.022184234),
 ('TV(2.0) Loss', 0.20817821)], overall loss: -1.32184100151
Iteration: 331, named_losses: [('ActivationMax Loss', -1.5835776),
 ('L-6.0 Norm Loss', 0.022184074),
 ('TV(2.0) Loss', 0.20852253)], overall loss: -1.35287094116
Iteration: 332, named_losses: [('ActivationMax Loss', -1.550739),
 ('L-6.0 Norm Loss', 0.022183834),
 ('TV(2.0) Loss', 0.20781308)], overall loss: -1.32074213028
Iteration: 333, named_losses: [('ActivationMax Loss', -1.5743692),
 ('L-6.0 Norm Loss', 0.022184083),
 ('TV(2.0) Loss', 0.20840251)], overall loss: -1.34378254414
Iteration: 334, named_losses: [('ActivationMax Loss', -1.5626487),
 ('L-6.0 Norm Loss', 0.022184134),
 ('TV(2.0) Loss', 0.20925905)], overall loss: -1.33120548725
Iteration: 335, named_losses: [('ActivationMax Loss', -1.6194222),
 ('L-6.0 Norm Loss', 0.022184232),
 ('TV(2.0) Loss', 0.2091267)], overall loss: -1.38811123371
Iteration: 336, named_losses: [('ActivationMax Loss', -1.5896888),
 ('L-6.0 Norm Loss', 0.022183975),
 ('TV(2.0) Loss', 0.20724787)], overall loss: -1.36025691032
Iteration: 337, named_losses: [('ActivationMax Loss', -1.556613),
 ('L-6.0 Norm Loss', 0.022185111),
 ('TV(2.0) Loss', 0.20826176)], overall loss: -1.32616615295
Iteration: 338, named_losses: [('ActivationMax Loss', -1.5735098),
 ('L-6.0 Norm Loss', 0.022183741),
 ('TV(2.0) Loss', 0.20779167)], overall loss: -1.3435343504
Iteration: 339, named_losses: [('ActivationMax Loss', -1.474005),
 ('L-6.0 Norm Loss', 0.022184011),
 ('TV(2.0) Loss', 0.20782703)], overall loss: -1.24399399757
Iteration: 340, named_losses: [('ActivationMax Loss', -1.5903128),
 ('L-6.0 Norm Loss', 0.022184156),
 ('TV(2.0) Loss', 0.20777795)], overall loss: -1.36035072803
Iteration: 341, named_losses: [('ActivationMax Loss', -1.5352867),
 ('L-6.0 Norm Loss', 0.02218454),
 ('TV(2.0) Loss', 0.20750403)], overall loss: -1.30559813976
Iteration: 342, named_losses: [('ActivationMax Loss', -1.5526955),
 ('L-6.0 Norm Loss', 0.022184391),
 ('TV(2.0) Loss', 0.2091431)], overall loss: -1.32136797905
Iteration: 343, named_losses: [('ActivationMax Loss', -1.5718498),
 ('L-6.0 Norm Loss', 0.022183862),
 ('TV(2.0) Loss', 0.20889823)], overall loss: -1.3407677412
Iteration: 344, named_losses: [('ActivationMax Loss', -1.5073378),
 ('L-6.0 Norm Loss', 0.022183668),
 ('TV(2.0) Loss', 0.21022275)], overall loss: -1.27493143082
Iteration: 345, named_losses: [('ActivationMax Loss', -1.513756),
 ('L-6.0 Norm Loss', 0.022184025),
 ('TV(2.0) Loss', 0.20910379)], overall loss: -1.28246819973
Iteration: 346, named_losses: [('ActivationMax Loss', -1.4805192),
 ('L-6.0 Norm Loss', 0.022183649),
 ('TV(2.0) Loss', 0.20821974)], overall loss: -1.25011575222
Iteration: 347, named_losses: [('ActivationMax Loss', -1.5539714),
 ('L-6.0 Norm Loss', 0.0221847),
 ('TV(2.0) Loss', 0.2085949)], overall loss: -1.32319176197
Iteration: 348, named_losses: [('ActivationMax Loss', -1.5230863),
 ('L-6.0 Norm Loss', 0.022184402),
 ('TV(2.0) Loss', 0.20796776)], overall loss: -1.29293417931
Iteration: 349, named_losses: [('ActivationMax Loss', -1.5345455),
 ('L-6.0 Norm Loss', 0.022185819),
 ('TV(2.0) Loss', 0.20868206)], overall loss: -1.30367767811
Iteration: 350, named_losses: [('ActivationMax Loss', -1.5406243),
 ('L-6.0 Norm Loss', 0.022186052),
 ('TV(2.0) Loss', 0.20817594)], overall loss: -1.31026232243
Iteration: 351, named_losses: [('ActivationMax Loss', -1.4895918),
 ('L-6.0 Norm Loss', 0.022185113),
 ('TV(2.0) Loss', 0.20763412)], overall loss: -1.25977265835
Iteration: 352, named_losses: [('ActivationMax Loss', -1.5594957),
 ('L-6.0 Norm Loss', 0.022184664),
 ('TV(2.0) Loss', 0.20813905)], overall loss: -1.32917201519
Iteration: 353, named_losses: [('ActivationMax Loss', -1.551608),
 ('L-6.0 Norm Loss', 0.022185437),
 ('TV(2.0) Loss', 0.20794748)], overall loss: -1.32147502899
Iteration: 354, named_losses: [('ActivationMax Loss', -1.5577967),
 ('L-6.0 Norm Loss', 0.022185778),
 ('TV(2.0) Loss', 0.20865335)], overall loss: -1.32695758343
Iteration: 355, named_losses: [('ActivationMax Loss', -1.5730965),
 ('L-6.0 Norm Loss', 0.022186963),
 ('TV(2.0) Loss', 0.20864132)], overall loss: -1.34226822853
Iteration: 356, named_losses: [('ActivationMax Loss', -1.5658116),
 ('L-6.0 Norm Loss', 0.022185912),
 ('TV(2.0) Loss', 0.20986857)], overall loss: -1.33375716209
Iteration: 357, named_losses: [('ActivationMax Loss', -1.470045),
 ('L-6.0 Norm Loss', 0.022185382),
 ('TV(2.0) Loss', 0.20751075)], overall loss: -1.24034893513
Iteration: 358, named_losses: [('ActivationMax Loss', -1.562108),
 ('L-6.0 Norm Loss', 0.022185374),
 ('TV(2.0) Loss', 0.20854686)], overall loss: -1.33137583733
Iteration: 359, named_losses: [('ActivationMax Loss', -1.5625702),
 ('L-6.0 Norm Loss', 0.022185832),
 ('TV(2.0) Loss', 0.20678876)], overall loss: -1.33359563351
Iteration: 360, named_losses: [('ActivationMax Loss', -1.5449233),
 ('L-6.0 Norm Loss', 0.022185784),
 ('TV(2.0) Loss', 0.20810297)], overall loss: -1.31463456154
Iteration: 361, named_losses: [('ActivationMax Loss', -1.5589068),
 ('L-6.0 Norm Loss', 0.022185724),
 ('TV(2.0) Loss', 0.20742294)], overall loss: -1.32929813862
Iteration: 362, named_losses: [('ActivationMax Loss', -1.5626858),
 ('L-6.0 Norm Loss', 0.022186343),
 ('TV(2.0) Loss', 0.20964143)], overall loss: -1.33085799217
Iteration: 363, named_losses: [('ActivationMax Loss', -1.5576453),
 ('L-6.0 Norm Loss', 0.022185069),
 ('TV(2.0) Loss', 0.20916048)], overall loss: -1.32629978657
Iteration: 364, named_losses: [('ActivationMax Loss', -1.538711),
 ('L-6.0 Norm Loss', 0.022185257),
 ('TV(2.0) Loss', 0.21096686)], overall loss: -1.30555891991
Iteration: 365, named_losses: [('ActivationMax Loss', -1.5976253),
 ('L-6.0 Norm Loss', 0.022185314),
 ('TV(2.0) Loss', 0.21025905)], overall loss: -1.36518085003
Iteration: 366, named_losses: [('ActivationMax Loss', -1.5670609),
 ('L-6.0 Norm Loss', 0.022184953),
 ('TV(2.0) Loss', 0.20833208)], overall loss: -1.33654391766
Iteration: 367, named_losses: [('ActivationMax Loss', -1.5413564),
 ('L-6.0 Norm Loss', 0.022184746),
 ('TV(2.0) Loss', 0.20930165)], overall loss: -1.30987000465
Iteration: 368, named_losses: [('ActivationMax Loss', -1.5087587),
 ('L-6.0 Norm Loss', 0.022184547),
 ('TV(2.0) Loss', 0.20762743)], overall loss: -1.27894675732
Iteration: 369, named_losses: [('ActivationMax Loss', -1.5007651),
 ('L-6.0 Norm Loss', 0.022185154),
 ('TV(2.0) Loss', 0.20799012)], overall loss: -1.27058970928
Iteration: 370, named_losses: [('ActivationMax Loss', -1.5707953),
 ('L-6.0 Norm Loss', 0.022184525),
 ('TV(2.0) Loss', 0.20778796)], overall loss: -1.3408228159
Iteration: 371, named_losses: [('ActivationMax Loss', -1.5934997),
 ('L-6.0 Norm Loss', 0.022185707),
 ('TV(2.0) Loss', 0.20834802)], overall loss: -1.36296594143
Iteration: 372, named_losses: [('ActivationMax Loss', -1.5472881),
 ('L-6.0 Norm Loss', 0.022185665),
 ('TV(2.0) Loss', 0.20691368)], overall loss: -1.3181886673
Iteration: 373, named_losses: [('ActivationMax Loss', -1.5810549),
 ('L-6.0 Norm Loss', 0.022185754),
 ('TV(2.0) Loss', 0.20761213)], overall loss: -1.35125696659
Iteration: 374, named_losses: [('ActivationMax Loss', -1.5601566),
 ('L-6.0 Norm Loss', 0.022184096),
 ('TV(2.0) Loss', 0.20670402)], overall loss: -1.33126842976
Iteration: 375, named_losses: [('ActivationMax Loss', -1.584921),
 ('L-6.0 Norm Loss', 0.022185501),
 ('TV(2.0) Loss', 0.20716955)], overall loss: -1.35556602478
Iteration: 376, named_losses: [('ActivationMax Loss', -1.5471334),
 ('L-6.0 Norm Loss', 0.022184949),
 ('TV(2.0) Loss', 0.20610282)], overall loss: -1.31884562969
Iteration: 377, named_losses: [('ActivationMax Loss', -1.5346816),
 ('L-6.0 Norm Loss', 0.022184502),
 ('TV(2.0) Loss', 0.20706511)], overall loss: -1.30543196201
Iteration: 378, named_losses: [('ActivationMax Loss', -1.5739791),
 ('L-6.0 Norm Loss', 0.022185052),
 ('TV(2.0) Loss', 0.20712282)], overall loss: -1.34467124939
Iteration: 379, named_losses: [('ActivationMax Loss', -1.6092442),
 ('L-6.0 Norm Loss', 0.022185337),
 ('TV(2.0) Loss', 0.20786184)], overall loss: -1.37919712067
Iteration: 380, named_losses: [('ActivationMax Loss', -1.5984534),
 ('L-6.0 Norm Loss', 0.022183992),
 ('TV(2.0) Loss', 0.20595795)], overall loss: -1.37031149864
Iteration: 381, named_losses: [('ActivationMax Loss', -1.6144755),
 ('L-6.0 Norm Loss', 0.022184009),
 ('TV(2.0) Loss', 0.20474656)], overall loss: -1.38754487038
Iteration: 382, named_losses: [('ActivationMax Loss', -1.5411414),
 ('L-6.0 Norm Loss', 0.02218459),
 ('TV(2.0) Loss', 0.20499912)], overall loss: -1.31395769119
Iteration: 383, named_losses: [('ActivationMax Loss', -1.5501244),
 ('L-6.0 Norm Loss', 0.022184346),
 ('TV(2.0) Loss', 0.20405456)], overall loss: -1.32388544083
Iteration: 384, named_losses: [('ActivationMax Loss', -1.58956),
 ('L-6.0 Norm Loss', 0.022184195),
 ('TV(2.0) Loss', 0.20485017)], overall loss: -1.36252558231
Iteration: 385, named_losses: [('ActivationMax Loss', -1.568717),
 ('L-6.0 Norm Loss', 0.022184001),
 ('TV(2.0) Loss', 0.20375834)], overall loss: -1.34277462959
Iteration: 386, named_losses: [('ActivationMax Loss', -1.5841999),
 ('L-6.0 Norm Loss', 0.022184441),
 ('TV(2.0) Loss', 0.20504165)], overall loss: -1.35697376728
Iteration: 387, named_losses: [('ActivationMax Loss', -1.5912116),
 ('L-6.0 Norm Loss', 0.022184506),
 ('TV(2.0) Loss', 0.20482212)], overall loss: -1.36420488358
Iteration: 388, named_losses: [('ActivationMax Loss', -1.5983297),
 ('L-6.0 Norm Loss', 0.022183582),
 ('TV(2.0) Loss', 0.20613183)], overall loss: -1.37001430988
Iteration: 389, named_losses: [('ActivationMax Loss', -1.5402994),
 ('L-6.0 Norm Loss', 0.022184741),
 ('TV(2.0) Loss', 0.20576225)], overall loss: -1.3123524189
Iteration: 390, named_losses: [('ActivationMax Loss', -1.5971644),
 ('L-6.0 Norm Loss', 0.0221835),
 ('TV(2.0) Loss', 0.20602033)], overall loss: -1.36896049976
Iteration: 391, named_losses: [('ActivationMax Loss', -1.5986629),
 ('L-6.0 Norm Loss', 0.022184851),
 ('TV(2.0) Loss', 0.20496377)], overall loss: -1.37151420116
Iteration: 392, named_losses: [('ActivationMax Loss', -1.55101),
 ('L-6.0 Norm Loss', 0.022183638),
 ('TV(2.0) Loss', 0.20503354)], overall loss: -1.32379281521
Iteration: 393, named_losses: [('ActivationMax Loss', -1.5646327),
 ('L-6.0 Norm Loss', 0.022183958),
 ('TV(2.0) Loss', 0.20541254)], overall loss: -1.33703613281
Iteration: 394, named_losses: [('ActivationMax Loss', -1.5033606),
 ('L-6.0 Norm Loss', 0.022184487),
 ('TV(2.0) Loss', 0.20710975)], overall loss: -1.27406644821
Iteration: 395, named_losses: [('ActivationMax Loss', -1.5648149),
 ('L-6.0 Norm Loss', 0.022184933),
 ('TV(2.0) Loss', 0.20782451)], overall loss: -1.33480548859
Iteration: 396, named_losses: [('ActivationMax Loss', -1.5207516),
 ('L-6.0 Norm Loss', 0.022184595),
 ('TV(2.0) Loss', 0.20814675)], overall loss: -1.29042029381
Iteration: 397, named_losses: [('ActivationMax Loss', -1.5318723),
 ('L-6.0 Norm Loss', 0.022184838),
 ('TV(2.0) Loss', 0.20816405)], overall loss: -1.30152332783
Iteration: 398, named_losses: [('ActivationMax Loss', -1.5850464),
 ('L-6.0 Norm Loss', 0.022185912),
 ('TV(2.0) Loss', 0.20926067)], overall loss: -1.35359978676
Iteration: 399, named_losses: [('ActivationMax Loss', -1.5893984),
 ('L-6.0 Norm Loss', 0.022186421),
 ('TV(2.0) Loss', 0.20838802)], overall loss: -1.35882401466
Iteration: 400, named_losses: [('ActivationMax Loss', -1.5844153),
 ('L-6.0 Norm Loss', 0.022186367),
 ('TV(2.0) Loss', 0.20859689)], overall loss: -1.35363197327
Iteration: 401, named_losses: [('ActivationMax Loss', -1.5858288),
 ('L-6.0 Norm Loss', 0.022186082),
 ('TV(2.0) Loss', 0.20824525)], overall loss: -1.35539746284
Iteration: 402, named_losses: [('ActivationMax Loss', -1.6289241),
 ('L-6.0 Norm Loss', 0.022186646),
 ('TV(2.0) Loss', 0.20841736)], overall loss: -1.39832019806
Iteration: 403, named_losses: [('ActivationMax Loss', -1.5938948),
 ('L-6.0 Norm Loss', 0.022185948),
 ('TV(2.0) Loss', 0.20538883)], overall loss: -1.36632013321
Iteration: 404, named_losses: [('ActivationMax Loss', -1.5973198),
 ('L-6.0 Norm Loss', 0.022185696),
 ('TV(2.0) Loss', 0.20658122)], overall loss: -1.3685529232
Iteration: 405, named_losses: [('ActivationMax Loss', -1.6141887),
 ('L-6.0 Norm Loss', 0.022185359),
 ('TV(2.0) Loss', 0.20614301)], overall loss: -1.38586032391
Iteration: 406, named_losses: [('ActivationMax Loss', -1.5946325),
 ('L-6.0 Norm Loss', 0.02218524),
 ('TV(2.0) Loss', 0.20609781)], overall loss: -1.36634945869
Iteration: 407, named_losses: [('ActivationMax Loss', -1.5876453),
 ('L-6.0 Norm Loss', 0.022186199),
 ('TV(2.0) Loss', 0.20572051)], overall loss: -1.35973858833
Iteration: 408, named_losses: [('ActivationMax Loss', -1.6073862),
 ('L-6.0 Norm Loss', 0.022185605),
 ('TV(2.0) Loss', 0.20647775)], overall loss: -1.37872290611
Iteration: 409, named_losses: [('ActivationMax Loss', -1.5844578),
 ('L-6.0 Norm Loss', 0.022184718),
 ('TV(2.0) Loss', 0.20538692)], overall loss: -1.35688614845
Iteration: 410, named_losses: [('ActivationMax Loss', -1.5768815),
 ('L-6.0 Norm Loss', 0.022186544),
 ('TV(2.0) Loss', 0.20693938)], overall loss: -1.34775567055
Iteration: 411, named_losses: [('ActivationMax Loss', -1.5833787),
 ('L-6.0 Norm Loss', 0.022185709),
 ('TV(2.0) Loss', 0.20612417)], overall loss: -1.35506880283
Iteration: 412, named_losses: [('ActivationMax Loss', -1.5809178),
 ('L-6.0 Norm Loss', 0.022183999),
 ('TV(2.0) Loss', 0.20604151)], overall loss: -1.35269236565
Iteration: 413, named_losses: [('ActivationMax Loss', -1.5743761),
 ('L-6.0 Norm Loss', 0.022184022),
 ('TV(2.0) Loss', 0.20544216)], overall loss: -1.34674990177
Iteration: 414, named_losses: [('ActivationMax Loss', -1.5172279),
 ('L-6.0 Norm Loss', 0.0221854),
 ('TV(2.0) Loss', 0.2061065)], overall loss: -1.28893589973
Iteration: 415, named_losses: [('ActivationMax Loss', -1.5941999),
 ('L-6.0 Norm Loss', 0.022184722),
 ('TV(2.0) Loss', 0.20649149)], overall loss: -1.36552369595
Iteration: 416, named_losses: [('ActivationMax Loss', -1.6020381),
 ('L-6.0 Norm Loss', 0.022183981),
 ('TV(2.0) Loss', 0.20482937)], overall loss: -1.37502479553
Iteration: 417, named_losses: [('ActivationMax Loss', -1.5874519),
 ('L-6.0 Norm Loss', 0.022184765),
 ('TV(2.0) Loss', 0.20443626)], overall loss: -1.36083090305
Iteration: 418, named_losses: [('ActivationMax Loss', -1.6134007),
 ('L-6.0 Norm Loss', 0.022184307),
 ('TV(2.0) Loss', 0.20366161)], overall loss: -1.38755488396
Iteration: 419, named_losses: [('ActivationMax Loss', -1.5659553),
 ('L-6.0 Norm Loss', 0.022184715),
 ('TV(2.0) Loss', 0.20271319)], overall loss: -1.34105730057
Iteration: 420, named_losses: [('ActivationMax Loss', -1.5591198),
 ('L-6.0 Norm Loss', 0.022183701),
 ('TV(2.0) Loss', 0.2031565)], overall loss: -1.33377969265
Iteration: 421, named_losses: [('ActivationMax Loss', -1.5674891),
 ('L-6.0 Norm Loss', 0.02218334),
 ('TV(2.0) Loss', 0.20416194)], overall loss: -1.34114384651
Iteration: 422, named_losses: [('ActivationMax Loss', -1.602555),
 ('L-6.0 Norm Loss', 0.022183528),
 ('TV(2.0) Loss', 0.2043795)], overall loss: -1.37599205971
Iteration: 423, named_losses: [('ActivationMax Loss', -1.6046479),
 ('L-6.0 Norm Loss', 0.022183791),
 ('TV(2.0) Loss', 0.20422271)], overall loss: -1.37824141979
Iteration: 424, named_losses: [('ActivationMax Loss', -1.5433252),
 ('L-6.0 Norm Loss', 0.022183511),
 ('TV(2.0) Loss', 0.20333467)], overall loss: -1.31780695915
Iteration: 425, named_losses: [('ActivationMax Loss', -1.5998229),
 ('L-6.0 Norm Loss', 0.022184841),
 ('TV(2.0) Loss', 0.20558748)], overall loss: -1.37205052376
Iteration: 426, named_losses: [('ActivationMax Loss', -1.5850904),
 ('L-6.0 Norm Loss', 0.022184666),
 ('TV(2.0) Loss', 0.20451814)], overall loss: -1.35838770866
Iteration: 427, named_losses: [('ActivationMax Loss', -1.5649319),
 ('L-6.0 Norm Loss', 0.022183981),
 ('TV(2.0) Loss', 0.20503671)], overall loss: -1.33771109581
Iteration: 428, named_losses: [('ActivationMax Loss', -1.5493618),
 ('L-6.0 Norm Loss', 0.022183878),
 ('TV(2.0) Loss', 0.20528747)], overall loss: -1.32189047337
Iteration: 429, named_losses: [('ActivationMax Loss', -1.5871578),
 ('L-6.0 Norm Loss', 0.022184366),
 ('TV(2.0) Loss', 0.20566575)], overall loss: -1.35930776596
Iteration: 430, named_losses: [('ActivationMax Loss', -1.5718137),
 ('L-6.0 Norm Loss', 0.022185683),
 ('TV(2.0) Loss', 0.20487769)], overall loss: -1.34475028515
Iteration: 431, named_losses: [('ActivationMax Loss', -1.5630603),
 ('L-6.0 Norm Loss', 0.022184696),
 ('TV(2.0) Loss', 0.20605879)], overall loss: -1.33481681347
Iteration: 432, named_losses: [('ActivationMax Loss', -1.4875548),
 ('L-6.0 Norm Loss', 0.022186359),
 ('TV(2.0) Loss', 0.2060423)], overall loss: -1.25932610035
Iteration: 433, named_losses: [('ActivationMax Loss', -1.5986543),
 ('L-6.0 Norm Loss', 0.022185527),
 ('TV(2.0) Loss', 0.20775844)], overall loss: -1.36871027946
Iteration: 434, named_losses: [('ActivationMax Loss', -1.4953413),
 ('L-6.0 Norm Loss', 0.022186518),
 ('TV(2.0) Loss', 0.2070201)], overall loss: -1.26613473892
Iteration: 435, named_losses: [('ActivationMax Loss', -1.5157938),
 ('L-6.0 Norm Loss', 0.02218654),
 ('TV(2.0) Loss', 0.20884731)], overall loss: -1.28475999832
Iteration: 436, named_losses: [('ActivationMax Loss', -1.4935915),
 ('L-6.0 Norm Loss', 0.022185883),
 ('TV(2.0) Loss', 0.20875667)], overall loss: -1.26264894009
Iteration: 437, named_losses: [('ActivationMax Loss', -1.5559062),
 ('L-6.0 Norm Loss', 0.022187298),
 ('TV(2.0) Loss', 0.20970522)], overall loss: -1.32401359081
Iteration: 438, named_losses: [('ActivationMax Loss', -1.5507544),
 ('L-6.0 Norm Loss', 0.022187298),
 ('TV(2.0) Loss', 0.2086187)], overall loss: -1.31994843483
Iteration: 439, named_losses: [('ActivationMax Loss', -1.5597624),
 ('L-6.0 Norm Loss', 0.022186356),
 ('TV(2.0) Loss', 0.20905592)], overall loss: -1.32852005959
Iteration: 440, named_losses: [('ActivationMax Loss', -1.5794277),
 ('L-6.0 Norm Loss', 0.022187099),
 ('TV(2.0) Loss', 0.20856799)], overall loss: -1.3486726284
Iteration: 441, named_losses: [('ActivationMax Loss', -1.5806061),
 ('L-6.0 Norm Loss', 0.022185192),
 ('TV(2.0) Loss', 0.20911953)], overall loss: -1.3493013382
Iteration: 442, named_losses: [('ActivationMax Loss', -1.5723304),
 ('L-6.0 Norm Loss', 0.022187019),
 ('TV(2.0) Loss', 0.20812133)], overall loss: -1.34202206135
Iteration: 443, named_losses: [('ActivationMax Loss', -1.600473),
 ('L-6.0 Norm Loss', 0.022186484),
 ('TV(2.0) Loss', 0.20879102)], overall loss: -1.36949551105
Iteration: 444, named_losses: [('ActivationMax Loss', -1.5722463),
 ('L-6.0 Norm Loss', 0.022184661),
 ('TV(2.0) Loss', 0.20785634)], overall loss: -1.34220540524
Iteration: 445, named_losses: [('ActivationMax Loss', -1.5178292),
 ('L-6.0 Norm Loss', 0.022184998),
 ('TV(2.0) Loss', 0.20890681)], overall loss: -1.28673744202
Iteration: 446, named_losses: [('ActivationMax Loss', -1.5648618),
 ('L-6.0 Norm Loss', 0.022184851),
 ('TV(2.0) Loss', 0.20913091)], overall loss: -1.33354604244
Iteration: 447, named_losses: [('ActivationMax Loss', -1.5505486),
 ('L-6.0 Norm Loss', 0.022186169),
 ('TV(2.0) Loss', 0.21010892)], overall loss: -1.31825351715
Iteration: 448, named_losses: [('ActivationMax Loss', -1.5506258),
 ('L-6.0 Norm Loss', 0.022185631),
 ('TV(2.0) Loss', 0.20895627)], overall loss: -1.31948387623
Iteration: 449, named_losses: [('ActivationMax Loss', -1.4806428),
 ('L-6.0 Norm Loss', 0.022186788),
 ('TV(2.0) Loss', 0.21032982)], overall loss: -1.24812626839
Iteration: 450, named_losses: [('ActivationMax Loss', -1.5541004),
 ('L-6.0 Norm Loss', 0.022185948),
 ('TV(2.0) Loss', 0.21003217)], overall loss: -1.32188224792
Iteration: 451, named_losses: [('ActivationMax Loss', -1.5562997),
 ('L-6.0 Norm Loss', 0.022186369),
 ('TV(2.0) Loss', 0.21030837)], overall loss: -1.32380485535
Iteration: 452, named_losses: [('ActivationMax Loss', -1.5636685),
 ('L-6.0 Norm Loss', 0.022186499),
 ('TV(2.0) Loss', 0.20904218)], overall loss: -1.33243978024
Iteration: 453, named_losses: [('ActivationMax Loss', -1.5875648),
 ('L-6.0 Norm Loss', 0.022186348),
 ('TV(2.0) Loss', 0.20959748)], overall loss: -1.35578095913
Iteration: 454, named_losses: [('ActivationMax Loss', -1.5753686),
 ('L-6.0 Norm Loss', 0.022185951),
 ('TV(2.0) Loss', 0.20905627)], overall loss: -1.34412646294
Iteration: 455, named_losses: [('ActivationMax Loss', -1.5173104),
 ('L-6.0 Norm Loss', 0.022186561),
 ('TV(2.0) Loss', 0.20972109)], overall loss: -1.28540277481
Iteration: 456, named_losses: [('ActivationMax Loss', -1.5778903),
 ('L-6.0 Norm Loss', 0.022185406),
 ('TV(2.0) Loss', 0.20878203)], overall loss: -1.34692275524
Iteration: 457, named_losses: [('ActivationMax Loss', -1.5814253),
 ('L-6.0 Norm Loss', 0.022185126),
 ('TV(2.0) Loss', 0.20894368)], overall loss: -1.35029649734
Iteration: 458, named_losses: [('ActivationMax Loss', -1.5697107),
 ('L-6.0 Norm Loss', 0.022185199),
 ('TV(2.0) Loss', 0.20886377)], overall loss: -1.33866178989
Iteration: 459, named_losses: [('ActivationMax Loss', -1.5413952),
 ('L-6.0 Norm Loss', 0.022186223),
 ('TV(2.0) Loss', 0.20924002)], overall loss: -1.30996894836
Iteration: 460, named_losses: [('ActivationMax Loss', -1.5907201),
 ('L-6.0 Norm Loss', 0.022186659),
 ('TV(2.0) Loss', 0.21022031)], overall loss: -1.35831308365
Iteration: 461, named_losses: [('ActivationMax Loss', -1.6038113),
 ('L-6.0 Norm Loss', 0.022185918),
 ('TV(2.0) Loss', 0.20821428)], overall loss: -1.37341105938
Iteration: 462, named_losses: [('ActivationMax Loss', -1.5792532),
 ('L-6.0 Norm Loss', 0.022185447),
 ('TV(2.0) Loss', 0.20843843)], overall loss: -1.34862935543
Iteration: 463, named_losses: [('ActivationMax Loss', -1.6069312),
 ('L-6.0 Norm Loss', 0.022185305),
 ('TV(2.0) Loss', 0.20629287)], overall loss: -1.37845301628
Iteration: 464, named_losses: [('ActivationMax Loss', -1.5973254),
 ('L-6.0 Norm Loss', 0.022185951),
 ('TV(2.0) Loss', 0.20821664)], overall loss: -1.36692285538
Iteration: 465, named_losses: [('ActivationMax Loss', -1.5729399),
 ('L-6.0 Norm Loss', 0.022183934),
 ('TV(2.0) Loss', 0.20549896)], overall loss: -1.34525704384
Iteration: 466, named_losses: [('ActivationMax Loss', -1.518537),
 ('L-6.0 Norm Loss', 0.022184376),
 ('TV(2.0) Loss', 0.20632532)], overall loss: -1.29002737999
Iteration: 467, named_losses: [('ActivationMax Loss', -1.5742321),
 ('L-6.0 Norm Loss', 0.022185221),
 ('TV(2.0) Loss', 0.206438)], overall loss: -1.34560894966
Iteration: 468, named_losses: [('ActivationMax Loss', -1.5075924),
 ('L-6.0 Norm Loss', 0.022185676),
 ('TV(2.0) Loss', 0.2065752)], overall loss: -1.27883160114
Iteration: 469, named_losses: [('ActivationMax Loss', -1.5669631),
 ('L-6.0 Norm Loss', 0.022185504),
 ('TV(2.0) Loss', 0.20818263)], overall loss: -1.33659505844
Iteration: 470, named_losses: [('ActivationMax Loss', -1.5185535),
 ('L-6.0 Norm Loss', 0.022186179),
 ('TV(2.0) Loss', 0.20819359)], overall loss: -1.28817379475
Iteration: 471, named_losses: [('ActivationMax Loss', -1.5883071),
 ('L-6.0 Norm Loss', 0.02218687),
 ('TV(2.0) Loss', 0.2097635)], overall loss: -1.35635674
Iteration: 472, named_losses: [('ActivationMax Loss', -1.5725193),
 ('L-6.0 Norm Loss', 0.022185653),
 ('TV(2.0) Loss', 0.20849927)], overall loss: -1.34183430672
Iteration: 473, named_losses: [('ActivationMax Loss', -1.5943301),
 ('L-6.0 Norm Loss', 0.022187028),
 ('TV(2.0) Loss', 0.20854725)], overall loss: -1.36359584332
Iteration: 474, named_losses: [('ActivationMax Loss', -1.5846913),
 ('L-6.0 Norm Loss', 0.022185592),
 ('TV(2.0) Loss', 0.20833869)], overall loss: -1.35416698456
Iteration: 475, named_losses: [('ActivationMax Loss', -1.6249745),
 ('L-6.0 Norm Loss', 0.02218616),
 ('TV(2.0) Loss', 0.20905817)], overall loss: -1.39373016357
Iteration: 476, named_losses: [('ActivationMax Loss', -1.5649663),
 ('L-6.0 Norm Loss', 0.022185754),
 ('TV(2.0) Loss', 0.20689124)], overall loss: -1.33588933945
Iteration: 477, named_losses: [('ActivationMax Loss', -1.5530065),
 ('L-6.0 Norm Loss', 0.022184853),
 ('TV(2.0) Loss', 0.20632924)], overall loss: -1.32449245453
Iteration: 478, named_losses: [('ActivationMax Loss', -1.5870532),
 ('L-6.0 Norm Loss', 0.022184661),
 ('TV(2.0) Loss', 0.20701896)], overall loss: -1.35784959793
Iteration: 479, named_losses: [('ActivationMax Loss', -1.6188561),
 ('L-6.0 Norm Loss', 0.022184543),
 ('TV(2.0) Loss', 0.20714332)], overall loss: -1.38952827454
Iteration: 480, named_losses: [('ActivationMax Loss', -1.5707511),
 ('L-6.0 Norm Loss', 0.022183536),
 ('TV(2.0) Loss', 0.20478779)], overall loss: -1.34377980232
Iteration: 481, named_losses: [('ActivationMax Loss', -1.5655226),
 ('L-6.0 Norm Loss', 0.022183789),
 ('TV(2.0) Loss', 0.2060315)], overall loss: -1.33730721474
Iteration: 482, named_losses: [('ActivationMax Loss', -1.586621),
 ('L-6.0 Norm Loss', 0.022183798),
 ('TV(2.0) Loss', 0.20586477)], overall loss: -1.35857248306
Iteration: 483, named_losses: [('ActivationMax Loss', -1.5433229),
 ('L-6.0 Norm Loss', 0.022184078),
 ('TV(2.0) Loss', 0.20638831)], overall loss: -1.31475043297
Iteration: 484, named_losses: [('ActivationMax Loss', -1.5703948),
 ('L-6.0 Norm Loss', 0.022183523),
 ('TV(2.0) Loss', 0.2067057)], overall loss: -1.3415055275
Iteration: 485, named_losses: [('ActivationMax Loss', -1.5526501),
 ('L-6.0 Norm Loss', 0.022185912),
 ('TV(2.0) Loss', 0.20670183)], overall loss: -1.32376229763
Iteration: 486, named_losses: [('ActivationMax Loss', -1.5946563),
 ('L-6.0 Norm Loss', 0.022184758),
 ('TV(2.0) Loss', 0.20690663)], overall loss: -1.36556494236
Iteration: 487, named_losses: [('ActivationMax Loss', -1.5681813),
 ('L-6.0 Norm Loss', 0.022184439),
 ('TV(2.0) Loss', 0.20552737)], overall loss: -1.34046936035
Iteration: 488, named_losses: [('ActivationMax Loss', -1.5672539),
 ('L-6.0 Norm Loss', 0.022185113),
 ('TV(2.0) Loss', 0.2073839)], overall loss: -1.33768498898
Iteration: 489, named_losses: [('ActivationMax Loss', -1.5709436),
 ('L-6.0 Norm Loss', 0.022184959),
 ('TV(2.0) Loss', 0.20476077)], overall loss: -1.34399783611
Iteration: 490, named_losses: [('ActivationMax Loss', -1.5714123),
 ('L-6.0 Norm Loss', 0.022183206),
 ('TV(2.0) Loss', 0.20649116)], overall loss: -1.34273803234
Iteration: 491, named_losses: [('ActivationMax Loss', -1.5934649),
 ('L-6.0 Norm Loss', 0.022183841),
 ('TV(2.0) Loss', 0.20688973)], overall loss: -1.3643912077
Iteration: 492, named_losses: [('ActivationMax Loss', -1.5676696),
 ('L-6.0 Norm Loss', 0.022183336),
 ('TV(2.0) Loss', 0.20638418)], overall loss: -1.33910214901
Iteration: 493, named_losses: [('ActivationMax Loss', -1.5494046),
 ('L-6.0 Norm Loss', 0.022184158),
 ('TV(2.0) Loss', 0.20703734)], overall loss: -1.32018315792
Iteration: 494, named_losses: [('ActivationMax Loss', -1.5968392),
 ('L-6.0 Norm Loss', 0.022184586),
 ('TV(2.0) Loss', 0.20837156)], overall loss: -1.36628305912
Iteration: 495, named_losses: [('ActivationMax Loss', -1.5628519),
 ('L-6.0 Norm Loss', 0.022183154),
 ('TV(2.0) Loss', 0.20745769)], overall loss: -1.33321106434
Iteration: 496, named_losses: [('ActivationMax Loss', -1.5978125),
 ('L-6.0 Norm Loss', 0.022183422),
 ('TV(2.0) Loss', 0.20871446)], overall loss: -1.36691462994
Iteration: 497, named_losses: [('ActivationMax Loss', -1.6260924),
 ('L-6.0 Norm Loss', 0.022182655),
 ('TV(2.0) Loss', 0.20637175)], overall loss: -1.3975379467
Iteration: 498, named_losses: [('ActivationMax Loss', -1.5617012),
 ('L-6.0 Norm Loss', 0.022183698),
 ('TV(2.0) Loss', 0.2065797)], overall loss: -1.33293783665
Iteration: 499, named_losses: [('ActivationMax Loss', -1.6145768),
 ('L-6.0 Norm Loss', 0.022182487),
 ('TV(2.0) Loss', 0.20579638)], overall loss: -1.38659799099
Iteration: 500, named_losses: [('ActivationMax Loss', -1.6184838),
 ('L-6.0 Norm Loss', 0.022182574),
 ('TV(2.0) Loss', 0.20564632)], overall loss: -1.39065492153
Iteration: 501, named_losses: [('ActivationMax Loss', -1.6224654),
 ('L-6.0 Norm Loss', 0.022181973),
 ('TV(2.0) Loss', 0.20538944)], overall loss: -1.39489388466
Iteration: 502, named_losses: [('ActivationMax Loss', -1.6444221),
 ('L-6.0 Norm Loss', 0.022181571),
 ('TV(2.0) Loss', 0.20537822)], overall loss: -1.41686236858
Iteration: 503, named_losses: [('ActivationMax Loss', -1.6254343),
 ('L-6.0 Norm Loss', 0.022181058),
 ('TV(2.0) Loss', 0.20480673)], overall loss: -1.39844655991
Iteration: 504, named_losses: [('ActivationMax Loss', -1.6223476),
 ('L-6.0 Norm Loss', 0.022180991),
 ('TV(2.0) Loss', 0.20459454)], overall loss: -1.39557206631
Iteration: 505, named_losses: [('ActivationMax Loss', -1.6352942),
 ('L-6.0 Norm Loss', 0.022180751),
 ('TV(2.0) Loss', 0.20454149)], overall loss: -1.40857195854
Iteration: 506, named_losses: [('ActivationMax Loss', -1.6106819),
 ('L-6.0 Norm Loss', 0.022180544),
 ('TV(2.0) Loss', 0.2030514)], overall loss: -1.38544988632
Iteration: 507, named_losses: [('ActivationMax Loss', -1.5913371),
 ('L-6.0 Norm Loss', 0.022180585),
 ('TV(2.0) Loss', 0.20226964)], overall loss: -1.36688685417
Iteration: 508, named_losses: [('ActivationMax Loss', -1.6086257),
 ('L-6.0 Norm Loss', 0.022179959),
 ('TV(2.0) Loss', 0.20445231)], overall loss: -1.38199341297
Iteration: 509, named_losses: [('ActivationMax Loss', -1.5771427),
 ('L-6.0 Norm Loss', 0.022180114),
 ('TV(2.0) Loss', 0.20347488)], overall loss: -1.35148775578
Iteration: 510, named_losses: [('ActivationMax Loss', -1.5197548),
 ('L-6.0 Norm Loss', 0.022180058),
 ('TV(2.0) Loss', 0.2032669)], overall loss: -1.29430782795
Iteration: 511, named_losses: [('ActivationMax Loss', -1.6032826),
 ('L-6.0 Norm Loss', 0.022180457),
 ('TV(2.0) Loss', 0.20382081)], overall loss: -1.37728130817
Iteration: 512, named_losses: [('ActivationMax Loss', -1.6046766),
 ('L-6.0 Norm Loss', 0.022180967),
 ('TV(2.0) Loss', 0.20419826)], overall loss: -1.37829744816
Iteration: 513, named_losses: [('ActivationMax Loss', -1.6387222),
 ('L-6.0 Norm Loss', 0.022180295),
 ('TV(2.0) Loss', 0.20376505)], overall loss: -1.41277682781
Iteration: 514, named_losses: [('ActivationMax Loss', -1.6195947),
 ('L-6.0 Norm Loss', 0.022180051),
 ('TV(2.0) Loss', 0.20237687)], overall loss: -1.39503777027
Iteration: 515, named_losses: [('ActivationMax Loss', -1.6296912),
 ('L-6.0 Norm Loss', 0.022179924),
 ('TV(2.0) Loss', 0.20204139)], overall loss: -1.40546989441
Iteration: 516, named_losses: [('ActivationMax Loss', -1.6155432),
 ('L-6.0 Norm Loss', 0.022178983),
 ('TV(2.0) Loss', 0.20063011)], overall loss: -1.39273416996
Iteration: 517, named_losses: [('ActivationMax Loss', -1.5901132),
 ('L-6.0 Norm Loss', 0.022179693),
 ('TV(2.0) Loss', 0.20095542)], overall loss: -1.36697804928
Iteration: 518, named_losses: [('ActivationMax Loss', -1.6238875),
 ('L-6.0 Norm Loss', 0.022177918),
 ('TV(2.0) Loss', 0.19955617)], overall loss: -1.40215349197
Iteration: 519, named_losses: [('ActivationMax Loss', -1.5914725),
 ('L-6.0 Norm Loss', 0.022179775),
 ('TV(2.0) Loss', 0.19974262)], overall loss: -1.36955022812
Iteration: 520, named_losses: [('ActivationMax Loss', -1.6193686),
 ('L-6.0 Norm Loss', 0.022179086),
 ('TV(2.0) Loss', 0.2015114)], overall loss: -1.39567804337
Iteration: 521, named_losses: [('ActivationMax Loss', -1.5550264),
 ('L-6.0 Norm Loss', 0.022178471),
 ('TV(2.0) Loss', 0.20071343)], overall loss: -1.33213448524
Iteration: 522, named_losses: [('ActivationMax Loss', -1.6162014),
 ('L-6.0 Norm Loss', 0.022179365),
 ('TV(2.0) Loss', 0.2007764)], overall loss: -1.39324569702
Iteration: 523, named_losses: [('ActivationMax Loss', -1.5707712),
 ('L-6.0 Norm Loss', 0.022177428),
 ('TV(2.0) Loss', 0.20012693)], overall loss: -1.34846687317
Iteration: 524, named_losses: [('ActivationMax Loss', -1.6028523),
 ('L-6.0 Norm Loss', 0.022178762),
 ('TV(2.0) Loss', 0.20026797)], overall loss: -1.38040566444
Iteration: 525, named_losses: [('ActivationMax Loss', -1.5869718),
 ('L-6.0 Norm Loss', 0.022178173),
 ('TV(2.0) Loss', 0.19931829)], overall loss: -1.36547529697
Iteration: 526, named_losses: [('ActivationMax Loss', -1.540535),
 ('L-6.0 Norm Loss', 0.022178445),
 ('TV(2.0) Loss', 0.20099279)], overall loss: -1.31736373901
Iteration: 527, named_losses: [('ActivationMax Loss', -1.5573529),
 ('L-6.0 Norm Loss', 0.02217795),
 ('TV(2.0) Loss', 0.20124228)], overall loss: -1.33393263817
Iteration: 528, named_losses: [('ActivationMax Loss', -1.5777618),
 ('L-6.0 Norm Loss', 0.022178117),
 ('TV(2.0) Loss', 0.20215058)], overall loss: -1.35343301296
Iteration: 529, named_losses: [('ActivationMax Loss', -1.5974979),
 ('L-6.0 Norm Loss', 0.022179147),
 ('TV(2.0) Loss', 0.20204811)], overall loss: -1.37327075005
Iteration: 530, named_losses: [('ActivationMax Loss', -1.6102649),
 ('L-6.0 Norm Loss', 0.022177428),
 ('TV(2.0) Loss', 0.20197052)], overall loss: -1.38611698151
Iteration: 531, named_losses: [('ActivationMax Loss', -1.5690913),
 ('L-6.0 Norm Loss', 0.022178544),
 ('TV(2.0) Loss', 0.20193115)], overall loss: -1.34498167038
Iteration: 532, named_losses: [('ActivationMax Loss', -1.5162628),
 ('L-6.0 Norm Loss', 0.022178387),
 ('TV(2.0) Loss', 0.20099367)], overall loss: -1.2930907011
Iteration: 533, named_losses: [('ActivationMax Loss', -1.5877639),
 ('L-6.0 Norm Loss', 0.022178613),
 ('TV(2.0) Loss', 0.20228203)], overall loss: -1.36330318451
Iteration: 534, named_losses: [('ActivationMax Loss', -1.6099899),
 ('L-6.0 Norm Loss', 0.022177396),
 ('TV(2.0) Loss', 0.20272394)], overall loss: -1.38508856297
Iteration: 535, named_losses: [('ActivationMax Loss', -1.6236895),
 ('L-6.0 Norm Loss', 0.022177838),
 ('TV(2.0) Loss', 0.20145261)], overall loss: -1.40005910397
Iteration: 536, named_losses: [('ActivationMax Loss', -1.655543),
 ('L-6.0 Norm Loss', 0.022177201),
 ('TV(2.0) Loss', 0.20012681)], overall loss: -1.43323898315
Iteration: 537, named_losses: [('ActivationMax Loss', -1.5598451),
 ('L-6.0 Norm Loss', 0.022176564),
 ('TV(2.0) Loss', 0.19894411)], overall loss: -1.33872437477
Iteration: 538, named_losses: [('ActivationMax Loss', -1.600184),
 ('L-6.0 Norm Loss', 0.022176234),
 ('TV(2.0) Loss', 0.19882028)], overall loss: -1.37918746471
Iteration: 539, named_losses: [('ActivationMax Loss', -1.5859326),
 ('L-6.0 Norm Loss', 0.022177551),
 ('TV(2.0) Loss', 0.19979317)], overall loss: -1.36396181583
Iteration: 540, named_losses: [('ActivationMax Loss', -1.5721598),
 ('L-6.0 Norm Loss', 0.022176441),
 ('TV(2.0) Loss', 0.19962934)], overall loss: -1.35035407543
Iteration: 541, named_losses: [('ActivationMax Loss', -1.5742102),
 ('L-6.0 Norm Loss', 0.022176247),
 ('TV(2.0) Loss', 0.20007604)], overall loss: -1.351957798
Iteration: 542, named_losses: [('ActivationMax Loss', -1.591714),
 ('L-6.0 Norm Loss', 0.02217654),
 ('TV(2.0) Loss', 0.19995385)], overall loss: -1.36958360672
Iteration: 543, named_losses: [('ActivationMax Loss', -1.5833199),
 ('L-6.0 Norm Loss', 0.022176495),
 ('TV(2.0) Loss', 0.20012392)], overall loss: -1.36101949215
Iteration: 544, named_losses: [('ActivationMax Loss', -1.6054509),
 ('L-6.0 Norm Loss', 0.022178022),
 ('TV(2.0) Loss', 0.20095485)], overall loss: -1.38231801987
Iteration: 545, named_losses: [('ActivationMax Loss', -1.5798113),
 ('L-6.0 Norm Loss', 0.0221771),
 ('TV(2.0) Loss', 0.2019095)], overall loss: -1.35572469234
Iteration: 546, named_losses: [('ActivationMax Loss', -1.6073954),
 ('L-6.0 Norm Loss', 0.022177873),
 ('TV(2.0) Loss', 0.20184514)], overall loss: -1.38337242603
Iteration: 547, named_losses: [('ActivationMax Loss', -1.633441),
 ('L-6.0 Norm Loss', 0.022177495),
 ('TV(2.0) Loss', 0.2017144)], overall loss: -1.40954911709
Iteration: 548, named_losses: [('ActivationMax Loss', -1.5925781),
 ('L-6.0 Norm Loss', 0.022177285),
 ('TV(2.0) Loss', 0.20010868)], overall loss: -1.37029206753
Iteration: 549, named_losses: [('ActivationMax Loss', -1.6253009),
 ('L-6.0 Norm Loss', 0.02217745),
 ('TV(2.0) Loss', 0.20187242)], overall loss: -1.40125095844
Iteration: 550, named_losses: [('ActivationMax Loss', -1.594278),
 ('L-6.0 Norm Loss', 0.022176897),
 ('TV(2.0) Loss', 0.2002569)], overall loss: -1.37184417248
Iteration: 551, named_losses: [('ActivationMax Loss', -1.5927914),
 ('L-6.0 Norm Loss', 0.022175869),
 ('TV(2.0) Loss', 0.20100623)], overall loss: -1.36960935593
Iteration: 552, named_losses: [('ActivationMax Loss', -1.6239011),
 ('L-6.0 Norm Loss', 0.022175835),
 ('TV(2.0) Loss', 0.20023586)], overall loss: -1.40148949623
Iteration: 553, named_losses: [('ActivationMax Loss', -1.5779305),
 ('L-6.0 Norm Loss', 0.022175509),
 ('TV(2.0) Loss', 0.19892913)], overall loss: -1.35682582855
Iteration: 554, named_losses: [('ActivationMax Loss', -1.5963206),
 ('L-6.0 Norm Loss', 0.022174634),
 ('TV(2.0) Loss', 0.19888599)], overall loss: -1.37525999546
Iteration: 555, named_losses: [('ActivationMax Loss', -1.5877131),
 ('L-6.0 Norm Loss', 0.022175295),
 ('TV(2.0) Loss', 0.1982028)], overall loss: -1.36733496189
Iteration: 556, named_losses: [('ActivationMax Loss', -1.5945059),
 ('L-6.0 Norm Loss', 0.022175215),
 ('TV(2.0) Loss', 0.19873907)], overall loss: -1.37359166145
Iteration: 557, named_losses: [('ActivationMax Loss', -1.6188293),
 ('L-6.0 Norm Loss', 0.022173814),
 ('TV(2.0) Loss', 0.1985725)], overall loss: -1.39808297157
Iteration: 558, named_losses: [('ActivationMax Loss', -1.5973917),
 ('L-6.0 Norm Loss', 0.022174073),
 ('TV(2.0) Loss', 0.19857097)], overall loss: -1.37664663792
Iteration: 559, named_losses: [('ActivationMax Loss', -1.6048939),
 ('L-6.0 Norm Loss', 0.022174148),
 ('TV(2.0) Loss', 0.19895315)], overall loss: -1.38376665115
Iteration: 560, named_losses: [('ActivationMax Loss', -1.5583545),
 ('L-6.0 Norm Loss', 0.022173658),
 ('TV(2.0) Loss', 0.19965585)], overall loss: -1.33652496338
Iteration: 561, named_losses: [('ActivationMax Loss', -1.5743392),
 ('L-6.0 Norm Loss', 0.02217385),
 ('TV(2.0) Loss', 0.20080955)], overall loss: -1.35135567188
Iteration: 562, named_losses: [('ActivationMax Loss', -1.6080071),
 ('L-6.0 Norm Loss', 0.022173917),
 ('TV(2.0) Loss', 0.20170835)], overall loss: -1.38412487507
Iteration: 563, named_losses: [('ActivationMax Loss', -1.5818859),
 ('L-6.0 Norm Loss', 0.022173963),
 ('TV(2.0) Loss', 0.20195767)], overall loss: -1.3577542305
Iteration: 564, named_losses: [('ActivationMax Loss', -1.5986316),
 ('L-6.0 Norm Loss', 0.022174791),
 ('TV(2.0) Loss', 0.20328777)], overall loss: -1.37316906452
Iteration: 565, named_losses: [('ActivationMax Loss', -1.6075033),
 ('L-6.0 Norm Loss', 0.022174677),
 ('TV(2.0) Loss', 0.20311716)], overall loss: -1.38221144676
Iteration: 566, named_losses: [('ActivationMax Loss', -1.5767598),
 ('L-6.0 Norm Loss', 0.022174083),
 ('TV(2.0) Loss', 0.20273498)], overall loss: -1.35185074806
Iteration: 567, named_losses: [('ActivationMax Loss', -1.5936071),
 ('L-6.0 Norm Loss', 0.022174772),
 ('TV(2.0) Loss', 0.20274404)], overall loss: -1.36868834496
Iteration: 568, named_losses: [('ActivationMax Loss', -1.5669281),
 ('L-6.0 Norm Loss', 0.022173766),
 ('TV(2.0) Loss', 0.20333414)], overall loss: -1.34142029285
Iteration: 569, named_losses: [('ActivationMax Loss', -1.5695062),
 ('L-6.0 Norm Loss', 0.022174949),
 ('TV(2.0) Loss', 0.20369348)], overall loss: -1.34363770485
Iteration: 570, named_losses: [('ActivationMax Loss', -1.6104016),
 ('L-6.0 Norm Loss', 0.022175424),
 ('TV(2.0) Loss', 0.20422323)], overall loss: -1.38400292397
Iteration: 571, named_losses: [('ActivationMax Loss', -1.5605576),
 ('L-6.0 Norm Loss', 0.022174314),
 ('TV(2.0) Loss', 0.20470253)], overall loss: -1.33368074894
Iteration: 572, named_losses: [('ActivationMax Loss', -1.5931562),
 ('L-6.0 Norm Loss', 0.022175211),
 ('TV(2.0) Loss', 0.2051727)], overall loss: -1.36580836773
Iteration: 573, named_losses: [('ActivationMax Loss', -1.5303992),
 ('L-6.0 Norm Loss', 0.022174604),
 ('TV(2.0) Loss', 0.20417939)], overall loss: -1.30404520035
Iteration: 574, named_losses: [('ActivationMax Loss', -1.5882432),
 ('L-6.0 Norm Loss', 0.02217498),
 ('TV(2.0) Loss', 0.20590159)], overall loss: -1.36016666889
Iteration: 575, named_losses: [('ActivationMax Loss', -1.5581656),
 ('L-6.0 Norm Loss', 0.022175167),
 ('TV(2.0) Loss', 0.20632376)], overall loss: -1.32966661453
Iteration: 576, named_losses: [('ActivationMax Loss', -1.6064214),
 ('L-6.0 Norm Loss', 0.02217507),
 ('TV(2.0) Loss', 0.20608248)], overall loss: -1.37816381454
Iteration: 577, named_losses: [('ActivationMax Loss', -1.5528492),
 ('L-6.0 Norm Loss', 0.022175053),
 ('TV(2.0) Loss', 0.20374148)], overall loss: -1.32693266869
Iteration: 578, named_losses: [('ActivationMax Loss', -1.5889754),
 ('L-6.0 Norm Loss', 0.022174593),
 ('TV(2.0) Loss', 0.20459215)], overall loss: -1.36220872402
Iteration: 579, named_losses: [('ActivationMax Loss', -1.6020467),
 ('L-6.0 Norm Loss', 0.022174735),
 ('TV(2.0) Loss', 0.20378757)], overall loss: -1.37608444691
Iteration: 580, named_losses: [('ActivationMax Loss', -1.5884963),
 ('L-6.0 Norm Loss', 0.022174921),
 ('TV(2.0) Loss', 0.20299345)], overall loss: -1.36332798004
Iteration: 581, named_losses: [('ActivationMax Loss', -1.562241),
 ('L-6.0 Norm Loss', 0.022175148),
 ('TV(2.0) Loss', 0.20209165)], overall loss: -1.3379740715
Iteration: 582, named_losses: [('ActivationMax Loss', -1.6149722),
 ('L-6.0 Norm Loss', 0.022174688),
 ('TV(2.0) Loss', 0.20284478)], overall loss: -1.38995277882
Iteration: 583, named_losses: [('ActivationMax Loss', -1.5997977),
 ('L-6.0 Norm Loss', 0.022174967),
 ('TV(2.0) Loss', 0.20232242)], overall loss: -1.37530040741
Iteration: 584, named_losses: [('ActivationMax Loss', -1.5838821),
 ('L-6.0 Norm Loss', 0.022174638),
 ('TV(2.0) Loss', 0.20296748)], overall loss: -1.35873997211
Iteration: 585, named_losses: [('ActivationMax Loss', -1.5506269),
 ('L-6.0 Norm Loss', 0.022173718),
 ('TV(2.0) Loss', 0.20368749)], overall loss: -1.32476568222
Iteration: 586, named_losses: [('ActivationMax Loss', -1.5819622),
 ('L-6.0 Norm Loss', 0.022174975),
 ('TV(2.0) Loss', 0.20324779)], overall loss: -1.35653948784
Iteration: 587, named_losses: [('ActivationMax Loss', -1.5636542),
 ('L-6.0 Norm Loss', 0.022173254),
 ('TV(2.0) Loss', 0.20371929)], overall loss: -1.33776164055
Iteration: 588, named_losses: [('ActivationMax Loss', -1.6340921),
 ('L-6.0 Norm Loss', 0.022173632),
 ('TV(2.0) Loss', 0.20314604)], overall loss: -1.40877246857
Iteration: 589, named_losses: [('ActivationMax Loss', -1.5234272),
 ('L-6.0 Norm Loss', 0.022173826),
 ('TV(2.0) Loss', 0.20285)], overall loss: -1.2984033823
Iteration: 590, named_losses: [('ActivationMax Loss', -1.5680223),
 ('L-6.0 Norm Loss', 0.022173569),
 ('TV(2.0) Loss', 0.20284954)], overall loss: -1.34299921989
Iteration: 591, named_losses: [('ActivationMax Loss', -1.6195939),
 ('L-6.0 Norm Loss', 0.022173587),
 ('TV(2.0) Loss', 0.20273715)], overall loss: -1.39468312263
Iteration: 592, named_losses: [('ActivationMax Loss', -1.6187344),
 ('L-6.0 Norm Loss', 0.022173703),
 ('TV(2.0) Loss', 0.20216519)], overall loss: -1.39439558983
Iteration: 593, named_losses: [('ActivationMax Loss', -1.5887249),
 ('L-6.0 Norm Loss', 0.022174211),
 ('TV(2.0) Loss', 0.20329407)], overall loss: -1.36325657368
Iteration: 594, named_losses: [('ActivationMax Loss', -1.5738724),
 ('L-6.0 Norm Loss', 0.022173632),
 ('TV(2.0) Loss', 0.20303516)], overall loss: -1.34866368771
Iteration: 595, named_losses: [('ActivationMax Loss', -1.5733333),
 ('L-6.0 Norm Loss', 0.022172688),
 ('TV(2.0) Loss', 0.20270079)], overall loss: -1.34845972061
Iteration: 596, named_losses: [('ActivationMax Loss', -1.6132756),
 ('L-6.0 Norm Loss', 0.022172123),
 ('TV(2.0) Loss', 0.2020757)], overall loss: -1.38902783394
Iteration: 597, named_losses: [('ActivationMax Loss', -1.6260421),
 ('L-6.0 Norm Loss', 0.022172932),
 ('TV(2.0) Loss', 0.20145085)], overall loss: -1.40241837502
Iteration: 598, named_losses: [('ActivationMax Loss', -1.5884815),
 ('L-6.0 Norm Loss', 0.022172663),
 ('TV(2.0) Loss', 0.20078029)], overall loss: -1.36552858353
Iteration: 599, named_losses: [('ActivationMax Loss', -1.6200135),
 ('L-6.0 Norm Loss', 0.022172492),
 ('TV(2.0) Loss', 0.20053193)], overall loss: -1.39730906487
Iteration: 600, named_losses: [('ActivationMax Loss', -1.6174238),
 ('L-6.0 Norm Loss', 0.022171721),
 ('TV(2.0) Loss', 0.19971016)], overall loss: -1.39554190636
Iteration: 601, named_losses: [('ActivationMax Loss', -1.6032053),
 ('L-6.0 Norm Loss', 0.022171929),
 ('TV(2.0) Loss', 0.19958729)], overall loss: -1.38144612312
Iteration: 602, named_losses: [('ActivationMax Loss', -1.6468152),
 ('L-6.0 Norm Loss', 0.022171317),
 ('TV(2.0) Loss', 0.20019159)], overall loss: -1.42445230484
Iteration: 603, named_losses: [('ActivationMax Loss', -1.631712),
 ('L-6.0 Norm Loss', 0.022171354),
 ('TV(2.0) Loss', 0.19810696)], overall loss: -1.41143357754
Iteration: 604, named_losses: [('ActivationMax Loss', -1.6127346),
 ('L-6.0 Norm Loss', 0.022170618),
 ('TV(2.0) Loss', 0.19862805)], overall loss: -1.39193582535
Iteration: 605, named_losses: [('ActivationMax Loss', -1.5887976),
 ('L-6.0 Norm Loss', 0.022170175),
 ('TV(2.0) Loss', 0.1984228)], overall loss: -1.36820459366
Iteration: 606, named_losses: [('ActivationMax Loss', -1.6173604),
 ('L-6.0 Norm Loss', 0.022170579),
 ('TV(2.0) Loss', 0.19924684)], overall loss: -1.39594292641
Iteration: 607, named_losses: [('ActivationMax Loss', -1.6123778),
 ('L-6.0 Norm Loss', 0.022170324),
 ('TV(2.0) Loss', 0.19919403)], overall loss: -1.39101338387
Iteration: 608, named_losses: [('ActivationMax Loss', -1.6158817),
 ('L-6.0 Norm Loss', 0.022170093),
 ('TV(2.0) Loss', 0.19917372)], overall loss: -1.39453792572
Iteration: 609, named_losses: [('ActivationMax Loss', -1.6132767),
 ('L-6.0 Norm Loss', 0.022169545),
 ('TV(2.0) Loss', 0.19890171)], overall loss: -1.39220547676
Iteration: 610, named_losses: [('ActivationMax Loss', -1.5721384),
 ('L-6.0 Norm Loss', 0.022169728),
 ('TV(2.0) Loss', 0.1983525)], overall loss: -1.35161626339
Iteration: 611, named_losses: [('ActivationMax Loss', -1.6488377),
 ('L-6.0 Norm Loss', 0.022169461),
 ('TV(2.0) Loss', 0.19844736)], overall loss: -1.42822086811
Iteration: 612, named_losses: [('ActivationMax Loss', -1.6282811),
 ('L-6.0 Norm Loss', 0.022169268),
 ('TV(2.0) Loss', 0.19708151)], overall loss: -1.40903043747
Iteration: 613, named_losses: [('ActivationMax Loss', -1.6067367),
 ('L-6.0 Norm Loss', 0.022168495),
 ('TV(2.0) Loss', 0.19773008)], overall loss: -1.3868380785
Iteration: 614, named_losses: [('ActivationMax Loss', -1.5749005),
 ('L-6.0 Norm Loss', 0.022168182),
 ('TV(2.0) Loss', 0.19625063)], overall loss: -1.35648167133
Iteration: 615, named_losses: [('ActivationMax Loss', -1.5855467),
 ('L-6.0 Norm Loss', 0.022168418),
 ('TV(2.0) Loss', 0.19630918)], overall loss: -1.36706912518
Iteration: 616, named_losses: [('ActivationMax Loss', -1.6057241),
 ('L-6.0 Norm Loss', 0.02216753),
 ('TV(2.0) Loss', 0.19770719)], overall loss: -1.38584935665
Iteration: 617, named_losses: [('ActivationMax Loss', -1.614826),
 ('L-6.0 Norm Loss', 0.022168141),
 ('TV(2.0) Loss', 0.19686708)], overall loss: -1.39579069614
Iteration: 618, named_losses: [('ActivationMax Loss', -1.6096195),
 ('L-6.0 Norm Loss', 0.022168944),
 ('TV(2.0) Loss', 0.19708663)], overall loss: -1.39036393166
Iteration: 619, named_losses: [('ActivationMax Loss', -1.6427989),
 ('L-6.0 Norm Loss', 0.022168739),
 ('TV(2.0) Loss', 0.19828758)], overall loss: -1.42234253883
Iteration: 620, named_losses: [('ActivationMax Loss', -1.596131),
 ('L-6.0 Norm Loss', 0.022168124),
 ('TV(2.0) Loss', 0.19712697)], overall loss: -1.37683582306
Iteration: 621, named_losses: [('ActivationMax Loss', -1.5453783),
 ('L-6.0 Norm Loss', 0.022168137),
 ('TV(2.0) Loss', 0.19811678)], overall loss: -1.32509338856
Iteration: 622, named_losses: [('ActivationMax Loss', -1.6129291),
 ('L-6.0 Norm Loss', 0.022169009),
 ('TV(2.0) Loss', 0.19954078)], overall loss: -1.39121937752
Iteration: 623, named_losses: [('ActivationMax Loss', -1.5476658),
 ('L-6.0 Norm Loss', 0.022168726),
 ('TV(2.0) Loss', 0.19989605)], overall loss: -1.32560098171
Iteration: 624, named_losses: [('ActivationMax Loss', -1.5295523),
 ('L-6.0 Norm Loss', 0.02216894),
 ('TV(2.0) Loss', 0.20147282)], overall loss: -1.30591058731
Iteration: 625, named_losses: [('ActivationMax Loss', -1.595606),
 ('L-6.0 Norm Loss', 0.022169717),
 ('TV(2.0) Loss', 0.20174967)], overall loss: -1.3716865778
Iteration: 626, named_losses: [('ActivationMax Loss', -1.5478518),
 ('L-6.0 Norm Loss', 0.022169398),
 ('TV(2.0) Loss', 0.20305301)], overall loss: -1.32262945175
Iteration: 627, named_losses: [('ActivationMax Loss', -1.6106122),
 ('L-6.0 Norm Loss', 0.022168599),
 ('TV(2.0) Loss', 0.20279014)], overall loss: -1.38565337658
Iteration: 628, named_losses: [('ActivationMax Loss', -1.5756954),
 ('L-6.0 Norm Loss', 0.022169219),
 ('TV(2.0) Loss', 0.20266944)], overall loss: -1.35085678101
Iteration: 629, named_losses: [('ActivationMax Loss', -1.591676),
 ('L-6.0 Norm Loss', 0.022169624),
 ('TV(2.0) Loss', 0.20260587)], overall loss: -1.36690056324
Iteration: 630, named_losses: [('ActivationMax Loss', -1.6335487),
 ('L-6.0 Norm Loss', 0.022169687),
 ('TV(2.0) Loss', 0.20295437)], overall loss: -1.40842461586
Iteration: 631, named_losses: [('ActivationMax Loss', -1.5585313),
 ('L-6.0 Norm Loss', 0.022168629),
 ('TV(2.0) Loss', 0.20156042)], overall loss: -1.33480226994
Iteration: 632, named_losses: [('ActivationMax Loss', -1.6060672),
 ('L-6.0 Norm Loss', 0.022168718),
 ('TV(2.0) Loss', 0.20263156)], overall loss: -1.38126683235
Iteration: 633, named_losses: [('ActivationMax Loss', -1.5796468),
 ('L-6.0 Norm Loss', 0.022168428),
 ('TV(2.0) Loss', 0.20158674)], overall loss: -1.35589170456
Iteration: 634, named_losses: [('ActivationMax Loss', -1.6246265),
 ('L-6.0 Norm Loss', 0.022168044),
 ('TV(2.0) Loss', 0.20189916)], overall loss: -1.40055930614
Iteration: 635, named_losses: [('ActivationMax Loss', -1.5884703),
 ('L-6.0 Norm Loss', 0.022167068),
 ('TV(2.0) Loss', 0.19986902)], overall loss: -1.3664342165
Iteration: 636, named_losses: [('ActivationMax Loss', -1.5986151),
 ('L-6.0 Norm Loss', 0.022167347),
 ('TV(2.0) Loss', 0.19956964)], overall loss: -1.37687802315
Iteration: 637, named_losses: [('ActivationMax Loss', -1.6060963),
 ('L-6.0 Norm Loss', 0.022167094),
 ('TV(2.0) Loss', 0.1986679)], overall loss: -1.38526129723
Iteration: 638, named_losses: [('ActivationMax Loss', -1.5560635),
 ('L-6.0 Norm Loss', 0.022167517),
 ('TV(2.0) Loss', 0.19908564)], overall loss: -1.33481037617
Iteration: 639, named_losses: [('ActivationMax Loss', -1.6094254),
 ('L-6.0 Norm Loss', 0.022167845),
 ('TV(2.0) Loss', 0.20021072)], overall loss: -1.38704693317
Iteration: 640, named_losses: [('ActivationMax Loss', -1.5311054),
 ('L-6.0 Norm Loss', 0.022167217),
 ('TV(2.0) Loss', 0.20038134)], overall loss: -1.30855679512
Iteration: 641, named_losses: [('ActivationMax Loss', -1.5480392),
 ('L-6.0 Norm Loss', 0.022167362),
 ('TV(2.0) Loss', 0.20173715)], overall loss: -1.32413470745
Iteration: 642, named_losses: [('ActivationMax Loss', -1.6036434),
 ('L-6.0 Norm Loss', 0.022167545),
 ('TV(2.0) Loss', 0.20275334)], overall loss: -1.37872254848
Iteration: 643, named_losses: [('ActivationMax Loss', -1.5648046),
 ('L-6.0 Norm Loss', 0.022167146),
 ('TV(2.0) Loss', 0.20289321)], overall loss: -1.33974409103
Iteration: 644, named_losses: [('ActivationMax Loss', -1.5724629),
 ('L-6.0 Norm Loss', 0.022168033),
 ('TV(2.0) Loss', 0.20439178)], overall loss: -1.34590315819
Iteration: 645, named_losses: [('ActivationMax Loss', -1.5906467),
 ('L-6.0 Norm Loss', 0.022168251),
 ('TV(2.0) Loss', 0.20354587)], overall loss: -1.36493253708
Iteration: 646, named_losses: [('ActivationMax Loss', -1.5673192),
 ('L-6.0 Norm Loss', 0.022167873),
 ('TV(2.0) Loss', 0.20488755)], overall loss: -1.34026372433
Iteration: 647, named_losses: [('ActivationMax Loss', -1.6024828),
 ('L-6.0 Norm Loss', 0.022166986),
 ('TV(2.0) Loss', 0.20381729)], overall loss: -1.37649857998
Iteration: 648, named_losses: [('ActivationMax Loss', -1.5997853),
 ('L-6.0 Norm Loss', 0.022165801),
 ('TV(2.0) Loss', 0.20423844)], overall loss: -1.37338113785
Iteration: 649, named_losses: [('ActivationMax Loss', -1.5803052),
 ('L-6.0 Norm Loss', 0.02216626),
 ('TV(2.0) Loss', 0.20349039)], overall loss: -1.35464859009
Iteration: 650, named_losses: [('ActivationMax Loss', -1.5289731),
 ('L-6.0 Norm Loss', 0.022165792),
 ('TV(2.0) Loss', 0.20380796)], overall loss: -1.30299937725
Iteration: 651, named_losses: [('ActivationMax Loss', -1.5834088),
 ('L-6.0 Norm Loss', 0.022166343),
 ('TV(2.0) Loss', 0.2031123)], overall loss: -1.3581302166
Iteration: 652, named_losses: [('ActivationMax Loss', -1.5967059),
 ('L-6.0 Norm Loss', 0.022165978),
 ('TV(2.0) Loss', 0.20283076)], overall loss: -1.37170910835
Iteration: 653, named_losses: [('ActivationMax Loss', -1.5838561),
 ('L-6.0 Norm Loss', 0.022166895),
 ('TV(2.0) Loss', 0.20350808)], overall loss: -1.35818123817
Iteration: 654, named_losses: [('ActivationMax Loss', -1.6030142),
 ('L-6.0 Norm Loss', 0.02216717),
 ('TV(2.0) Loss', 0.20425279)], overall loss: -1.37659418583
Iteration: 655, named_losses: [('ActivationMax Loss', -1.5777693),
 ('L-6.0 Norm Loss', 0.022166306),
 ('TV(2.0) Loss', 0.20358619)], overall loss: -1.3520168066
Iteration: 656, named_losses: [('ActivationMax Loss', -1.613458),
 ('L-6.0 Norm Loss', 0.02216538),
 ('TV(2.0) Loss', 0.20426582)], overall loss: -1.3870267868
Iteration: 657, named_losses: [('ActivationMax Loss', -1.6065669),
 ('L-6.0 Norm Loss', 0.022166716),
 ('TV(2.0) Loss', 0.20229724)], overall loss: -1.38210296631
Iteration: 658, named_losses: [('ActivationMax Loss', -1.6180831),
 ('L-6.0 Norm Loss', 0.022165859),
 ('TV(2.0) Loss', 0.20135196)], overall loss: -1.39456522465
Iteration: 659, named_losses: [('ActivationMax Loss', -1.5842617),
 ('L-6.0 Norm Loss', 0.022164669),
 ('TV(2.0) Loss', 0.2022752)], overall loss: -1.35982179642
Iteration: 660, named_losses: [('ActivationMax Loss', -1.6037147),
 ('L-6.0 Norm Loss', 0.022165831),
 ('TV(2.0) Loss', 0.20310031)], overall loss: -1.37844860554
Iteration: 661, named_losses: [('ActivationMax Loss', -1.6206232),
 ('L-6.0 Norm Loss', 0.022165831),
 ('TV(2.0) Loss', 0.20368366)], overall loss: -1.3947738409
Iteration: 662, named_losses: [('ActivationMax Loss', -1.5635123),
 ('L-6.0 Norm Loss', 0.022164771),
 ('TV(2.0) Loss', 0.20232938)], overall loss: -1.33901810646
Iteration: 663, named_losses: [('ActivationMax Loss', -1.6447569),
 ('L-6.0 Norm Loss', 0.022164583),
 ('TV(2.0) Loss', 0.20247467)], overall loss: -1.42011761665
Iteration: 664, named_losses: [('ActivationMax Loss', -1.5781593),
 ('L-6.0 Norm Loss', 0.022163909),
 ('TV(2.0) Loss', 0.20031829)], overall loss: -1.35567712784
Iteration: 665, named_losses: [('ActivationMax Loss', -1.6248953),
 ('L-6.0 Norm Loss', 0.022163473),
 ('TV(2.0) Loss', 0.20003718)], overall loss: -1.40269470215
Iteration: 666, named_losses: [('ActivationMax Loss', -1.5936136),
 ('L-6.0 Norm Loss', 0.02216281),
 ('TV(2.0) Loss', 0.19991393)], overall loss: -1.37153685093
Iteration: 667, named_losses: [('ActivationMax Loss', -1.6012053),
 ('L-6.0 Norm Loss', 0.02216243),
 ('TV(2.0) Loss', 0.20074669)], overall loss: -1.37829625607
Iteration: 668, named_losses: [('ActivationMax Loss', -1.5797275),
 ('L-6.0 Norm Loss', 0.022163102),
 ('TV(2.0) Loss', 0.19919007)], overall loss: -1.35837435722
Iteration: 669, named_losses: [('ActivationMax Loss', -1.5975498),
 ('L-6.0 Norm Loss', 0.022161774),
 ('TV(2.0) Loss', 0.20016153)], overall loss: -1.37522649765
Iteration: 670, named_losses: [('ActivationMax Loss', -1.6048779),
 ('L-6.0 Norm Loss', 0.022162944),
 ('TV(2.0) Loss', 0.2001929)], overall loss: -1.38252210617
Iteration: 671, named_losses: [('ActivationMax Loss', -1.6309967),
 ('L-6.0 Norm Loss', 0.022162411),
 ('TV(2.0) Loss', 0.19977035)], overall loss: -1.40906393528
Iteration: 672, named_losses: [('ActivationMax Loss', -1.5853665),
 ('L-6.0 Norm Loss', 0.022162691),
 ('TV(2.0) Loss', 0.19894853)], overall loss: -1.3642553091
Iteration: 673, named_losses: [('ActivationMax Loss', -1.611465),
 ('L-6.0 Norm Loss', 0.022162518),
 ('TV(2.0) Loss', 0.19887628)], overall loss: -1.39042615891
Iteration: 674, named_losses: [('ActivationMax Loss', -1.5534422),
 ('L-6.0 Norm Loss', 0.02216229),
 ('TV(2.0) Loss', 0.19906956)], overall loss: -1.33221030235
Iteration: 675, named_losses: [('ActivationMax Loss', -1.5846395),
 ('L-6.0 Norm Loss', 0.022160988),
 ('TV(2.0) Loss', 0.2010338)], overall loss: -1.36144471169
Iteration: 676, named_losses: [('ActivationMax Loss', -1.6272972),
 ('L-6.0 Norm Loss', 0.02216243),
 ('TV(2.0) Loss', 0.20068373)], overall loss: -1.40445101261
Iteration: 677, named_losses: [('ActivationMax Loss', -1.5809389),
 ('L-6.0 Norm Loss', 0.022162208),
 ('TV(2.0) Loss', 0.20055982)], overall loss: -1.35821688175
Iteration: 678, named_losses: [('ActivationMax Loss', -1.6199286),
 ('L-6.0 Norm Loss', 0.02216173),
 ('TV(2.0) Loss', 0.20089749)], overall loss: -1.39686942101
Iteration: 679, named_losses: [('ActivationMax Loss', -1.6134052),
 ('L-6.0 Norm Loss', 0.022162046),
 ('TV(2.0) Loss', 0.20051654)], overall loss: -1.39072656631
Iteration: 680, named_losses: [('ActivationMax Loss', -1.5896634),
 ('L-6.0 Norm Loss', 0.022161279),
 ('TV(2.0) Loss', 0.20044006)], overall loss: -1.36706209183
Iteration: 681, named_losses: [('ActivationMax Loss', -1.5827308),
 ('L-6.0 Norm Loss', 0.022161651),
 ('TV(2.0) Loss', 0.20081761)], overall loss: -1.35975158215
Iteration: 682, named_losses: [('ActivationMax Loss', -1.5981946),
 ('L-6.0 Norm Loss', 0.022162713),
 ('TV(2.0) Loss', 0.20162559)], overall loss: -1.37440633774
Iteration: 683, named_losses: [('ActivationMax Loss', -1.5463667),
 ('L-6.0 Norm Loss', 0.022161396),
 ('TV(2.0) Loss', 0.20195875)], overall loss: -1.32224655151
Iteration: 684, named_losses: [('ActivationMax Loss', -1.59527),
 ('L-6.0 Norm Loss', 0.022163121),
 ('TV(2.0) Loss', 0.2036169)], overall loss: -1.36949002743
Iteration: 685, named_losses: [('ActivationMax Loss', -1.6256016),
 ('L-6.0 Norm Loss', 0.022162197),
 ('TV(2.0) Loss', 0.20202474)], overall loss: -1.40141475201
Iteration: 686, named_losses: [('ActivationMax Loss', -1.6100305),
 ('L-6.0 Norm Loss', 0.022162504),
 ('TV(2.0) Loss', 0.20054355)], overall loss: -1.3873244524
Iteration: 687, named_losses: [('ActivationMax Loss', -1.6053948),
 ('L-6.0 Norm Loss', 0.022160141),
 ('TV(2.0) Loss', 0.20084158)], overall loss: -1.38239312172
Iteration: 688, named_losses: [('ActivationMax Loss', -1.6178244),
 ('L-6.0 Norm Loss', 0.022160258),
 ('TV(2.0) Loss', 0.20103565)], overall loss: -1.39462852478
Iteration: 689, named_losses: [('ActivationMax Loss', -1.5933297),
 ('L-6.0 Norm Loss', 0.022159271),
 ('TV(2.0) Loss', 0.20060405)], overall loss: -1.3705663681
Iteration: 690, named_losses: [('ActivationMax Loss', -1.5967569),
 ('L-6.0 Norm Loss', 0.022159059),
 ('TV(2.0) Loss', 0.19936691)], overall loss: -1.37523090839
Iteration: 691, named_losses: [('ActivationMax Loss', -1.6222019),
 ('L-6.0 Norm Loss', 0.022158157),
 ('TV(2.0) Loss', 0.19962667)], overall loss: -1.40041708946
Iteration: 692, named_losses: [('ActivationMax Loss', -1.6136727),
 ('L-6.0 Norm Loss', 0.022159342),
 ('TV(2.0) Loss', 0.19891106)], overall loss: -1.39260232449
Iteration: 693, named_losses: [('ActivationMax Loss', -1.6022487),
 ('L-6.0 Norm Loss', 0.022158829),
 ('TV(2.0) Loss', 0.19866368)], overall loss: -1.38142609596
Iteration: 694, named_losses: [('ActivationMax Loss', -1.6206467),
 ('L-6.0 Norm Loss', 0.02215877),
 ('TV(2.0) Loss', 0.19901136)], overall loss: -1.39947664738
Iteration: 695, named_losses: [('ActivationMax Loss', -1.5923593),
 ('L-6.0 Norm Loss', 0.022158049),
 ('TV(2.0) Loss', 0.19929078)], overall loss: -1.37091052532
Iteration: 696, named_losses: [('ActivationMax Loss', -1.6146579),
 ('L-6.0 Norm Loss', 0.022159049),
 ('TV(2.0) Loss', 0.2004078)], overall loss: -1.39209103584
Iteration: 697, named_losses: [('ActivationMax Loss', -1.5862811),
 ('L-6.0 Norm Loss', 0.022158775),
 ('TV(2.0) Loss', 0.20073646)], overall loss: -1.36338591576
Iteration: 698, named_losses: [('ActivationMax Loss', -1.5811182),
 ('L-6.0 Norm Loss', 0.022158166),
 ('TV(2.0) Loss', 0.20029071)], overall loss: -1.35866940022
Iteration: 699, named_losses: [('ActivationMax Loss', -1.6375337),
 ('L-6.0 Norm Loss', 0.022157339),
 ('TV(2.0) Loss', 0.20003754)], overall loss: -1.41533875465
Iteration: 700, named_losses: [('ActivationMax Loss', -1.6381235),
 ('L-6.0 Norm Loss', 0.022157285),
 ('TV(2.0) Loss', 0.19702558)], overall loss: -1.41894066334
Iteration: 701, named_losses: [('ActivationMax Loss', -1.603828),
 ('L-6.0 Norm Loss', 0.022155998),
 ('TV(2.0) Loss', 0.19729771)], overall loss: -1.3843742609
Iteration: 702, named_losses: [('ActivationMax Loss', -1.5773275),
 ('L-6.0 Norm Loss', 0.022157174),
 ('TV(2.0) Loss', 0.19784847)], overall loss: -1.35732185841
Iteration: 703, named_losses: [('ActivationMax Loss', -1.6285263),
 ('L-6.0 Norm Loss', 0.022157887),
 ('TV(2.0) Loss', 0.1999764)], overall loss: -1.40639197826
Iteration: 704, named_losses: [('ActivationMax Loss', -1.6013225),
 ('L-6.0 Norm Loss', 0.022155775),
 ('TV(2.0) Loss', 0.19813859)], overall loss: -1.38102817535
Iteration: 705, named_losses: [('ActivationMax Loss', -1.6257883),
 ('L-6.0 Norm Loss', 0.022157967),
 ('TV(2.0) Loss', 0.20064363)], overall loss: -1.4029866457
Iteration: 706, named_losses: [('ActivationMax Loss', -1.605149),
 ('L-6.0 Norm Loss', 0.022156805),
 ('TV(2.0) Loss', 0.19892094)], overall loss: -1.38407123089
Iteration: 707, named_losses: [('ActivationMax Loss', -1.650532),
 ('L-6.0 Norm Loss', 0.022155998),
 ('TV(2.0) Loss', 0.19870642)], overall loss: -1.42966961861
Iteration: 708, named_losses: [('ActivationMax Loss', -1.6109494),
 ('L-6.0 Norm Loss', 0.022155847),
 ('TV(2.0) Loss', 0.19717635)], overall loss: -1.39161717892
Iteration: 709, named_losses: [('ActivationMax Loss', -1.6237277),
 ('L-6.0 Norm Loss', 0.022154603),
 ('TV(2.0) Loss', 0.19804956)], overall loss: -1.40352356434
Iteration: 710, named_losses: [('ActivationMax Loss', -1.5974369),
 ('L-6.0 Norm Loss', 0.022155588),
 ('TV(2.0) Loss', 0.19748445)], overall loss: -1.37779676914
Iteration: 711, named_losses: [('ActivationMax Loss', -1.6621349),
 ('L-6.0 Norm Loss', 0.022155352),
 ('TV(2.0) Loss', 0.19833381)], overall loss: -1.44164562225
Iteration: 712, named_losses: [('ActivationMax Loss', -1.579453),
 ('L-6.0 Norm Loss', 0.022153957),
 ('TV(2.0) Loss', 0.19747095)], overall loss: -1.35982811451
Iteration: 713, named_losses: [('ActivationMax Loss', -1.5799358),
 ('L-6.0 Norm Loss', 0.022156434),
 ('TV(2.0) Loss', 0.19799672)], overall loss: -1.35978257656
Iteration: 714, named_losses: [('ActivationMax Loss', -1.6204424),
 ('L-6.0 Norm Loss', 0.022155747),
 ('TV(2.0) Loss', 0.19959499)], overall loss: -1.39869165421
Iteration: 715, named_losses: [('ActivationMax Loss', -1.5953088),
 ('L-6.0 Norm Loss', 0.022156309),
 ('TV(2.0) Loss', 0.19806843)], overall loss: -1.37508404255
Iteration: 716, named_losses: [('ActivationMax Loss', -1.5471383),
 ('L-6.0 Norm Loss', 0.022155613),
 ('TV(2.0) Loss', 0.19889377)], overall loss: -1.32608890533
Iteration: 717, named_losses: [('ActivationMax Loss', -1.5496542),
 ('L-6.0 Norm Loss', 0.022155818),
 ('TV(2.0) Loss', 0.20070007)], overall loss: -1.32679843903
Iteration: 718, named_losses: [('ActivationMax Loss', -1.5799839),
 ('L-6.0 Norm Loss', 0.022155792),
 ('TV(2.0) Loss', 0.2015952)], overall loss: -1.35623300076
Iteration: 719, named_losses: [('ActivationMax Loss', -1.5556513),
 ('L-6.0 Norm Loss', 0.022156641),
 ('TV(2.0) Loss', 0.20136569)], overall loss: -1.33212900162
Iteration: 720, named_losses: [('ActivationMax Loss', -1.5741131),
 ('L-6.0 Norm Loss', 0.022155836),
 ('TV(2.0) Loss', 0.20215766)], overall loss: -1.34979963303
Iteration: 721, named_losses: [('ActivationMax Loss', -1.5735453),
 ('L-6.0 Norm Loss', 0.022156285),
 ('TV(2.0) Loss', 0.20269164)], overall loss: -1.34869742393
Iteration: 722, named_losses: [('ActivationMax Loss', -1.5783411),
 ('L-6.0 Norm Loss', 0.02215708),
 ('TV(2.0) Loss', 0.20266157)], overall loss: -1.35352253914
Iteration: 723, named_losses: [('ActivationMax Loss', -1.5876913),
 ('L-6.0 Norm Loss', 0.022154832),
 ('TV(2.0) Loss', 0.20230459)], overall loss: -1.36323189735
Iteration: 724, named_losses: [('ActivationMax Loss', -1.6062896),
 ('L-6.0 Norm Loss', 0.022155577),
 ('TV(2.0) Loss', 0.20189068)], overall loss: -1.38224339485
Iteration: 725, named_losses: [('ActivationMax Loss', -1.617679),
 ('L-6.0 Norm Loss', 0.022156484),
 ('TV(2.0) Loss', 0.20189653)], overall loss: -1.39362597466
Iteration: 726, named_losses: [('ActivationMax Loss', -1.5786302),
 ('L-6.0 Norm Loss', 0.022154789),
 ('TV(2.0) Loss', 0.20236139)], overall loss: -1.35411405563
Iteration: 727, named_losses: [('ActivationMax Loss', -1.6177009),
 ('L-6.0 Norm Loss', 0.022154694),
 ('TV(2.0) Loss', 0.20303926)], overall loss: -1.39250695705
Iteration: 728, named_losses: [('ActivationMax Loss', -1.5797464),
 ('L-6.0 Norm Loss', 0.022155466),
 ('TV(2.0) Loss', 0.20400707)], overall loss: -1.35358381271
Iteration: 729, named_losses: [('ActivationMax Loss', -1.5959517),
 ('L-6.0 Norm Loss', 0.022154378),
 ('TV(2.0) Loss', 0.20303077)], overall loss: -1.37076663971
Iteration: 730, named_losses: [('ActivationMax Loss', -1.5717692),
 ('L-6.0 Norm Loss', 0.022155123),
 ('TV(2.0) Loss', 0.20381135)], overall loss: -1.34580278397
Iteration: 731, named_losses: [('ActivationMax Loss', -1.6127177),
 ('L-6.0 Norm Loss', 0.022155279),
 ('TV(2.0) Loss', 0.20282245)], overall loss: -1.38774001598
Iteration: 732, named_losses: [('ActivationMax Loss', -1.5980821),
 ('L-6.0 Norm Loss', 0.022154547),
 ('TV(2.0) Loss', 0.20207134)], overall loss: -1.37385618687
Iteration: 733, named_losses: [('ActivationMax Loss', -1.5748993),
 ('L-6.0 Norm Loss', 0.02215511),
 ('TV(2.0) Loss', 0.2015219)], overall loss: -1.35122227669
Iteration: 734, named_losses: [('ActivationMax Loss', -1.6281068),
 ('L-6.0 Norm Loss', 0.022154864),
 ('TV(2.0) Loss', 0.20244606)], overall loss: -1.40350592136
Iteration: 735, named_losses: [('ActivationMax Loss', -1.5973008),
 ('L-6.0 Norm Loss', 0.022154145),
 ('TV(2.0) Loss', 0.20225374)], overall loss: -1.37289297581
Iteration: 736, named_losses: [('ActivationMax Loss', -1.5591279),
 ('L-6.0 Norm Loss', 0.022153763),
 ('TV(2.0) Loss', 0.20171401)], overall loss: -1.33526015282
Iteration: 737, named_losses: [('ActivationMax Loss', -1.5868065),
 ('L-6.0 Norm Loss', 0.022154965),
 ('TV(2.0) Loss', 0.20267685)], overall loss: -1.36197471619
Iteration: 738, named_losses: [('ActivationMax Loss', -1.6372209),
 ('L-6.0 Norm Loss', 0.022153515),
 ('TV(2.0) Loss', 0.20154908)], overall loss: -1.41351830959
Iteration: 739, named_losses: [('ActivationMax Loss', -1.6001856),
 ('L-6.0 Norm Loss', 0.022154849),
 ('TV(2.0) Loss', 0.20168076)], overall loss: -1.3763500452
Iteration: 740, named_losses: [('ActivationMax Loss', -1.6069922),
 ('L-6.0 Norm Loss', 0.022153966),
 ('TV(2.0) Loss', 0.19964401)], overall loss: -1.38519430161
Iteration: 741, named_losses: [('ActivationMax Loss', -1.5485643),
 ('L-6.0 Norm Loss', 0.02215302),
 ('TV(2.0) Loss', 0.20147641)], overall loss: -1.3249348402
Iteration: 742, named_losses: [('ActivationMax Loss', -1.635725),
 ('L-6.0 Norm Loss', 0.022152264),
 ('TV(2.0) Loss', 0.19915035)], overall loss: -1.41442239285
Iteration: 743, named_losses: [('ActivationMax Loss', -1.5944483),
 ('L-6.0 Norm Loss', 0.022152781),
 ('TV(2.0) Loss', 0.19847491)], overall loss: -1.3738206625
Iteration: 744, named_losses: [('ActivationMax Loss', -1.5978053),
 ('L-6.0 Norm Loss', 0.022153083),
 ('TV(2.0) Loss', 0.1988879)], overall loss: -1.37676417828
Iteration: 745, named_losses: [('ActivationMax Loss', -1.6031719),
 ('L-6.0 Norm Loss', 0.022153348),
 ('TV(2.0) Loss', 0.1998322)], overall loss: -1.38118636608
Iteration: 746, named_losses: [('ActivationMax Loss', -1.5453733),
 ('L-6.0 Norm Loss', 0.022153927),
 ('TV(2.0) Loss', 0.19967519)], overall loss: -1.32354414463
Iteration: 747, named_losses: [('ActivationMax Loss', -1.5800128),
 ('L-6.0 Norm Loss', 0.022153851),
 ('TV(2.0) Loss', 0.20155889)], overall loss: -1.35630011559
Iteration: 748, named_losses: [('ActivationMax Loss', -1.5703033),
 ('L-6.0 Norm Loss', 0.022154784),
 ('TV(2.0) Loss', 0.20224544)], overall loss: -1.34590303898
Iteration: 749, named_losses: [('ActivationMax Loss', -1.594018),
 ('L-6.0 Norm Loss', 0.022153368),
 ('TV(2.0) Loss', 0.20087902)], overall loss: -1.37098562717
Iteration: 750, named_losses: [('ActivationMax Loss', -1.6132183),
 ('L-6.0 Norm Loss', 0.022153145),
 ('TV(2.0) Loss', 0.20167653)], overall loss: -1.38938868046
Iteration: 751, named_losses: [('ActivationMax Loss', -1.5983715),
 ('L-6.0 Norm Loss', 0.022152858),
 ('TV(2.0) Loss', 0.1997706)], overall loss: -1.37644803524
Iteration: 752, named_losses: [('ActivationMax Loss', -1.6008122),
 ('L-6.0 Norm Loss', 0.022154076),
 ('TV(2.0) Loss', 0.19979158)], overall loss: -1.37886655331
Iteration: 753, named_losses: [('ActivationMax Loss', -1.5995507),
 ('L-6.0 Norm Loss', 0.022153627),
 ('TV(2.0) Loss', 0.19922206)], overall loss: -1.37817502022
Iteration: 754, named_losses: [('ActivationMax Loss', -1.6311173),
 ('L-6.0 Norm Loss', 0.022153949),
 ('TV(2.0) Loss', 0.19938272)], overall loss: -1.40958070755
Iteration: 755, named_losses: [('ActivationMax Loss', -1.5782019),
 ('L-6.0 Norm Loss', 0.022153089),
 ('TV(2.0) Loss', 0.19798803)], overall loss: -1.35806071758
Iteration: 756, named_losses: [('ActivationMax Loss', -1.6437052),
 ('L-6.0 Norm Loss', 0.022153106),
 ('TV(2.0) Loss', 0.19737352)], overall loss: -1.42417860031
Iteration: 757, named_losses: [('ActivationMax Loss', -1.5863032),
 ('L-6.0 Norm Loss', 0.022152405),
 ('TV(2.0) Loss', 0.19703533)], overall loss: -1.36711549759
Iteration: 758, named_losses: [('ActivationMax Loss', -1.6101089),
 ('L-6.0 Norm Loss', 0.022151124),
 ('TV(2.0) Loss', 0.19780238)], overall loss: -1.3901553154
Iteration: 759, named_losses: [('ActivationMax Loss', -1.5488386),
 ('L-6.0 Norm Loss', 0.022151332),
 ('TV(2.0) Loss', 0.19775215)], overall loss: -1.32893514633
Iteration: 760, named_losses: [('ActivationMax Loss', -1.5883635),
 ('L-6.0 Norm Loss', 0.022151653),
 ('TV(2.0) Loss', 0.19779913)], overall loss: -1.36841273308
Iteration: 761, named_losses: [('ActivationMax Loss', -1.5816454),
 ('L-6.0 Norm Loss', 0.022151666),
 ('TV(2.0) Loss', 0.19739896)], overall loss: -1.36209464073
Iteration: 762, named_losses: [('ActivationMax Loss', -1.5766418),
 ('L-6.0 Norm Loss', 0.022151664),
 ('TV(2.0) Loss', 0.19697486)], overall loss: -1.35751521587
Iteration: 763, named_losses: [('ActivationMax Loss', -1.6123499),
 ('L-6.0 Norm Loss', 0.02215052),
 ('TV(2.0) Loss', 0.19794022)], overall loss: -1.39225912094
Iteration: 764, named_losses: [('ActivationMax Loss', -1.5993456),
 ('L-6.0 Norm Loss', 0.022150449),
 ('TV(2.0) Loss', 0.1981747)], overall loss: -1.3790204525
Iteration: 765, named_losses: [('ActivationMax Loss', -1.5822634),
 ('L-6.0 Norm Loss', 0.022150636),
 ('TV(2.0) Loss', 0.19798955)], overall loss: -1.36212313175
Iteration: 766, named_losses: [('ActivationMax Loss', -1.6063709),
 ('L-6.0 Norm Loss', 0.022150381),
 ('TV(2.0) Loss', 0.1994428)], overall loss: -1.38477778435
Iteration: 767, named_losses: [('ActivationMax Loss', -1.6334332),
 ('L-6.0 Norm Loss', 0.022151535),
 ('TV(2.0) Loss', 0.19857095)], overall loss: -1.41271066666
Iteration: 768, named_losses: [('ActivationMax Loss', -1.5969851),
 ('L-6.0 Norm Loss', 0.022149369),
 ('TV(2.0) Loss', 0.19778718)], overall loss: -1.37704861164
Iteration: 769, named_losses: [('ActivationMax Loss', -1.6288946),
 ('L-6.0 Norm Loss', 0.022149447),
 ('TV(2.0) Loss', 0.19762039)], overall loss: -1.40912473202
Iteration: 770, named_losses: [('ActivationMax Loss', -1.6488655),
 ('L-6.0 Norm Loss', 0.02214958),
 ('TV(2.0) Loss', 0.19801748)], overall loss: -1.42869842052
Iteration: 771, named_losses: [('ActivationMax Loss', -1.6116214),
 ('L-6.0 Norm Loss', 0.022148591),
 ('TV(2.0) Loss', 0.19693197)], overall loss: -1.39254081249
Iteration: 772, named_losses: [('ActivationMax Loss', -1.5802855),
 ('L-6.0 Norm Loss', 0.02214811),
 ('TV(2.0) Loss', 0.19649577)], overall loss: -1.36164164543
Iteration: 773, named_losses: [('ActivationMax Loss', -1.5676028),
 ('L-6.0 Norm Loss', 0.022148546),
 ('TV(2.0) Loss', 0.19707048)], overall loss: -1.34838378429
Iteration: 774, named_losses: [('ActivationMax Loss', -1.5758474),
 ('L-6.0 Norm Loss', 0.022149224),
 ('TV(2.0) Loss', 0.19838217)], overall loss: -1.3553160429
Iteration: 775, named_losses: [('ActivationMax Loss', -1.6008574),
 ('L-6.0 Norm Loss', 0.022149654),
 ('TV(2.0) Loss', 0.19802099)], overall loss: -1.38068675995
Iteration: 776, named_losses: [('ActivationMax Loss', -1.6013805),
 ('L-6.0 Norm Loss', 0.022149572),
 ('TV(2.0) Loss', 0.19804263)], overall loss: -1.38118827343
Iteration: 777, named_losses: [('ActivationMax Loss', -1.6247588),
 ('L-6.0 Norm Loss', 0.02214819),
 ('TV(2.0) Loss', 0.1986112)], overall loss: -1.40399956703
Iteration: 778, named_losses: [('ActivationMax Loss', -1.571805),
 ('L-6.0 Norm Loss', 0.022148687),
 ('TV(2.0) Loss', 0.19740854)], overall loss: -1.352247715
Iteration: 779, named_losses: [('ActivationMax Loss', -1.6006505),
 ('L-6.0 Norm Loss', 0.022148674),
 ('TV(2.0) Loss', 0.20001052)], overall loss: -1.37849128246
Iteration: 780, named_losses: [('ActivationMax Loss', -1.5911019),
 ('L-6.0 Norm Loss', 0.022148971),
 ('TV(2.0) Loss', 0.19934075)], overall loss: -1.36961221695
Iteration: 781, named_losses: [('ActivationMax Loss', -1.5733795),
 ('L-6.0 Norm Loss', 0.02214884),
 ('TV(2.0) Loss', 0.20128685)], overall loss: -1.34994387627
Iteration: 782, named_losses: [('ActivationMax Loss', -1.5908717),
 ('L-6.0 Norm Loss', 0.022149086),
 ('TV(2.0) Loss', 0.20190021)], overall loss: -1.36682236195
Iteration: 783, named_losses: [('ActivationMax Loss', -1.6127387),
 ('L-6.0 Norm Loss', 0.022147898),
 ('TV(2.0) Loss', 0.20033178)], overall loss: -1.39025902748
Iteration: 784, named_losses: [('ActivationMax Loss', -1.5558078),
 ('L-6.0 Norm Loss', 0.022147272),
 ('TV(2.0) Loss', 0.19926259)], overall loss: -1.33439791203
Iteration: 785, named_losses: [('ActivationMax Loss', -1.6027911),
 ('L-6.0 Norm Loss', 0.022147227),
 ('TV(2.0) Loss', 0.20007545)], overall loss: -1.38056850433
Iteration: 786, named_losses: [('ActivationMax Loss', -1.5170885),
 ('L-6.0 Norm Loss', 0.022146441),
 ('TV(2.0) Loss', 0.19992729)], overall loss: -1.29501473904
Iteration: 787, named_losses: [('ActivationMax Loss', -1.5755373),
 ('L-6.0 Norm Loss', 0.022148598),
 ('TV(2.0) Loss', 0.19925836)], overall loss: -1.35413038731
Iteration: 788, named_losses: [('ActivationMax Loss', -1.6087742),
 ('L-6.0 Norm Loss', 0.022149216),
 ('TV(2.0) Loss', 0.20059614)], overall loss: -1.38602888584
Iteration: 789, named_losses: [('ActivationMax Loss', -1.6060278),
 ('L-6.0 Norm Loss', 0.022146551),
 ('TV(2.0) Loss', 0.19997069)], overall loss: -1.38391053677
Iteration: 790, named_losses: [('ActivationMax Loss', -1.577769),
 ('L-6.0 Norm Loss', 0.022148034),
 ('TV(2.0) Loss', 0.19971149)], overall loss: -1.35590958595
Iteration: 791, named_losses: [('ActivationMax Loss', -1.6058676),
 ('L-6.0 Norm Loss', 0.022145977),
 ('TV(2.0) Loss', 0.20142725)], overall loss: -1.38229441643
Iteration: 792, named_losses: [('ActivationMax Loss', -1.5993097),
 ('L-6.0 Norm Loss', 0.022147954),
 ('TV(2.0) Loss', 0.20076448)], overall loss: -1.37639737129
Iteration: 793, named_losses: [('ActivationMax Loss', -1.5831699),
 ('L-6.0 Norm Loss', 0.022146739),
 ('TV(2.0) Loss', 0.20024076)], overall loss: -1.36078250408
Iteration: 794, named_losses: [('ActivationMax Loss', -1.5976586),
 ('L-6.0 Norm Loss', 0.022147082),
 ('TV(2.0) Loss', 0.20055668)], overall loss: -1.37495493889
Iteration: 795, named_losses: [('ActivationMax Loss', -1.618088),
 ('L-6.0 Norm Loss', 0.022146761),
 ('TV(2.0) Loss', 0.20083284)], overall loss: -1.39510846138
Iteration: 796, named_losses: [('ActivationMax Loss', -1.5817395),
 ('L-6.0 Norm Loss', 0.022145232),
 ('TV(2.0) Loss', 0.19973148)], overall loss: -1.35986280441
Iteration: 797, named_losses: [('ActivationMax Loss', -1.5996644),
 ('L-6.0 Norm Loss', 0.022147244),
 ('TV(2.0) Loss', 0.19960031)], overall loss: -1.3779168129
Iteration: 798, named_losses: [('ActivationMax Loss', -1.6250285),
 ('L-6.0 Norm Loss', 0.02214786),
 ('TV(2.0) Loss', 0.2001528)], overall loss: -1.40272784233
Iteration: 799, named_losses: [('ActivationMax Loss', -1.6102524),
 ('L-6.0 Norm Loss', 0.022145487),
 ('TV(2.0) Loss', 0.2001693)], overall loss: -1.38793754578
Iteration: 800, named_losses: [('ActivationMax Loss', -1.5867686),
 ('L-6.0 Norm Loss', 0.02214653),
 ('TV(2.0) Loss', 0.19866428)], overall loss: -1.36595773697
Iteration: 801, named_losses: [('ActivationMax Loss', -1.5506234),
 ('L-6.0 Norm Loss', 0.022144828),
 ('TV(2.0) Loss', 0.19753961)], overall loss: -1.33093905449
Iteration: 802, named_losses: [('ActivationMax Loss', -1.6113584),
 ('L-6.0 Norm Loss', 0.022145256),
 ('TV(2.0) Loss', 0.19659474)], overall loss: -1.39261841774
Iteration: 803, named_losses: [('ActivationMax Loss', -1.5749369),
 ('L-6.0 Norm Loss', 0.022145631),
 ('TV(2.0) Loss', 0.19538923)], overall loss: -1.35740196705
Iteration: 804, named_losses: [('ActivationMax Loss', -1.5777003),
 ('L-6.0 Norm Loss', 0.022144318),
 ('TV(2.0) Loss', 0.19486888)], overall loss: -1.36068701744
Iteration: 805, named_losses: [('ActivationMax Loss', -1.6156731),
 ('L-6.0 Norm Loss', 0.022143517),
 ('TV(2.0) Loss', 0.19524753)], overall loss: -1.39828205109
Iteration: 806, named_losses: [('ActivationMax Loss', -1.5861554),
 ('L-6.0 Norm Loss', 0.022144059),
 ('TV(2.0) Loss', 0.19551195)], overall loss: -1.36849939823
Iteration: 807, named_losses: [('ActivationMax Loss', -1.6172941),
 ('L-6.0 Norm Loss', 0.022144904),
 ('TV(2.0) Loss', 0.19610627)], overall loss: -1.39904284477
Iteration: 808, named_losses: [('ActivationMax Loss', -1.6273301),
 ('L-6.0 Norm Loss', 0.022144096),
 ('TV(2.0) Loss', 0.19448777)], overall loss: -1.41069817543
Iteration: 809, named_losses: [('ActivationMax Loss', -1.5933334),
 ('L-6.0 Norm Loss', 0.022142358),
 ('TV(2.0) Loss', 0.19349)], overall loss: -1.37770092487
Iteration: 810, named_losses: [('ActivationMax Loss', -1.5762411),
 ('L-6.0 Norm Loss', 0.022143135),
 ('TV(2.0) Loss', 0.19491231)], overall loss: -1.35918569565
Iteration: 811, named_losses: [('ActivationMax Loss', -1.6179777),
 ('L-6.0 Norm Loss', 0.022144388),
 ('TV(2.0) Loss', 0.19685626)], overall loss: -1.39897704124
Iteration: 812, named_losses: [('ActivationMax Loss', -1.5771124),
 ('L-6.0 Norm Loss', 0.022143209),
 ('TV(2.0) Loss', 0.19768445)], overall loss: -1.35728478432
Iteration: 813, named_losses: [('ActivationMax Loss', -1.5926998),
 ('L-6.0 Norm Loss', 0.022144102),
 ('TV(2.0) Loss', 0.19832434)], overall loss: -1.37223136425
Iteration: 814, named_losses: [('ActivationMax Loss', -1.6095607),
 ('L-6.0 Norm Loss', 0.02214485),
 ('TV(2.0) Loss', 0.19910198)], overall loss: -1.38831400871
Iteration: 815, named_losses: [('ActivationMax Loss', -1.5842094),
 ('L-6.0 Norm Loss', 0.022144701),
 ('TV(2.0) Loss', 0.19897634)], overall loss: -1.36308836937
Iteration: 816, named_losses: [('ActivationMax Loss', -1.6159177),
 ('L-6.0 Norm Loss', 0.022144618),
 ('TV(2.0) Loss', 0.19874528)], overall loss: -1.39502775669
Iteration: 817, named_losses: [('ActivationMax Loss', -1.5912929),
 ('L-6.0 Norm Loss', 0.022142211),
 ('TV(2.0) Loss', 0.19756427)], overall loss: -1.37158644199
Iteration: 818, named_losses: [('ActivationMax Loss', -1.5948504),
 ('L-6.0 Norm Loss', 0.022144606),
 ('TV(2.0) Loss', 0.19715823)], overall loss: -1.37554764748
Iteration: 819, named_losses: [('ActivationMax Loss', -1.5758678),
 ('L-6.0 Norm Loss', 0.022143222),
 ('TV(2.0) Loss', 0.19822192)], overall loss: -1.35550260544
Iteration: 820, named_losses: [('ActivationMax Loss', -1.6283042),
 ('L-6.0 Norm Loss', 0.022142068),
 ('TV(2.0) Loss', 0.19859807)], overall loss: -1.40756416321
Iteration: 821, named_losses: [('ActivationMax Loss', -1.5868102),
 ('L-6.0 Norm Loss', 0.022144152),
 ('TV(2.0) Loss', 0.19715032)], overall loss: -1.36751568317
Iteration: 822, named_losses: [('ActivationMax Loss', -1.629496),
 ('L-6.0 Norm Loss', 0.022142928),
 ('TV(2.0) Loss', 0.19753596)], overall loss: -1.40981709957
Iteration: 823, named_losses: [('ActivationMax Loss', -1.6107206),
 ('L-6.0 Norm Loss', 0.022141807),
 ('TV(2.0) Loss', 0.19675884)], overall loss: -1.39181995392
Iteration: 824, named_losses: [('ActivationMax Loss', -1.595476),
 ('L-6.0 Norm Loss', 0.022141227),
 ('TV(2.0) Loss', 0.19581845)], overall loss: -1.37751638889
Iteration: 825, named_losses: [('ActivationMax Loss', -1.5674007),
 ('L-6.0 Norm Loss', 0.022141423),
 ('TV(2.0) Loss', 0.19686872)], overall loss: -1.34839057922
Iteration: 826, named_losses: [('ActivationMax Loss', -1.5393819),
 ('L-6.0 Norm Loss', 0.02214174),
 ('TV(2.0) Loss', 0.19691311)], overall loss: -1.32032704353
Iteration: 827, named_losses: [('ActivationMax Loss', -1.5187299),
 ('L-6.0 Norm Loss', 0.022141514),
 ('TV(2.0) Loss', 0.19778274)], overall loss: -1.29880571365
Iteration: 828, named_losses: [('ActivationMax Loss', -1.5951025),
 ('L-6.0 Norm Loss', 0.022141419),
 ('TV(2.0) Loss', 0.19740923)], overall loss: -1.3755518198
Iteration: 829, named_losses: [('ActivationMax Loss', -1.5825452),
 ('L-6.0 Norm Loss', 0.022143051),
 ('TV(2.0) Loss', 0.19761987)], overall loss: -1.36278223991
Iteration: 830, named_losses: [('ActivationMax Loss', -1.5914261),
 ('L-6.0 Norm Loss', 0.022140963),
 ('TV(2.0) Loss', 0.19675577)], overall loss: -1.37252938747
Iteration: 831, named_losses: [('ActivationMax Loss', -1.5780818),
 ('L-6.0 Norm Loss', 0.022141978),
 ('TV(2.0) Loss', 0.19752747)], overall loss: -1.3584125042
Iteration: 832, named_losses: [('ActivationMax Loss', -1.5864515),
 ('L-6.0 Norm Loss', 0.022141628),
 ('TV(2.0) Loss', 0.1981146)], overall loss: -1.36619532108
Iteration: 833, named_losses: [('ActivationMax Loss', -1.5591614),
 ('L-6.0 Norm Loss', 0.022141282),
 ('TV(2.0) Loss', 0.19800304)], overall loss: -1.33901703358
Iteration: 834, named_losses: [('ActivationMax Loss', -1.5843331),
 ('L-6.0 Norm Loss', 0.022141282),
 ('TV(2.0) Loss', 0.1985613)], overall loss: -1.36363041401
Iteration: 835, named_losses: [('ActivationMax Loss', -1.6040202),
 ('L-6.0 Norm Loss', 0.022141552),
 ('TV(2.0) Loss', 0.19791323)], overall loss: -1.38396549225
Iteration: 836, named_losses: [('ActivationMax Loss', -1.6194296),
 ('L-6.0 Norm Loss', 0.022142155),
 ('TV(2.0) Loss', 0.1985099)], overall loss: -1.39877748489
Iteration: 837, named_losses: [('ActivationMax Loss', -1.6206245),
 ('L-6.0 Norm Loss', 0.022140794),
 ('TV(2.0) Loss', 0.19767584)], overall loss: -1.40080797672
Iteration: 838, named_losses: [('ActivationMax Loss', -1.5552564),
 ('L-6.0 Norm Loss', 0.022141077),
 ('TV(2.0) Loss', 0.19715345)], overall loss: -1.3359618187
Iteration: 839, named_losses: [('ActivationMax Loss', -1.6149259),
 ('L-6.0 Norm Loss', 0.022139829),
 ('TV(2.0) Loss', 0.19720912)], overall loss: -1.39557695389
Iteration: 840, named_losses: [('ActivationMax Loss', -1.5870572),
 ('L-6.0 Norm Loss', 0.022140762),
 ('TV(2.0) Loss', 0.19703241)], overall loss: -1.36788403988
Iteration: 841, named_losses: [('ActivationMax Loss', -1.6052096),
 ('L-6.0 Norm Loss', 0.022140721),
 ('TV(2.0) Loss', 0.19795884)], overall loss: -1.38511002064
Iteration: 842, named_losses: [('ActivationMax Loss', -1.6075823),
 ('L-6.0 Norm Loss', 0.022141598),
 ('TV(2.0) Loss', 0.19758137)], overall loss: -1.38785934448
Iteration: 843, named_losses: [('ActivationMax Loss', -1.5843883),
 ('L-6.0 Norm Loss', 0.022140712),
 ('TV(2.0) Loss', 0.19911693)], overall loss: -1.36313056946
Iteration: 844, named_losses: [('ActivationMax Loss', -1.6097572),
 ('L-6.0 Norm Loss', 0.022141377),
 ('TV(2.0) Loss', 0.19866763)], overall loss: -1.38894820213
Iteration: 845, named_losses: [('ActivationMax Loss', -1.6231134),
 ('L-6.0 Norm Loss', 0.022139423),
 ('TV(2.0) Loss', 0.20004554)], overall loss: -1.40092837811
Iteration: 846, named_losses: [('ActivationMax Loss', -1.6237358),
 ('L-6.0 Norm Loss', 0.022140229),
 ('TV(2.0) Loss', 0.19834201)], overall loss: -1.4032535553
Iteration: 847, named_losses: [('ActivationMax Loss', -1.6450737),
 ('L-6.0 Norm Loss', 0.022140019),
 ('TV(2.0) Loss', 0.19954067)], overall loss: -1.42339301109
Iteration: 848, named_losses: [('ActivationMax Loss', -1.5802234),
 ('L-6.0 Norm Loss', 0.022138298),
 ('TV(2.0) Loss', 0.19631033)], overall loss: -1.36177492142
Iteration: 849, named_losses: [('ActivationMax Loss', -1.6383357),
 ('L-6.0 Norm Loss', 0.02213861),
 ('TV(2.0) Loss', 0.19765557)], overall loss: -1.41854155064
Iteration: 850, named_losses: [('ActivationMax Loss', -1.6121525),
 ('L-6.0 Norm Loss', 0.022138057),
 ('TV(2.0) Loss', 0.19466878)], overall loss: -1.39534568787
Iteration: 851, named_losses: [('ActivationMax Loss', -1.6425328),
 ('L-6.0 Norm Loss', 0.02213601),
 ('TV(2.0) Loss', 0.19535062)], overall loss: -1.42504620552
Iteration: 852, named_losses: [('ActivationMax Loss', -1.6271188),
 ('L-6.0 Norm Loss', 0.022137988),
 ('TV(2.0) Loss', 0.19543499)], overall loss: -1.40954589844
Iteration: 853, named_losses: [('ActivationMax Loss', -1.6352749),
 ('L-6.0 Norm Loss', 0.022136269),
 ('TV(2.0) Loss', 0.19513479)], overall loss: -1.41800391674
Iteration: 854, named_losses: [('ActivationMax Loss', -1.5858728),
 ('L-6.0 Norm Loss', 0.022136789),
 ('TV(2.0) Loss', 0.19521962)], overall loss: -1.36851632595
Iteration: 855, named_losses: [('ActivationMax Loss', -1.5933063),
 ('L-6.0 Norm Loss', 0.022136152),
 ('TV(2.0) Loss', 0.19664043)], overall loss: -1.37452960014
Iteration: 856, named_losses: [('ActivationMax Loss', -1.6001899),
 ('L-6.0 Norm Loss', 0.022137262),
 ('TV(2.0) Loss', 0.19695963)], overall loss: -1.38109302521
Iteration: 857, named_losses: [('ActivationMax Loss', -1.5794995),
 ('L-6.0 Norm Loss', 0.022135621),
 ('TV(2.0) Loss', 0.19861218)], overall loss: -1.35875165462
Iteration: 858, named_losses: [('ActivationMax Loss', -1.6027731),
 ('L-6.0 Norm Loss', 0.022136161),
 ('TV(2.0) Loss', 0.19897862)], overall loss: -1.38165819645
Iteration: 859, named_losses: [('ActivationMax Loss', -1.5725577),
 ('L-6.0 Norm Loss', 0.022136517),
 ('TV(2.0) Loss', 0.19885837)], overall loss: -1.35156273842
Iteration: 860, named_losses: [('ActivationMax Loss', -1.6174574),
 ('L-6.0 Norm Loss', 0.022136237),
 ('TV(2.0) Loss', 0.20011583)], overall loss: -1.39520537853
Iteration: 861, named_losses: [('ActivationMax Loss', -1.5725502),
 ('L-6.0 Norm Loss', 0.022136198),
 ('TV(2.0) Loss', 0.20011336)], overall loss: -1.35030055046
Iteration: 862, named_losses: [('ActivationMax Loss', -1.608006),
 ('L-6.0 Norm Loss', 0.022136083),
 ('TV(2.0) Loss', 0.19986588)], overall loss: -1.3860039711
Iteration: 863, named_losses: [('ActivationMax Loss', -1.573652),
 ('L-6.0 Norm Loss', 0.022135999),
 ('TV(2.0) Loss', 0.20050573)], overall loss: -1.35101032257
Iteration: 864, named_losses: [('ActivationMax Loss', -1.6188083),
 ('L-6.0 Norm Loss', 0.022135889),
 ('TV(2.0) Loss', 0.20109607)], overall loss: -1.39557635784
Iteration: 865, named_losses: [('ActivationMax Loss', -1.5892502),
 ('L-6.0 Norm Loss', 0.022135578),
 ('TV(2.0) Loss', 0.20032056)], overall loss: -1.36679399014
Iteration: 866, named_losses: [('ActivationMax Loss', -1.6066161),
 ('L-6.0 Norm Loss', 0.022135274),
 ('TV(2.0) Loss', 0.20081384)], overall loss: -1.38366699219
Iteration: 867, named_losses: [('ActivationMax Loss', -1.5850735),
 ('L-6.0 Norm Loss', 0.022134516),
 ('TV(2.0) Loss', 0.20008539)], overall loss: -1.36285352707
Iteration: 868, named_losses: [('ActivationMax Loss', -1.6053796),
 ('L-6.0 Norm Loss', 0.022134455),
 ('TV(2.0) Loss', 0.19987619)], overall loss: -1.38336896896
Iteration: 869, named_losses: [('ActivationMax Loss', -1.6018627),
 ('L-6.0 Norm Loss', 0.022134652),
 ('TV(2.0) Loss', 0.19868928)], overall loss: -1.38103866577
Iteration: 870, named_losses: [('ActivationMax Loss', -1.6189492),
 ('L-6.0 Norm Loss', 0.022133067),
 ('TV(2.0) Loss', 0.19913891)], overall loss: -1.39767718315
Iteration: 871, named_losses: [('ActivationMax Loss', -1.6136894),
 ('L-6.0 Norm Loss', 0.022132851),
 ('TV(2.0) Loss', 0.19907163)], overall loss: -1.39248490334
Iteration: 872, named_losses: [('ActivationMax Loss', -1.6360614),
 ('L-6.0 Norm Loss', 0.02213368),
 ('TV(2.0) Loss', 0.20003267)], overall loss: -1.41389501095
Iteration: 873, named_losses: [('ActivationMax Loss', -1.6506366),
 ('L-6.0 Norm Loss', 0.022133114),
 ('TV(2.0) Loss', 0.19939791)], overall loss: -1.42910552025
Iteration: 874, named_losses: [('ActivationMax Loss', -1.5599459),
 ('L-6.0 Norm Loss', 0.02213442),
 ('TV(2.0) Loss', 0.19849981)], overall loss: -1.33931171894
Iteration: 875, named_losses: [('ActivationMax Loss', -1.6350071),
 ('L-6.0 Norm Loss', 0.022133227),
 ('TV(2.0) Loss', 0.19967546)], overall loss: -1.41319847107
Iteration: 876, named_losses: [('ActivationMax Loss', -1.565764),
 ('L-6.0 Norm Loss', 0.022131195),
 ('TV(2.0) Loss', 0.19886412)], overall loss: -1.34476864338
Iteration: 877, named_losses: [('ActivationMax Loss', -1.6022646),
 ('L-6.0 Norm Loss', 0.022132274),
 ('TV(2.0) Loss', 0.19932957)], overall loss: -1.38080275059
Iteration: 878, named_losses: [('ActivationMax Loss', -1.6372322),
 ('L-6.0 Norm Loss', 0.022131929),
 ('TV(2.0) Loss', 0.19827707)], overall loss: -1.41682314873
Iteration: 879, named_losses: [('ActivationMax Loss', -1.5771632),
 ('L-6.0 Norm Loss', 0.022130929),
 ('TV(2.0) Loss', 0.19681981)], overall loss: -1.35821247101
Iteration: 880, named_losses: [('ActivationMax Loss', -1.6183178),
 ('L-6.0 Norm Loss', 0.022131059),
 ('TV(2.0) Loss', 0.19707899)], overall loss: -1.39910781384
Iteration: 881, named_losses: [('ActivationMax Loss', -1.5378789),
 ('L-6.0 Norm Loss', 0.022131357),
 ('TV(2.0) Loss', 0.19673626)], overall loss: -1.3190113306
Iteration: 882, named_losses: [('ActivationMax Loss', -1.609253),
 ('L-6.0 Norm Loss', 0.02213168),
 ('TV(2.0) Loss', 0.19835635)], overall loss: -1.38876497746
Iteration: 883, named_losses: [('ActivationMax Loss', -1.5707179),
 ('L-6.0 Norm Loss', 0.022130514),
 ('TV(2.0) Loss', 0.19679275)], overall loss: -1.3517947197
Iteration: 884, named_losses: [('ActivationMax Loss', -1.5782843),
 ('L-6.0 Norm Loss', 0.022131475),
 ('TV(2.0) Loss', 0.19874826)], overall loss: -1.35740458965
Iteration: 885, named_losses: [('ActivationMax Loss', -1.568485),
 ('L-6.0 Norm Loss', 0.02213107),
 ('TV(2.0) Loss', 0.19752176)], overall loss: -1.34883213043
Iteration: 886, named_losses: [('ActivationMax Loss', -1.5784795),
 ('L-6.0 Norm Loss', 0.022131151),
 ('TV(2.0) Loss', 0.19827096)], overall loss: -1.35807740688
Iteration: 887, named_losses: [('ActivationMax Loss', -1.5849102),
 ('L-6.0 Norm Loss', 0.022130592),
 ('TV(2.0) Loss', 0.19793183)], overall loss: -1.36484766006
Iteration: 888, named_losses: [('ActivationMax Loss', -1.6230288),
 ('L-6.0 Norm Loss', 0.022130609),
 ('TV(2.0) Loss', 0.19737148)], overall loss: -1.40352666378
Iteration: 889, named_losses: [('ActivationMax Loss', -1.615546),
 ('L-6.0 Norm Loss', 0.022129808),
 ('TV(2.0) Loss', 0.19804254)], overall loss: -1.39537370205
Iteration: 890, named_losses: [('ActivationMax Loss', -1.5782781),
 ('L-6.0 Norm Loss', 0.022128865),
 ('TV(2.0) Loss', 0.19754596)], overall loss: -1.35860323906
Iteration: 891, named_losses: [('ActivationMax Loss', -1.5495862),
 ('L-6.0 Norm Loss', 0.022130048),
 ('TV(2.0) Loss', 0.19817066)], overall loss: -1.32928550243
Iteration: 892, named_losses: [('ActivationMax Loss', -1.5973901),
 ('L-6.0 Norm Loss', 0.022130497),
 ('TV(2.0) Loss', 0.19731535)], overall loss: -1.37794423103
Iteration: 893, named_losses: [('ActivationMax Loss', -1.5974376),
 ('L-6.0 Norm Loss', 0.022130804),
 ('TV(2.0) Loss', 0.19763261)], overall loss: -1.37767410278
Iteration: 894, named_losses: [('ActivationMax Loss', -1.6252022),
 ('L-6.0 Norm Loss', 0.022130046),
 ('TV(2.0) Loss', 0.19708)], overall loss: -1.40599215031
Iteration: 895, named_losses: [('ActivationMax Loss', -1.609235),
 ('L-6.0 Norm Loss', 0.022129158),
 ('TV(2.0) Loss', 0.19783907)], overall loss: -1.38926684856
Iteration: 896, named_losses: [('ActivationMax Loss', -1.603476),
 ('L-6.0 Norm Loss', 0.022128316),
 ('TV(2.0) Loss', 0.19706316)], overall loss: -1.38428449631
Iteration: 897, named_losses: [('ActivationMax Loss', -1.6000181),
 ('L-6.0 Norm Loss', 0.022129074),
 ('TV(2.0) Loss', 0.19756256)], overall loss: -1.38032650948
Iteration: 898, named_losses: [('ActivationMax Loss', -1.5893464),
 ('L-6.0 Norm Loss', 0.022130154),
 ('TV(2.0) Loss', 0.19631542)], overall loss: -1.37090086937
Iteration: 899, named_losses: [('ActivationMax Loss', -1.6001283),
 ('L-6.0 Norm Loss', 0.022129437),
 ('TV(2.0) Loss', 0.19763777)], overall loss: -1.38036108017
Iteration: 900, named_losses: [('ActivationMax Loss', -1.5923734),
 ('L-6.0 Norm Loss', 0.022129433),
 ('TV(2.0) Loss', 0.19848476)], overall loss: -1.37175917625
Iteration: 901, named_losses: [('ActivationMax Loss', -1.6286677),
 ('L-6.0 Norm Loss', 0.022128986),
 ('TV(2.0) Loss', 0.19775094)], overall loss: -1.40878784657
Iteration: 902, named_losses: [('ActivationMax Loss', -1.5648167),
 ('L-6.0 Norm Loss', 0.022129631),
 ('TV(2.0) Loss', 0.19741321)], overall loss: -1.34527385235
Iteration: 903, named_losses: [('ActivationMax Loss', -1.6097734),
 ('L-6.0 Norm Loss', 0.022128701),
 ('TV(2.0) Loss', 0.19680589)], overall loss: -1.39083886147
Iteration: 904, named_losses: [('ActivationMax Loss', -1.6077813),
 ('L-6.0 Norm Loss', 0.02212696),
 ('TV(2.0) Loss', 0.19471531)], overall loss: -1.39093911648
Iteration: 905, named_losses: [('ActivationMax Loss', -1.6235733),
 ('L-6.0 Norm Loss', 0.022128226),
 ('TV(2.0) Loss', 0.19437574)], overall loss: -1.40706932545
Iteration: 906, named_losses: [('ActivationMax Loss', -1.5775459),
 ('L-6.0 Norm Loss', 0.02212831),
 ('TV(2.0) Loss', 0.19519567)], overall loss: -1.36022186279
Iteration: 907, named_losses: [('ActivationMax Loss', -1.591157),
 ('L-6.0 Norm Loss', 0.022128588),
 ('TV(2.0) Loss', 0.19612363)], overall loss: -1.37290477753
Iteration: 908, named_losses: [('ActivationMax Loss', -1.6204728),
 ('L-6.0 Norm Loss', 0.022128537),
 ('TV(2.0) Loss', 0.19557364)], overall loss: -1.40277051926
Iteration: 909, named_losses: [('ActivationMax Loss', -1.5885551),
 ('L-6.0 Norm Loss', 0.022126369),
 ('TV(2.0) Loss', 0.194548)], overall loss: -1.37188076973
Iteration: 910, named_losses: [('ActivationMax Loss', -1.6197087),
 ('L-6.0 Norm Loss', 0.022125944),
 ('TV(2.0) Loss', 0.19507435)], overall loss: -1.40250837803
Iteration: 911, named_losses: [('ActivationMax Loss', -1.5834707),
 ('L-6.0 Norm Loss', 0.022128038),
 ('TV(2.0) Loss', 0.19521898)], overall loss: -1.3661236763
Iteration: 912, named_losses: [('ActivationMax Loss', -1.6127076),
 ('L-6.0 Norm Loss', 0.022127841),
 ('TV(2.0) Loss', 0.19594513)], overall loss: -1.39463460445
Iteration: 913, named_losses: [('ActivationMax Loss', -1.5562143),
 ('L-6.0 Norm Loss', 0.022126507),
 ('TV(2.0) Loss', 0.19457674)], overall loss: -1.33951103687
Iteration: 914, named_losses: [('ActivationMax Loss', -1.6198959),
 ('L-6.0 Norm Loss', 0.022127423),
 ('TV(2.0) Loss', 0.19540766)], overall loss: -1.40236091614
Iteration: 915, named_losses: [('ActivationMax Loss', -1.6212829),
 ('L-6.0 Norm Loss', 0.022127662),
 ('TV(2.0) Loss', 0.1943763)], overall loss: -1.40477895737
Iteration: 916, named_losses: [('ActivationMax Loss', -1.5994649),
 ('L-6.0 Norm Loss', 0.022126775),
 ('TV(2.0) Loss', 0.19489568)], overall loss: -1.38244247437
Iteration: 917, named_losses: [('ActivationMax Loss', -1.6277664),
 ('L-6.0 Norm Loss', 0.022126306),
 ('TV(2.0) Loss', 0.19384244)], overall loss: -1.41179764271
Iteration: 918, named_losses: [('ActivationMax Loss', -1.6070175),
 ('L-6.0 Norm Loss', 0.022126773),
 ('TV(2.0) Loss', 0.19400501)], overall loss: -1.39088571072
Iteration: 919, named_losses: [('ActivationMax Loss', -1.5907475),
 ('L-6.0 Norm Loss', 0.022124629),
 ('TV(2.0) Loss', 0.19359721)], overall loss: -1.37502563
Iteration: 920, named_losses: [('ActivationMax Loss', -1.5613191),
 ('L-6.0 Norm Loss', 0.022126455),
 ('TV(2.0) Loss', 0.19532751)], overall loss: -1.34386515617
Iteration: 921, named_losses: [('ActivationMax Loss', -1.5894178),
 ('L-6.0 Norm Loss', 0.022126434),
 ('TV(2.0) Loss', 0.19523124)], overall loss: -1.37206017971
Iteration: 922, named_losses: [('ActivationMax Loss', -1.6020799),
 ('L-6.0 Norm Loss', 0.02212695),
 ('TV(2.0) Loss', 0.19519898)], overall loss: -1.38475394249
Iteration: 923, named_losses: [('ActivationMax Loss', -1.6105094),
 ('L-6.0 Norm Loss', 0.022126278),
 ('TV(2.0) Loss', 0.19515938)], overall loss: -1.39322376251
Iteration: 924, named_losses: [('ActivationMax Loss', -1.6362724),
 ('L-6.0 Norm Loss', 0.022126289),
 ('TV(2.0) Loss', 0.19527674)], overall loss: -1.41886937618
Iteration: 925, named_losses: [('ActivationMax Loss', -1.6254642),
 ('L-6.0 Norm Loss', 0.022124322),
 ('TV(2.0) Loss', 0.19459912)], overall loss: -1.4087407589
Iteration: 926, named_losses: [('ActivationMax Loss', -1.631155),
 ('L-6.0 Norm Loss', 0.022123083),
 ('TV(2.0) Loss', 0.1943154)], overall loss: -1.41471648216
Iteration: 927, named_losses: [('ActivationMax Loss', -1.620998),
 ('L-6.0 Norm Loss', 0.022124987),
 ('TV(2.0) Loss', 0.19302826)], overall loss: -1.40584480762
Iteration: 928, named_losses: [('ActivationMax Loss', -1.6312742),
 ('L-6.0 Norm Loss', 0.022123314),
 ('TV(2.0) Loss', 0.19336677)], overall loss: -1.41578412056
Iteration: 929, named_losses: [('ActivationMax Loss', -1.6409826),
 ('L-6.0 Norm Loss', 0.022124279),
 ('TV(2.0) Loss', 0.19373009)], overall loss: -1.42512822151
Iteration: 930, named_losses: [('ActivationMax Loss', -1.5627649),
 ('L-6.0 Norm Loss', 0.022123929),
 ('TV(2.0) Loss', 0.19382995)], overall loss: -1.34681105614
Iteration: 931, named_losses: [('ActivationMax Loss', -1.581412),
 ('L-6.0 Norm Loss', 0.022123663),
 ('TV(2.0) Loss', 0.19440807)], overall loss: -1.3648802042
Iteration: 932, named_losses: [('ActivationMax Loss', -1.5894259),
 ('L-6.0 Norm Loss', 0.022124998),
 ('TV(2.0) Loss', 0.19456497)], overall loss: -1.37273597717
Iteration: 933, named_losses: [('ActivationMax Loss', -1.6294583),
 ('L-6.0 Norm Loss', 0.022124831),
 ('TV(2.0) Loss', 0.19386485)], overall loss: -1.41346859932
Iteration: 934, named_losses: [('ActivationMax Loss', -1.6268867),
 ('L-6.0 Norm Loss', 0.022122536),
 ('TV(2.0) Loss', 0.19371618)], overall loss: -1.4110480547
Iteration: 935, named_losses: [('ActivationMax Loss', -1.5913241),
 ('L-6.0 Norm Loss', 0.022122089),
 ('TV(2.0) Loss', 0.1935481)], overall loss: -1.37565386295
Iteration: 936, named_losses: [('ActivationMax Loss', -1.6100743),
 ('L-6.0 Norm Loss', 0.022123564),
 ('TV(2.0) Loss', 0.1945098)], overall loss: -1.39344096184
Iteration: 937, named_losses: [('ActivationMax Loss', -1.6011815),
 ('L-6.0 Norm Loss', 0.022122942),
 ('TV(2.0) Loss', 0.19456284)], overall loss: -1.38449573517
Iteration: 938, named_losses: [('ActivationMax Loss', -1.6530086),
 ('L-6.0 Norm Loss', 0.022123542),
 ('TV(2.0) Loss', 0.19513494)], overall loss: -1.43575000763
Iteration: 939, named_losses: [('ActivationMax Loss', -1.6199336),
 ('L-6.0 Norm Loss', 0.022122592),
 ('TV(2.0) Loss', 0.19330749)], overall loss: -1.4045034647
Iteration: 940, named_losses: [('ActivationMax Loss', -1.556607),
 ('L-6.0 Norm Loss', 0.022121582),
 ('TV(2.0) Loss', 0.1930494)], overall loss: -1.34143602848
Iteration: 941, named_losses: [('ActivationMax Loss', -1.621449),
 ('L-6.0 Norm Loss', 0.022121845),
 ('TV(2.0) Loss', 0.19322388)], overall loss: -1.40610337257
Iteration: 942, named_losses: [('ActivationMax Loss', -1.6194528),
 ('L-6.0 Norm Loss', 0.022122853),
 ('TV(2.0) Loss', 0.19358455)], overall loss: -1.40374541283
Iteration: 943, named_losses: [('ActivationMax Loss', -1.5966868),
 ('L-6.0 Norm Loss', 0.022121526),
 ('TV(2.0) Loss', 0.19270124)], overall loss: -1.38186407089
Iteration: 944, named_losses: [('ActivationMax Loss', -1.5926003),
 ('L-6.0 Norm Loss', 0.022120602),
 ('TV(2.0) Loss', 0.19386387)], overall loss: -1.37661588192
Iteration: 945, named_losses: [('ActivationMax Loss', -1.6192263),
 ('L-6.0 Norm Loss', 0.022120113),
 ('TV(2.0) Loss', 0.19232352)], overall loss: -1.40478265285
Iteration: 946, named_losses: [('ActivationMax Loss', -1.5905313),
 ('L-6.0 Norm Loss', 0.02212072),
 ('TV(2.0) Loss', 0.19245349)], overall loss: -1.37595713139
Iteration: 947, named_losses: [('ActivationMax Loss', -1.5715927),
 ('L-6.0 Norm Loss', 0.022120198),
 ('TV(2.0) Loss', 0.19254476)], overall loss: -1.35692763329
Iteration: 948, named_losses: [('ActivationMax Loss', -1.599928),
 ('L-6.0 Norm Loss', 0.0221196),
 ('TV(2.0) Loss', 0.19343986)], overall loss: -1.38436853886
Iteration: 949, named_losses: [('ActivationMax Loss', -1.6221124),
 ('L-6.0 Norm Loss', 0.022119394),
 ('TV(2.0) Loss', 0.19190553)], overall loss: -1.40808749199
Iteration: 950, named_losses: [('ActivationMax Loss', -1.6040741),
 ('L-6.0 Norm Loss', 0.022120137),
 ('TV(2.0) Loss', 0.19245523)], overall loss: -1.38949871063
Iteration: 951, named_losses: [('ActivationMax Loss', -1.6213076),
 ('L-6.0 Norm Loss', 0.022120334),
 ('TV(2.0) Loss', 0.19332533)], overall loss: -1.40586197376
Iteration: 952, named_losses: [('ActivationMax Loss', -1.5405948),
 ('L-6.0 Norm Loss', 0.022119522),
 ('TV(2.0) Loss', 0.1941185)], overall loss: -1.32435679436
Iteration: 953, named_losses: [('ActivationMax Loss', -1.6106786),
 ('L-6.0 Norm Loss', 0.022119226),
 ('TV(2.0) Loss', 0.19404002)], overall loss: -1.39451920986
Iteration: 954, named_losses: [('ActivationMax Loss', -1.6077299),
 ('L-6.0 Norm Loss', 0.022118896),
 ('TV(2.0) Loss', 0.19488999)], overall loss: -1.39072096348
Iteration: 955, named_losses: [('ActivationMax Loss', -1.6234738),
 ('L-6.0 Norm Loss', 0.022119183),
 ('TV(2.0) Loss', 0.19550034)], overall loss: -1.40585422516
Iteration: 956, named_losses: [('ActivationMax Loss', -1.601933),
 ('L-6.0 Norm Loss', 0.02211949),
 ('TV(2.0) Loss', 0.19468382)], overall loss: -1.38512969017
Iteration: 957, named_losses: [('ActivationMax Loss', -1.6265243),
 ('L-6.0 Norm Loss', 0.02211915),
 ('TV(2.0) Loss', 0.1950011)], overall loss: -1.40940403938
Iteration: 958, named_losses: [('ActivationMax Loss', -1.6151149),
 ('L-6.0 Norm Loss', 0.022121113),
 ('TV(2.0) Loss', 0.19494149)], overall loss: -1.39805233479
Iteration: 959, named_losses: [('ActivationMax Loss', -1.6300839),
 ('L-6.0 Norm Loss', 0.022120528),
 ('TV(2.0) Loss', 0.19385482)], overall loss: -1.414108634
Iteration: 960, named_losses: [('ActivationMax Loss', -1.5932658),
 ('L-6.0 Norm Loss', 0.022118889),
 ('TV(2.0) Loss', 0.19425994)], overall loss: -1.37688684464
Iteration: 961, named_losses: [('ActivationMax Loss', -1.6381464),
 ('L-6.0 Norm Loss', 0.022119377),
 ('TV(2.0) Loss', 0.19396287)], overall loss: -1.42206406593
Iteration: 962, named_losses: [('ActivationMax Loss', -1.6218293),
 ('L-6.0 Norm Loss', 0.022119313),
 ('TV(2.0) Loss', 0.19402085)], overall loss: -1.40568912029
Iteration: 963, named_losses: [('ActivationMax Loss', -1.6081573),
 ('L-6.0 Norm Loss', 0.022119775),
 ('TV(2.0) Loss', 0.19315279)], overall loss: -1.39288473129
Iteration: 964, named_losses: [('ActivationMax Loss', -1.5953921),
 ('L-6.0 Norm Loss', 0.022119431),
 ('TV(2.0) Loss', 0.19351539)], overall loss: -1.37975728512
Iteration: 965, named_losses: [('ActivationMax Loss', -1.6165572),
 ('L-6.0 Norm Loss', 0.022119131),
 ('TV(2.0) Loss', 0.19376279)], overall loss: -1.40067529678
Iteration: 966, named_losses: [('ActivationMax Loss', -1.5926439),
 ('L-6.0 Norm Loss', 0.022119621),
 ('TV(2.0) Loss', 0.19441852)], overall loss: -1.37610566616
Iteration: 967, named_losses: [('ActivationMax Loss', -1.6041864),
 ('L-6.0 Norm Loss', 0.022118248),
 ('TV(2.0) Loss', 0.19245557)], overall loss: -1.38961267471
Iteration: 968, named_losses: [('ActivationMax Loss', -1.6125435),
 ('L-6.0 Norm Loss', 0.022118382),
 ('TV(2.0) Loss', 0.19364065)], overall loss: -1.39678454399
Iteration: 969, named_losses: [('ActivationMax Loss', -1.6476578),
 ('L-6.0 Norm Loss', 0.022117598),
 ('TV(2.0) Loss', 0.19187242)], overall loss: -1.43366765976
Iteration: 970, named_losses: [('ActivationMax Loss', -1.5763552),
 ('L-6.0 Norm Loss', 0.022116166),
 ('TV(2.0) Loss', 0.19258264)], overall loss: -1.36165642738
Iteration: 971, named_losses: [('ActivationMax Loss', -1.6125495),
 ('L-6.0 Norm Loss', 0.022118798),
 ('TV(2.0) Loss', 0.19206323)], overall loss: -1.39836752415
Iteration: 972, named_losses: [('ActivationMax Loss', -1.6337342),
 ('L-6.0 Norm Loss', 0.02211589),
 ('TV(2.0) Loss', 0.19310006)], overall loss: -1.41851818562
Iteration: 973, named_losses: [('ActivationMax Loss', -1.5879285),
 ('L-6.0 Norm Loss', 0.02211751),
 ('TV(2.0) Loss', 0.19232181)], overall loss: -1.37348926067
Iteration: 974, named_losses: [('ActivationMax Loss', -1.6036288),
 ('L-6.0 Norm Loss', 0.022117293),
 ('TV(2.0) Loss', 0.19355693)], overall loss: -1.3879545927
Iteration: 975, named_losses: [('ActivationMax Loss', -1.6170654),
 ('L-6.0 Norm Loss', 0.022118878),
 ('TV(2.0) Loss', 0.1935275)], overall loss: -1.40141904354
Iteration: 976, named_losses: [('ActivationMax Loss', -1.6262754),
 ('L-6.0 Norm Loss', 0.022115197),
 ('TV(2.0) Loss', 0.19311878)], overall loss: -1.41104137897
Iteration: 977, named_losses: [('ActivationMax Loss', -1.6108602),
 ('L-6.0 Norm Loss', 0.022114336),
 ('TV(2.0) Loss', 0.19216935)], overall loss: -1.39657652378
Iteration: 978, named_losses: [('ActivationMax Loss', -1.5883455),
 ('L-6.0 Norm Loss', 0.022116445),
 ('TV(2.0) Loss', 0.19228616)], overall loss: -1.37394297123
Iteration: 979, named_losses: [('ActivationMax Loss', -1.629903),
 ('L-6.0 Norm Loss', 0.022117531),
 ('TV(2.0) Loss', 0.19249654)], overall loss: -1.41528892517
Iteration: 980, named_losses: [('ActivationMax Loss', -1.5968302),
 ('L-6.0 Norm Loss', 0.022116385),
 ('TV(2.0) Loss', 0.1949781)], overall loss: -1.37973570824
Iteration: 981, named_losses: [('ActivationMax Loss', -1.5993174),
 ('L-6.0 Norm Loss', 0.022116566),
 ('TV(2.0) Loss', 0.1941155)], overall loss: -1.38308537006
Iteration: 982, named_losses: [('ActivationMax Loss', -1.6268679),
 ('L-6.0 Norm Loss', 0.022117821),
 ('TV(2.0) Loss', 0.19628547)], overall loss: -1.40846455097
Iteration: 983, named_losses: [('ActivationMax Loss', -1.6008006),
 ('L-6.0 Norm Loss', 0.022115262),
 ('TV(2.0) Loss', 0.19406272)], overall loss: -1.38462269306
Iteration: 984, named_losses: [('ActivationMax Loss', -1.5875535),
 ('L-6.0 Norm Loss', 0.022115184),
 ('TV(2.0) Loss', 0.19552928)], overall loss: -1.36990904808
Iteration: 985, named_losses: [('ActivationMax Loss', -1.5879322),
 ('L-6.0 Norm Loss', 0.022116169),
 ('TV(2.0) Loss', 0.19701599)], overall loss: -1.36880004406
Iteration: 986, named_losses: [('ActivationMax Loss', -1.6098045),
 ('L-6.0 Norm Loss', 0.0221164),
 ('TV(2.0) Loss', 0.19662012)], overall loss: -1.39106798172
Iteration: 987, named_losses: [('ActivationMax Loss', -1.5833932),
 ('L-6.0 Norm Loss', 0.02211638),
 ('TV(2.0) Loss', 0.19700976)], overall loss: -1.36426699162
Iteration: 988, named_losses: [('ActivationMax Loss', -1.6018641),
 ('L-6.0 Norm Loss', 0.022116285),
 ('TV(2.0) Loss', 0.19644202)], overall loss: -1.38330578804
Iteration: 989, named_losses: [('ActivationMax Loss', -1.5918381),
 ('L-6.0 Norm Loss', 0.022116236),
 ('TV(2.0) Loss', 0.19829263)], overall loss: -1.37142932415
Iteration: 990, named_losses: [('ActivationMax Loss', -1.5962492),
 ('L-6.0 Norm Loss', 0.022115696),
 ('TV(2.0) Loss', 0.19744793)], overall loss: -1.37668561935
Iteration: 991, named_losses: [('ActivationMax Loss', -1.6090828),
 ('L-6.0 Norm Loss', 0.022116296),
 ('TV(2.0) Loss', 0.19721518)], overall loss: -1.38975131512
Iteration: 992, named_losses: [('ActivationMax Loss', -1.6302073),
 ('L-6.0 Norm Loss', 0.022115465),
 ('TV(2.0) Loss', 0.19661035)], overall loss: -1.41148149967
Iteration: 993, named_losses: [('ActivationMax Loss', -1.6058443),
 ('L-6.0 Norm Loss', 0.022116529),
 ('TV(2.0) Loss', 0.19516826)], overall loss: -1.38855946064
Iteration: 994, named_losses: [('ActivationMax Loss', -1.6247122),
 ('L-6.0 Norm Loss', 0.022115318),
 ('TV(2.0) Loss', 0.19627485)], overall loss: -1.40632200241
Iteration: 995, named_losses: [('ActivationMax Loss', -1.5945442),
 ('L-6.0 Norm Loss', 0.022116464),
 ('TV(2.0) Loss', 0.19501552)], overall loss: -1.37741219997
Iteration: 996, named_losses: [('ActivationMax Loss', -1.6189446),
 ('L-6.0 Norm Loss', 0.022115692),
 ('TV(2.0) Loss', 0.19602294)], overall loss: -1.40080595016
Iteration: 997, named_losses: [('ActivationMax Loss', -1.564819),
 ('L-6.0 Norm Loss', 0.022116171),
 ('TV(2.0) Loss', 0.19540516)], overall loss: -1.34729766846
Iteration: 998, named_losses: [('ActivationMax Loss', -1.5978329),
 ('L-6.0 Norm Loss', 0.02211513),
 ('TV(2.0) Loss', 0.19616266)], overall loss: -1.37955510616
Iteration: 999, named_losses: [('ActivationMax Loss', -1.5516376),
 ('L-6.0 Norm Loss', 0.022115184),
 ('TV(2.0) Loss', 0.19714493)], overall loss: -1.33237743378
Iteration: 1000, named_losses: [('ActivationMax Loss', -1.5821873),
 ('L-6.0 Norm Loss', 0.022116084),
 ('TV(2.0) Loss', 0.19927998)], overall loss: -1.36079120636
Iteration: 1001, named_losses: [('ActivationMax Loss', -1.559775),
 ('L-6.0 Norm Loss', 0.022115225),
 ('TV(2.0) Loss', 0.20068663)], overall loss: -1.33697319031
Iteration: 1002, named_losses: [('ActivationMax Loss', -1.5858052),
 ('L-6.0 Norm Loss', 0.022115717),
 ('TV(2.0) Loss', 0.20175321)], overall loss: -1.36193621159
Iteration: 1003, named_losses: [('ActivationMax Loss', -1.5685925),
 ('L-6.0 Norm Loss', 0.022115959),
 ('TV(2.0) Loss', 0.20049061)], overall loss: -1.34598600864
Iteration: 1004, named_losses: [('ActivationMax Loss', -1.5647589),
 ('L-6.0 Norm Loss', 0.022115719),
 ('TV(2.0) Loss', 0.20265283)], overall loss: -1.33999037743
Iteration: 1005, named_losses: [('ActivationMax Loss', -1.5498275),
 ('L-6.0 Norm Loss', 0.022116285),
 ('TV(2.0) Loss', 0.20301278)], overall loss: -1.32469832897
Iteration: 1006, named_losses: [('ActivationMax Loss', -1.5984043),
 ('L-6.0 Norm Loss', 0.022117419),
 ('TV(2.0) Loss', 0.20337169)], overall loss: -1.37291526794
Iteration: 1007, named_losses: [('ActivationMax Loss', -1.5839036),
 ('L-6.0 Norm Loss', 0.022116883),
 ('TV(2.0) Loss', 0.20178516)], overall loss: -1.36000144482
Iteration: 1008, named_losses: [('ActivationMax Loss', -1.5709929),
 ('L-6.0 Norm Loss', 0.022117652),
 ('TV(2.0) Loss', 0.20087975)], overall loss: -1.34799551964
Iteration: 1009, named_losses: [('ActivationMax Loss', -1.6124966),
 ('L-6.0 Norm Loss', 0.022117214),
 ('TV(2.0) Loss', 0.20113273)], overall loss: -1.38924658298
Iteration: 1010, named_losses: [('ActivationMax Loss', -1.5990965),
 ('L-6.0 Norm Loss', 0.022116967),
 ('TV(2.0) Loss', 0.2001341)], overall loss: -1.3768453598
Iteration: 1011, named_losses: [('ActivationMax Loss', -1.6158639),
 ('L-6.0 Norm Loss', 0.022115523),
 ('TV(2.0) Loss', 0.19947872)], overall loss: -1.39426970482
Iteration: 1012, named_losses: [('ActivationMax Loss', -1.5269034),
 ('L-6.0 Norm Loss', 0.022115126),
 ('TV(2.0) Loss', 0.19971772)], overall loss: -1.30507051945
Iteration: 1013, named_losses: [('ActivationMax Loss', -1.5623492),
 ('L-6.0 Norm Loss', 0.022114722),
 ('TV(2.0) Loss', 0.20048438)], overall loss: -1.3397500515
Iteration: 1014, named_losses: [('ActivationMax Loss', -1.6265564),
 ('L-6.0 Norm Loss', 0.022115774),
 ('TV(2.0) Loss', 0.19934535)], overall loss: -1.40509521961
Iteration: 1015, named_losses: [('ActivationMax Loss', -1.6196852),
 ('L-6.0 Norm Loss', 0.022113934),
 ('TV(2.0) Loss', 0.19853446)], overall loss: -1.3990367651
Iteration: 1016, named_losses: [('ActivationMax Loss', -1.6248971),
 ('L-6.0 Norm Loss', 0.022113461),
 ('TV(2.0) Loss', 0.1975674)], overall loss: -1.40521621704
Iteration: 1017, named_losses: [('ActivationMax Loss', -1.6175346),
 ('L-6.0 Norm Loss', 0.022114016),
 ('TV(2.0) Loss', 0.19592643)], overall loss: -1.39949417114
Iteration: 1018, named_losses: [('ActivationMax Loss', -1.5903354),
 ('L-6.0 Norm Loss', 0.022112578),
 ('TV(2.0) Loss', 0.19597445)], overall loss: -1.37224829197
Iteration: 1019, named_losses: [('ActivationMax Loss', -1.6257697),
 ('L-6.0 Norm Loss', 0.022114098),
 ('TV(2.0) Loss', 0.19526529)], overall loss: -1.40839028358
Iteration: 1020, named_losses: [('ActivationMax Loss', -1.645171),
 ('L-6.0 Norm Loss', 0.022112837),
 ('TV(2.0) Loss', 0.1955988)], overall loss: -1.42745935917
Iteration: 1021, named_losses: [('ActivationMax Loss', -1.6185639),
 ('L-6.0 Norm Loss', 0.022112429),
 ('TV(2.0) Loss', 0.19320297)], overall loss: -1.40324854851
Iteration: 1022, named_losses: [('ActivationMax Loss', -1.5987674),
 ('L-6.0 Norm Loss', 0.022111747),
 ('TV(2.0) Loss', 0.19371046)], overall loss: -1.38294517994
Iteration: 1023, named_losses: [('ActivationMax Loss', -1.6128269),
 ('L-6.0 Norm Loss', 0.022112204),
 ('TV(2.0) Loss', 0.1931299)], overall loss: -1.39758479595
Iteration: 1024, named_losses: [('ActivationMax Loss', -1.6292872),
 ('L-6.0 Norm Loss', 0.02211161),
 ('TV(2.0) Loss', 0.19343533)], overall loss: -1.41374027729
Iteration: 1025, named_losses: [('ActivationMax Loss', -1.6353798),
 ('L-6.0 Norm Loss', 0.022111686),
 ('TV(2.0) Loss', 0.19327568)], overall loss: -1.4199924469
Iteration: 1026, named_losses: [('ActivationMax Loss', -1.5979655),
 ('L-6.0 Norm Loss', 0.022110103),
 ('TV(2.0) Loss', 0.19239011)], overall loss: -1.38346529007
Iteration: 1027, named_losses: [('ActivationMax Loss', -1.6271257),
 ('L-6.0 Norm Loss', 0.022109546),
 ('TV(2.0) Loss', 0.19155031)], overall loss: -1.41346597672
Iteration: 1028, named_losses: [('ActivationMax Loss', -1.6243646),
 ('L-6.0 Norm Loss', 0.022109147),
 ('TV(2.0) Loss', 0.19122335)], overall loss: -1.41103208065
Iteration: 1029, named_losses: [('ActivationMax Loss', -1.6466764),
 ('L-6.0 Norm Loss', 0.02210943),
 ('TV(2.0) Loss', 0.19123366)], overall loss: -1.43333339691
Iteration: 1030, named_losses: [('ActivationMax Loss', -1.615301),
 ('L-6.0 Norm Loss', 0.022109458),
 ('TV(2.0) Loss', 0.19178091)], overall loss: -1.40141057968
Iteration: 1031, named_losses: [('ActivationMax Loss', -1.6214304),
 ('L-6.0 Norm Loss', 0.022108683),
 ('TV(2.0) Loss', 0.19125579)], overall loss: -1.40806591511
Iteration: 1032, named_losses: [('ActivationMax Loss', -1.5739428),
 ('L-6.0 Norm Loss', 0.022108043),
 ('TV(2.0) Loss', 0.19265549)], overall loss: -1.35917925835
Iteration: 1033, named_losses: [('ActivationMax Loss', -1.6025327),
 ('L-6.0 Norm Loss', 0.022108601),
 ('TV(2.0) Loss', 0.19472417)], overall loss: -1.38569998741
Iteration: 1034, named_losses: [('ActivationMax Loss', -1.5795928),
 ('L-6.0 Norm Loss', 0.022109227),
 ('TV(2.0) Loss', 0.19424629)], overall loss: -1.36323726177
Iteration: 1035, named_losses: [('ActivationMax Loss', -1.6373076),
 ('L-6.0 Norm Loss', 0.022108497),
 ('TV(2.0) Loss', 0.19417234)], overall loss: -1.4210267067
Iteration: 1036, named_losses: [('ActivationMax Loss', -1.5808991),
 ('L-6.0 Norm Loss', 0.022108527),
 ('TV(2.0) Loss', 0.19346727)], overall loss: -1.36532330513
Iteration: 1037, named_losses: [('ActivationMax Loss', -1.5777018),
 ('L-6.0 Norm Loss', 0.022107903),
 ('TV(2.0) Loss', 0.19326933)], overall loss: -1.36232447624
Iteration: 1038, named_losses: [('ActivationMax Loss', -1.6376441),
 ('L-6.0 Norm Loss', 0.022108203),
 ('TV(2.0) Loss', 0.19347699)], overall loss: -1.42205882072
Iteration: 1039, named_losses: [('ActivationMax Loss', -1.6565989),
 ('L-6.0 Norm Loss', 0.022108786),
 ('TV(2.0) Loss', 0.19381995)], overall loss: -1.44067013264
Iteration: 1040, named_losses: [('ActivationMax Loss', -1.600843),
 ('L-6.0 Norm Loss', 0.022105884),
 ('TV(2.0) Loss', 0.19258562)], overall loss: -1.38615143299
Iteration: 1041, named_losses: [('ActivationMax Loss', -1.6418655),
 ('L-6.0 Norm Loss', 0.022105347),
 ('TV(2.0) Loss', 0.19366223)], overall loss: -1.42609786987
Iteration: 1042, named_losses: [('ActivationMax Loss', -1.6407142),
 ('L-6.0 Norm Loss', 0.02210564),
 ('TV(2.0) Loss', 0.19234629)], overall loss: -1.42626214027
Iteration: 1043, named_losses: [('ActivationMax Loss', -1.5995356),
 ('L-6.0 Norm Loss', 0.022105351),
 ('TV(2.0) Loss', 0.19273609)], overall loss: -1.38469409943
Iteration: 1044, named_losses: [('ActivationMax Loss', -1.5922254),
 ('L-6.0 Norm Loss', 0.022104865),
 ('TV(2.0) Loss', 0.19171365)], overall loss: -1.37840688229
Iteration: 1045, named_losses: [('ActivationMax Loss', -1.6548669),
 ('L-6.0 Norm Loss', 0.022105668),
 ('TV(2.0) Loss', 0.1926863)], overall loss: -1.44007492065
Iteration: 1046, named_losses: [('ActivationMax Loss', -1.6309446),
 ('L-6.0 Norm Loss', 0.022104029),
 ('TV(2.0) Loss', 0.19052686)], overall loss: -1.41831374168
Iteration: 1047, named_losses: [('ActivationMax Loss', -1.6332787),
 ('L-6.0 Norm Loss', 0.022103366),
 ('TV(2.0) Loss', 0.19069406)], overall loss: -1.4204813242
Iteration: 1048, named_losses: [('ActivationMax Loss', -1.593642),
 ('L-6.0 Norm Loss', 0.022103703),
 ('TV(2.0) Loss', 0.1898897)], overall loss: -1.38164865971
Iteration: 1049, named_losses: [('ActivationMax Loss', -1.6337781),
 ('L-6.0 Norm Loss', 0.022103759),
 ('TV(2.0) Loss', 0.19093536)], overall loss: -1.42073893547
Iteration: 1050, named_losses: [('ActivationMax Loss', -1.6069764),
 ('L-6.0 Norm Loss', 0.022102976),
 ('TV(2.0) Loss', 0.19058704)], overall loss: -1.39428639412
Iteration: 1051, named_losses: [('ActivationMax Loss', -1.5487931),
 ('L-6.0 Norm Loss', 0.022104792),
 ('TV(2.0) Loss', 0.19341272)], overall loss: -1.33327555656
Iteration: 1052, named_losses: [('ActivationMax Loss', -1.5621345),
 ('L-6.0 Norm Loss', 0.022104559),
 ('TV(2.0) Loss', 0.19452511)], overall loss: -1.34550487995
Iteration: 1053, named_losses: [('ActivationMax Loss', -1.6079577),
 ('L-6.0 Norm Loss', 0.022103878),
 ('TV(2.0) Loss', 0.19592844)], overall loss: -1.38992536068
Iteration: 1054, named_losses: [('ActivationMax Loss', -1.6293688),
 ('L-6.0 Norm Loss', 0.022103544),
 ('TV(2.0) Loss', 0.19501495)], overall loss: -1.41225028038
Iteration: 1055, named_losses: [('ActivationMax Loss', -1.6066146),
 ('L-6.0 Norm Loss', 0.022102853),
 ('TV(2.0) Loss', 0.19536865)], overall loss: -1.38914310932
Iteration: 1056, named_losses: [('ActivationMax Loss', -1.6259909),
 ('L-6.0 Norm Loss', 0.022103623),
 ('TV(2.0) Loss', 0.19370279)], overall loss: -1.41018438339
Iteration: 1057, named_losses: [('ActivationMax Loss', -1.6512029),
 ('L-6.0 Norm Loss', 0.022103328),
 ('TV(2.0) Loss', 0.1950822)], overall loss: -1.43401741982
Iteration: 1058, named_losses: [('ActivationMax Loss', -1.6312276),
 ('L-6.0 Norm Loss', 0.022101566),
 ('TV(2.0) Loss', 0.19228141)], overall loss: -1.41684472561
Iteration: 1059, named_losses: [('ActivationMax Loss', -1.6123985),
 ('L-6.0 Norm Loss', 0.022101615),
 ('TV(2.0) Loss', 0.19238308)], overall loss: -1.39791381359
Iteration: 1060, named_losses: [('ActivationMax Loss', -1.5578296),
 ('L-6.0 Norm Loss', 0.022101345),
 ('TV(2.0) Loss', 0.19074614)], overall loss: -1.34498202801
Iteration: 1061, named_losses: [('ActivationMax Loss', -1.6386549),
 ('L-6.0 Norm Loss', 0.02210176),
 ('TV(2.0) Loss', 0.19362997)], overall loss: -1.42292320728
Iteration: 1062, named_losses: [('ActivationMax Loss', -1.5846778),
 ('L-6.0 Norm Loss', 0.022099219),
 ('TV(2.0) Loss', 0.19151506)], overall loss: -1.37106347084
Iteration: 1063, named_losses: [('ActivationMax Loss', -1.5933319),
 ('L-6.0 Norm Loss', 0.022100156),
 ('TV(2.0) Loss', 0.19442031)], overall loss: -1.37681138515
Iteration: 1064, named_losses: [('ActivationMax Loss', -1.5994539),
 ('L-6.0 Norm Loss', 0.022100329),
 ('TV(2.0) Loss', 0.19397998)], overall loss: -1.38337361813
Iteration: 1065, named_losses: [('ActivationMax Loss', -1.6024895),
 ('L-6.0 Norm Loss', 0.02210094),
 ('TV(2.0) Loss', 0.19549288)], overall loss: -1.38489568233
Iteration: 1066, named_losses: [('ActivationMax Loss', -1.6122282),
 ('L-6.0 Norm Loss', 0.022101596),
 ('TV(2.0) Loss', 0.19547233)], overall loss: -1.39465415478
Iteration: 1067, named_losses: [('ActivationMax Loss', -1.5916462),
 ('L-6.0 Norm Loss', 0.022099733),
 ('TV(2.0) Loss', 0.19596863)], overall loss: -1.37357783318
Iteration: 1068, named_losses: [('ActivationMax Loss', -1.6151124),
 ('L-6.0 Norm Loss', 0.022098711),
 ('TV(2.0) Loss', 0.19618008)], overall loss: -1.39683365822
Iteration: 1069, named_losses: [('ActivationMax Loss', -1.6493597),
 ('L-6.0 Norm Loss', 0.022098718),
 ('TV(2.0) Loss', 0.19680998)], overall loss: -1.4304510355
Iteration: 1070, named_losses: [('ActivationMax Loss', -1.6045166),
 ('L-6.0 Norm Loss', 0.02210103),
 ('TV(2.0) Loss', 0.19493325)], overall loss: -1.3874822855
Iteration: 1071, named_losses: [('ActivationMax Loss', -1.6418362),
 ('L-6.0 Norm Loss', 0.022099003),
 ('TV(2.0) Loss', 0.19698109)], overall loss: -1.42275607586
Iteration: 1072, named_losses: [('ActivationMax Loss', -1.6343153),
 ('L-6.0 Norm Loss', 0.022097949),
 ('TV(2.0) Loss', 0.19498277)], overall loss: -1.41723453999
Iteration: 1073, named_losses: [('ActivationMax Loss', -1.5678198),
 ('L-6.0 Norm Loss', 0.022097889),
 ('TV(2.0) Loss', 0.19550537)], overall loss: -1.35021650791
Iteration: 1074, named_losses: [('ActivationMax Loss', -1.5640051),
 ('L-6.0 Norm Loss', 0.022098573),
 ('TV(2.0) Loss', 0.19581413)], overall loss: -1.34609246254
Iteration: 1075, named_losses: [('ActivationMax Loss', -1.6311986),
 ('L-6.0 Norm Loss', 0.022099026),
 ('TV(2.0) Loss', 0.19726938)], overall loss: -1.41183018684
Iteration: 1076, named_losses: [('ActivationMax Loss', -1.584938),
 ('L-6.0 Norm Loss', 0.022097595),
 ('TV(2.0) Loss', 0.19549984)], overall loss: -1.36734056473
Iteration: 1077, named_losses: [('ActivationMax Loss', -1.5997401),
 ('L-6.0 Norm Loss', 0.022097526),
 ('TV(2.0) Loss', 0.19617328)], overall loss: -1.38146936893
Iteration: 1078, named_losses: [('ActivationMax Loss', -1.6140958),
 ('L-6.0 Norm Loss', 0.022098115),
 ('TV(2.0) Loss', 0.19603676)], overall loss: -1.39596104622
Iteration: 1079, named_losses: [('ActivationMax Loss', -1.6240418),
 ('L-6.0 Norm Loss', 0.022097694),
 ('TV(2.0) Loss', 0.19564188)], overall loss: -1.40630221367
Iteration: 1080, named_losses: [('ActivationMax Loss', -1.6036233),
 ('L-6.0 Norm Loss', 0.022097643),
 ('TV(2.0) Loss', 0.19637389)], overall loss: -1.38515174389
Iteration: 1081, named_losses: [('ActivationMax Loss', -1.5997462),
 ('L-6.0 Norm Loss', 0.022097841),
 ('TV(2.0) Loss', 0.19385214)], overall loss: -1.38379621506
Iteration: 1082, named_losses: [('ActivationMax Loss', -1.5606742),
 ('L-6.0 Norm Loss', 0.022097548),
 ('TV(2.0) Loss', 0.19590648)], overall loss: -1.34267008305
Iteration: 1083, named_losses: [('ActivationMax Loss', -1.6230328),
 ('L-6.0 Norm Loss', 0.022097237),
 ('TV(2.0) Loss', 0.19441462)], overall loss: -1.40652096272
Iteration: 1084, named_losses: [('ActivationMax Loss', -1.5855983),
 ('L-6.0 Norm Loss', 0.022096058),
 ('TV(2.0) Loss', 0.19521102)], overall loss: -1.36829125881
Iteration: 1085, named_losses: [('ActivationMax Loss', -1.6201161),
 ('L-6.0 Norm Loss', 0.022094751),
 ('TV(2.0) Loss', 0.19340679)], overall loss: -1.40461456776
Iteration: 1086, named_losses: [('ActivationMax Loss', -1.6026794),
 ('L-6.0 Norm Loss', 0.022094388),
 ('TV(2.0) Loss', 0.19288711)], overall loss: -1.3876979351
Iteration: 1087, named_losses: [('ActivationMax Loss', -1.6216638),
 ('L-6.0 Norm Loss', 0.022094594),
 ('TV(2.0) Loss', 0.19269468)], overall loss: -1.40687453747
Iteration: 1088, named_losses: [('ActivationMax Loss', -1.6402689),
 ('L-6.0 Norm Loss', 0.022095136),
 ('TV(2.0) Loss', 0.19345684)], overall loss: -1.42471694946
Iteration: 1089, named_losses: [('ActivationMax Loss', -1.605105),
 ('L-6.0 Norm Loss', 0.022095164),
 ('TV(2.0) Loss', 0.19278923)], overall loss: -1.39022064209
Iteration: 1090, named_losses: [('ActivationMax Loss', -1.6357989),
 ('L-6.0 Norm Loss', 0.022095116),
 ('TV(2.0) Loss', 0.19227567)], overall loss: -1.42142820358
Iteration: 1091, named_losses: [('ActivationMax Loss', -1.6138598),
 ('L-6.0 Norm Loss', 0.022094296),
 ('TV(2.0) Loss', 0.19347204)], overall loss: -1.39829349518
Iteration: 1092, named_losses: [('ActivationMax Loss', -1.5955399),
 ('L-6.0 Norm Loss', 0.022093695),
 ('TV(2.0) Loss', 0.19205777)], overall loss: -1.38138854504
Iteration: 1093, named_losses: [('ActivationMax Loss', -1.6263322),
 ('L-6.0 Norm Loss', 0.022092775),
 ('TV(2.0) Loss', 0.19254895)], overall loss: -1.41169035435
Iteration: 1094, named_losses: [('ActivationMax Loss', -1.6031816),
 ('L-6.0 Norm Loss', 0.02209367),
 ('TV(2.0) Loss', 0.19198617)], overall loss: -1.3891017437
Iteration: 1095, named_losses: [('ActivationMax Loss', -1.6371382),
 ('L-6.0 Norm Loss', 0.022091756),
 ('TV(2.0) Loss', 0.19141839)], overall loss: -1.42362809181
Iteration: 1096, named_losses: [('ActivationMax Loss', -1.6317856),
 ('L-6.0 Norm Loss', 0.022093903),
 ('TV(2.0) Loss', 0.19098023)], overall loss: -1.41871154308
Iteration: 1097, named_losses: [('ActivationMax Loss', -1.6467775),
 ('L-6.0 Norm Loss', 0.022091243),
 ('TV(2.0) Loss', 0.19174385)], overall loss: -1.43294239044
Iteration: 1098, named_losses: [('ActivationMax Loss', -1.6109174),
 ('L-6.0 Norm Loss', 0.022092219),
 ('TV(2.0) Loss', 0.19139218)], overall loss: -1.39743304253
Iteration: 1099, named_losses: [('ActivationMax Loss', -1.6242429),
 ('L-6.0 Norm Loss', 0.022091994),
 ('TV(2.0) Loss', 0.19076791)], overall loss: -1.4113830328
Iteration: 1100, named_losses: [('ActivationMax Loss', -1.6263038),
 ('L-6.0 Norm Loss', 0.022091202),
 ('TV(2.0) Loss', 0.18980193)], overall loss: -1.41441071033
Iteration: 1101, named_losses: [('ActivationMax Loss', -1.6473955),
 ('L-6.0 Norm Loss', 0.022091873),
 ('TV(2.0) Loss', 0.19132535)], overall loss: -1.43397831917
Iteration: 1102, named_losses: [('ActivationMax Loss', -1.6339399),
 ('L-6.0 Norm Loss', 0.022091232),
 ('TV(2.0) Loss', 0.19042233)], overall loss: -1.42142629623
Iteration: 1103, named_losses: [('ActivationMax Loss', -1.6518537),
 ('L-6.0 Norm Loss', 0.022089669),
 ('TV(2.0) Loss', 0.19160613)], overall loss: -1.43815779686
Iteration: 1104, named_losses: [('ActivationMax Loss', -1.5963092),
 ('L-6.0 Norm Loss', 0.02209245),
 ('TV(2.0) Loss', 0.19270149)], overall loss: -1.38151526451
Iteration: 1105, named_losses: [('ActivationMax Loss', -1.6165555),
 ('L-6.0 Norm Loss', 0.022091242),
 ('TV(2.0) Loss', 0.19269252)], overall loss: -1.40177166462
Iteration: 1106, named_losses: [('ActivationMax Loss', -1.5627724),
 ('L-6.0 Norm Loss', 0.022090573),
 ('TV(2.0) Loss', 0.19413455)], overall loss: -1.34654724598
Iteration: 1107, named_losses: [('ActivationMax Loss', -1.6244687),
 ('L-6.0 Norm Loss', 0.022091528),
 ('TV(2.0) Loss', 0.19377109)], overall loss: -1.4086060524
Iteration: 1108, named_losses: [('ActivationMax Loss', -1.6522448),
 ('L-6.0 Norm Loss', 0.022090446),
 ('TV(2.0) Loss', 0.19250818)], overall loss: -1.43764615059
Iteration: 1109, named_losses: [('ActivationMax Loss', -1.6552858),
 ('L-6.0 Norm Loss', 0.022090834),
 ('TV(2.0) Loss', 0.1928428)], overall loss: -1.44035220146
Iteration: 1110, named_losses: [('ActivationMax Loss', -1.6536978),
 ('L-6.0 Norm Loss', 0.022089332),
 ('TV(2.0) Loss', 0.19116211)], overall loss: -1.4404463768
Iteration: 1111, named_losses: [('ActivationMax Loss', -1.6458907),
 ('L-6.0 Norm Loss', 0.022088874),
 ('TV(2.0) Loss', 0.19095123)], overall loss: -1.43285059929
Iteration: 1112, named_losses: [('ActivationMax Loss', -1.5794331),
 ('L-6.0 Norm Loss', 0.022088364),
 ('TV(2.0) Loss', 0.19124319)], overall loss: -1.36610150337
Iteration: 1113, named_losses: [('ActivationMax Loss', -1.6109489),
 ('L-6.0 Norm Loss', 0.022089181),
 ('TV(2.0) Loss', 0.19285278)], overall loss: -1.396007061
Iteration: 1114, named_losses: [('ActivationMax Loss', -1.5890485),
 ('L-6.0 Norm Loss', 0.022089582),
 ('TV(2.0) Loss', 0.19284606)], overall loss: -1.37411284447
Iteration: 1115, named_losses: [('ActivationMax Loss', -1.6251698),
 ('L-6.0 Norm Loss', 0.022089789),
 ('TV(2.0) Loss', 0.19423984)], overall loss: -1.40884006023
Iteration: 1116, named_losses: [('ActivationMax Loss', -1.6192836),
 ('L-6.0 Norm Loss', 0.022089014),
 ('TV(2.0) Loss', 0.19384928)], overall loss: -1.40334522724
Iteration: 1117, named_losses: [('ActivationMax Loss', -1.6415591),
 ('L-6.0 Norm Loss', 0.022089954),
 ('TV(2.0) Loss', 0.19530445)], overall loss: -1.42416477203
Iteration: 1118, named_losses: [('ActivationMax Loss', -1.6024536),
 ('L-6.0 Norm Loss', 0.02208823),
 ('TV(2.0) Loss', 0.19325979)], overall loss: -1.38710558414
Iteration: 1119, named_losses: [('ActivationMax Loss', -1.6057124),
 ('L-6.0 Norm Loss', 0.022087518),
 ('TV(2.0) Loss', 0.19280571)], overall loss: -1.39081907272
Iteration: 1120, named_losses: [('ActivationMax Loss', -1.6006579),
 ('L-6.0 Norm Loss', 0.022087567),
 ('TV(2.0) Loss', 0.19316204)], overall loss: -1.38540828228
Iteration: 1121, named_losses: [('ActivationMax Loss', -1.5828251),
 ('L-6.0 Norm Loss', 0.022088122),
 ('TV(2.0) Loss', 0.19417758)], overall loss: -1.36655926704
Iteration: 1122, named_losses: [('ActivationMax Loss', -1.6253467),
 ('L-6.0 Norm Loss', 0.022089224),
 ('TV(2.0) Loss', 0.19438484)], overall loss: -1.40887260437
Iteration: 1123, named_losses: [('ActivationMax Loss', -1.5385338),
 ('L-6.0 Norm Loss', 0.022088688),
 ('TV(2.0) Loss', 0.19406326)], overall loss: -1.32238185406
Iteration: 1124, named_losses: [('ActivationMax Loss', -1.6154543),
 ('L-6.0 Norm Loss', 0.022087947),
 ('TV(2.0) Loss', 0.19501761)], overall loss: -1.39834880829
Iteration: 1125, named_losses: [('ActivationMax Loss', -1.5869459),
 ('L-6.0 Norm Loss', 0.022087673),
 ('TV(2.0) Loss', 0.19472763)], overall loss: -1.37013053894
Iteration: 1126, named_losses: [('ActivationMax Loss', -1.5710639),
 ('L-6.0 Norm Loss', 0.022088159),
 ('TV(2.0) Loss', 0.19577537)], overall loss: -1.35320031643
Iteration: 1127, named_losses: [('ActivationMax Loss', -1.6050367),
 ('L-6.0 Norm Loss', 0.022088602),
 ('TV(2.0) Loss', 0.19673425)], overall loss: -1.38621377945
Iteration: 1128, named_losses: [('ActivationMax Loss', -1.6083307),
 ('L-6.0 Norm Loss', 0.022087023),
 ('TV(2.0) Loss', 0.1968029)], overall loss: -1.38944089413
Iteration: 1129, named_losses: [('ActivationMax Loss', -1.6182606),
 ('L-6.0 Norm Loss', 0.022086486),
 ('TV(2.0) Loss', 0.19476353)], overall loss: -1.40141057968
Iteration: 1130, named_losses: [('ActivationMax Loss', -1.6426772),
 ('L-6.0 Norm Loss', 0.022086009),
 ('TV(2.0) Loss', 0.19545385)], overall loss: -1.42513728142
Iteration: 1131, named_losses: [('ActivationMax Loss', -1.6110218),
 ('L-6.0 Norm Loss', 0.022086464),
 ('TV(2.0) Loss', 0.19482739)], overall loss: -1.3941078186
Iteration: 1132, named_losses: [('ActivationMax Loss', -1.6401006),
 ('L-6.0 Norm Loss', 0.022086333),
 ('TV(2.0) Loss', 0.19520579)], overall loss: -1.42280840874
Iteration: 1133, named_losses: [('ActivationMax Loss', -1.589678),
 ('L-6.0 Norm Loss', 0.022084866),
 ('TV(2.0) Loss', 0.19378433)], overall loss: -1.37380886078
Iteration: 1134, named_losses: [('ActivationMax Loss', -1.6086079),
 ('L-6.0 Norm Loss', 0.022085795),
 ('TV(2.0) Loss', 0.19566245)], overall loss: -1.39085960388
Iteration: 1135, named_losses: [('ActivationMax Loss', -1.6334491),
 ('L-6.0 Norm Loss', 0.022085093),
 ('TV(2.0) Loss', 0.19471654)], overall loss: -1.41664743423
Iteration: 1136, named_losses: [('ActivationMax Loss', -1.61428),
 ('L-6.0 Norm Loss', 0.022083487),
 ('TV(2.0) Loss', 0.19466978)], overall loss: -1.39752674103
Iteration: 1137, named_losses: [('ActivationMax Loss', -1.6042382),
 ('L-6.0 Norm Loss', 0.022083016),
 ('TV(2.0) Loss', 0.19296347)], overall loss: -1.3891916275
Iteration: 1138, named_losses: [('ActivationMax Loss', -1.6448345),
 ('L-6.0 Norm Loss', 0.022083709),
 ('TV(2.0) Loss', 0.19362469)], overall loss: -1.42912602425
Iteration: 1139, named_losses: [('ActivationMax Loss', -1.5988851),
 ('L-6.0 Norm Loss', 0.022082824),
 ('TV(2.0) Loss', 0.19267519)], overall loss: -1.38412702084
Iteration: 1140, named_losses: [('ActivationMax Loss', -1.6356592),
 ('L-6.0 Norm Loss', 0.022081837),
 ('TV(2.0) Loss', 0.1923729)], overall loss: -1.42120444775
Iteration: 1141, named_losses: [('ActivationMax Loss', -1.6158652),
 ('L-6.0 Norm Loss', 0.022083499),
 ('TV(2.0) Loss', 0.19348212)], overall loss: -1.4002995491
Iteration: 1142, named_losses: [('ActivationMax Loss', -1.6116586),
 ('L-6.0 Norm Loss', 0.022082562),
 ('TV(2.0) Loss', 0.19271322)], overall loss: -1.39686274529
Iteration: 1143, named_losses: [('ActivationMax Loss', -1.6117998),
 ('L-6.0 Norm Loss', 0.022082839),
 ('TV(2.0) Loss', 0.19354992)], overall loss: -1.39616715908
Iteration: 1144, named_losses: [('ActivationMax Loss', -1.6603945),
 ('L-6.0 Norm Loss', 0.02208199),
 ('TV(2.0) Loss', 0.19425122)], overall loss: -1.44406139851
Iteration: 1145, named_losses: [('ActivationMax Loss', -1.5900825),
 ('L-6.0 Norm Loss', 0.022081707),
 ('TV(2.0) Loss', 0.1928045)], overall loss: -1.3751963377
Iteration: 1146, named_losses: [('ActivationMax Loss', -1.6199635),
 ('L-6.0 Norm Loss', 0.022081399),
 ('TV(2.0) Loss', 0.19334735)], overall loss: -1.40453481674
Iteration: 1147, named_losses: [('ActivationMax Loss', -1.6330121),
 ('L-6.0 Norm Loss', 0.022080809),
 ('TV(2.0) Loss', 0.19414106)], overall loss: -1.41679024696
Iteration: 1148, named_losses: [('ActivationMax Loss', -1.6268045),
 ('L-6.0 Norm Loss', 0.022081092),
 ('TV(2.0) Loss', 0.19308443)], overall loss: -1.41163885593
Iteration: 1149, named_losses: [('ActivationMax Loss', -1.6413555),
 ('L-6.0 Norm Loss', 0.022080779),
 ('TV(2.0) Loss', 0.19382766)], overall loss: -1.42544710636
Iteration: 1150, named_losses: [('ActivationMax Loss', -1.6498084),
 ('L-6.0 Norm Loss', 0.022080749),
 ('TV(2.0) Loss', 0.19254343)], overall loss: -1.43518424034
Iteration: 1151, named_losses: [('ActivationMax Loss', -1.6096147),
 ('L-6.0 Norm Loss', 0.022080775),
 ('TV(2.0) Loss', 0.19221282)], overall loss: -1.39532113075
Iteration: 1152, named_losses: [('ActivationMax Loss', -1.667299),
 ('L-6.0 Norm Loss', 0.022079302),
 ('TV(2.0) Loss', 0.19158897)], overall loss: -1.45363068581
Iteration: 1153, named_losses: [('ActivationMax Loss', -1.6398748),
 ('L-6.0 Norm Loss', 0.022081066),
 ('TV(2.0) Loss', 0.19042251)], overall loss: -1.4273712635
Iteration: 1154, named_losses: [('ActivationMax Loss', -1.6413711),
 ('L-6.0 Norm Loss', 0.022078471),
 ('TV(2.0) Loss', 0.19017126)], overall loss: -1.42912137508
Iteration: 1155, named_losses: [('ActivationMax Loss', -1.5865902),
 ('L-6.0 Norm Loss', 0.022078929),
 ('TV(2.0) Loss', 0.19001354)], overall loss: -1.37449777126
Iteration: 1156, named_losses: [('ActivationMax Loss', -1.5873736),
 ('L-6.0 Norm Loss', 0.022078333),
 ('TV(2.0) Loss', 0.19127066)], overall loss: -1.37402462959
Iteration: 1157, named_losses: [('ActivationMax Loss', -1.5513703),
 ('L-6.0 Norm Loss', 0.022079229),
 ('TV(2.0) Loss', 0.19269449)], overall loss: -1.33659648895
Iteration: 1158, named_losses: [('ActivationMax Loss', -1.5499196),
 ('L-6.0 Norm Loss', 0.02208079),
 ('TV(2.0) Loss', 0.19381322)], overall loss: -1.33402562141
Iteration: 1159, named_losses: [('ActivationMax Loss', -1.5873772),
 ('L-6.0 Norm Loss', 0.022080287),
 ('TV(2.0) Loss', 0.19506389)], overall loss: -1.37023305893
Iteration: 1160, named_losses: [('ActivationMax Loss', -1.6195574),
 ('L-6.0 Norm Loss', 0.022081923),
 ('TV(2.0) Loss', 0.19629316)], overall loss: -1.40118229389
Iteration: 1161, named_losses: [('ActivationMax Loss', -1.5716288),
 ('L-6.0 Norm Loss', 0.022080231),
 ('TV(2.0) Loss', 0.19612935)], overall loss: -1.35341930389
Iteration: 1162, named_losses: [('ActivationMax Loss', -1.6121417),
 ('L-6.0 Norm Loss', 0.022081053),
 ('TV(2.0) Loss', 0.19695526)], overall loss: -1.3931055069
Iteration: 1163, named_losses: [('ActivationMax Loss', -1.6197966),
 ('L-6.0 Norm Loss', 0.022080865),
 ('TV(2.0) Loss', 0.19623525)], overall loss: -1.40148043633
Iteration: 1164, named_losses: [('ActivationMax Loss', -1.5847603),
 ('L-6.0 Norm Loss', 0.02207825),
 ('TV(2.0) Loss', 0.19620797)], overall loss: -1.3664740324
Iteration: 1165, named_losses: [('ActivationMax Loss', -1.5945481),
 ('L-6.0 Norm Loss', 0.022079751),
 ('TV(2.0) Loss', 0.19670795)], overall loss: -1.37576043606
Iteration: 1166, named_losses: [('ActivationMax Loss', -1.5804875),
 ('L-6.0 Norm Loss', 0.022078644),
 ('TV(2.0) Loss', 0.19557615)], overall loss: -1.36283266544
Iteration: 1167, named_losses: [('ActivationMax Loss', -1.6302145),
 ('L-6.0 Norm Loss', 0.022080157),
 ('TV(2.0) Loss', 0.19536927)], overall loss: -1.41276502609
Iteration: 1168, named_losses: [('ActivationMax Loss', -1.6316719),
 ('L-6.0 Norm Loss', 0.022079401),
 ('TV(2.0) Loss', 0.19359154)], overall loss: -1.41600108147
Iteration: 1169, named_losses: [('ActivationMax Loss', -1.6183672),
 ('L-6.0 Norm Loss', 0.0220777),
 ('TV(2.0) Loss', 0.19288635)], overall loss: -1.40340316296
Iteration: 1170, named_losses: [('ActivationMax Loss', -1.5963924),
 ('L-6.0 Norm Loss', 0.022078892),
 ('TV(2.0) Loss', 0.19181953)], overall loss: -1.38249397278
Iteration: 1171, named_losses: [('ActivationMax Loss', -1.6378329),
 ('L-6.0 Norm Loss', 0.022077154),
 ('TV(2.0) Loss', 0.19330156)], overall loss: -1.42245411873
Iteration: 1172, named_losses: [('ActivationMax Loss', -1.6023793),
 ('L-6.0 Norm Loss', 0.022076961),
 ('TV(2.0) Loss', 0.19142681)], overall loss: -1.38887548447
Iteration: 1173, named_losses: [('ActivationMax Loss', -1.6470071),
 ('L-6.0 Norm Loss', 0.022076584),
 ('TV(2.0) Loss', 0.19215377)], overall loss: -1.43277668953
Iteration: 1174, named_losses: [('ActivationMax Loss', -1.6175025),
 ('L-6.0 Norm Loss', 0.022077),
 ('TV(2.0) Loss', 0.19146591)], overall loss: -1.40395951271
Iteration: 1175, named_losses: [('ActivationMax Loss', -1.6399207),
 ('L-6.0 Norm Loss', 0.022076167),
 ('TV(2.0) Loss', 0.19097638)], overall loss: -1.4268682003
Iteration: 1176, named_losses: [('ActivationMax Loss', -1.6134677),
 ('L-6.0 Norm Loss', 0.022076238),
 ('TV(2.0) Loss', 0.18985675)], overall loss: -1.40153467655
Iteration: 1177, named_losses: [('ActivationMax Loss', -1.6343429),
 ('L-6.0 Norm Loss', 0.022075223),
 ('TV(2.0) Loss', 0.18938465)], overall loss: -1.42288303375
Iteration: 1178, named_losses: [('ActivationMax Loss', -1.6227695),
 ('L-6.0 Norm Loss', 0.022075441),
 ('TV(2.0) Loss', 0.18984039)], overall loss: -1.41085362434
Iteration: 1179, named_losses: [('ActivationMax Loss', -1.6531047),
 ('L-6.0 Norm Loss', 0.022074234),
 ('TV(2.0) Loss', 0.1894476)], overall loss: -1.44158279896
Iteration: 1180, named_losses: [('ActivationMax Loss', -1.6244448),
 ('L-6.0 Norm Loss', 0.022076109),
 ('TV(2.0) Loss', 0.18932271)], overall loss: -1.41304600239
Iteration: 1181, named_losses: [('ActivationMax Loss', -1.631283),
 ('L-6.0 Norm Loss', 0.022074057),
 ('TV(2.0) Loss', 0.18914995)], overall loss: -1.42005896568
Iteration: 1182, named_losses: [('ActivationMax Loss', -1.6581395),
 ('L-6.0 Norm Loss', 0.022073815),
 ('TV(2.0) Loss', 0.18918265)], overall loss: -1.44688296318
Iteration: 1183, named_losses: [('ActivationMax Loss', -1.6572301),
 ('L-6.0 Norm Loss', 0.02207331),
 ('TV(2.0) Loss', 0.18796793)], overall loss: -1.44718897343
Iteration: 1184, named_losses: [('ActivationMax Loss', -1.6466258),
 ('L-6.0 Norm Loss', 0.022072464),
 ('TV(2.0) Loss', 0.18841733)], overall loss: -1.43613600731
Iteration: 1185, named_losses: [('ActivationMax Loss', -1.6289103),
 ('L-6.0 Norm Loss', 0.022072261),
 ('TV(2.0) Loss', 0.18828055)], overall loss: -1.41855740547
Iteration: 1186, named_losses: [('ActivationMax Loss', -1.5939237),
 ('L-6.0 Norm Loss', 0.022071648),
 ('TV(2.0) Loss', 0.1892409)], overall loss: -1.38261115551
Iteration: 1187, named_losses: [('ActivationMax Loss', -1.5929898),
 ('L-6.0 Norm Loss', 0.022071481),
 ('TV(2.0) Loss', 0.19039957)], overall loss: -1.38051879406
Iteration: 1188, named_losses: [('ActivationMax Loss', -1.5830513),
 ('L-6.0 Norm Loss', 0.022071861),
 ('TV(2.0) Loss', 0.19268857)], overall loss: -1.36829090118
Iteration: 1189, named_losses: [('ActivationMax Loss', -1.5671525),
 ('L-6.0 Norm Loss', 0.022072468),
 ('TV(2.0) Loss', 0.1939467)], overall loss: -1.35113334656
Iteration: 1190, named_losses: [('ActivationMax Loss', -1.6129497),
 ('L-6.0 Norm Loss', 0.022072552),
 ('TV(2.0) Loss', 0.19257283)], overall loss: -1.39830434322
Iteration: 1191, named_losses: [('ActivationMax Loss', -1.6255596),
 ('L-6.0 Norm Loss', 0.022071993),
 ('TV(2.0) Loss', 0.19217423)], overall loss: -1.41131341457
Iteration: 1192, named_losses: [('ActivationMax Loss', -1.5683063),
 ('L-6.0 Norm Loss', 0.022070603),
 ('TV(2.0) Loss', 0.19334751)], overall loss: -1.3528881073
Iteration: 1193, named_losses: [('ActivationMax Loss', -1.5738292),
 ('L-6.0 Norm Loss', 0.022072051),
 ('TV(2.0) Loss', 0.19449104)], overall loss: -1.35726606846
Iteration: 1194, named_losses: [('ActivationMax Loss', -1.6048553),
 ('L-6.0 Norm Loss', 0.022072794),
 ('TV(2.0) Loss', 0.19666773)], overall loss: -1.38611483574
Iteration: 1195, named_losses: [('ActivationMax Loss', -1.5875959),
 ('L-6.0 Norm Loss', 0.022070734),
 ('TV(2.0) Loss', 0.19651449)], overall loss: -1.36901068687
Iteration: 1196, named_losses: [('ActivationMax Loss', -1.6317289),
 ('L-6.0 Norm Loss', 0.022071423),
 ('TV(2.0) Loss', 0.19667171)], overall loss: -1.41298568249
Iteration: 1197, named_losses: [('ActivationMax Loss', -1.630604),
 ('L-6.0 Norm Loss', 0.022070734),
 ('TV(2.0) Loss', 0.19403064)], overall loss: -1.4145026207
Iteration: 1198, named_losses: [('ActivationMax Loss', -1.573982),
 ('L-6.0 Norm Loss', 0.022070659),
 ('TV(2.0) Loss', 0.19264781)], overall loss: -1.35926353931
Iteration: 1199, named_losses: [('ActivationMax Loss', -1.6372626),
 ('L-6.0 Norm Loss', 0.022070713),
 ('TV(2.0) Loss', 0.19354333)], overall loss: -1.42164850235
Iteration: 1200, named_losses: [('ActivationMax Loss', -1.6494056),
 ('L-6.0 Norm Loss', 0.022070449),
 ('TV(2.0) Loss', 0.19133924)], overall loss: -1.43599593639
Iteration: 1201, named_losses: [('ActivationMax Loss', -1.6416759),
 ('L-6.0 Norm Loss', 0.022069747),
 ('TV(2.0) Loss', 0.1909802)], overall loss: -1.42862606049
Iteration: 1202, named_losses: [('ActivationMax Loss', -1.5669448),
 ('L-6.0 Norm Loss', 0.02206853),
 ('TV(2.0) Loss', 0.19030267)], overall loss: -1.35457372665
Iteration: 1203, named_losses: [('ActivationMax Loss', -1.6286353),
 ('L-6.0 Norm Loss', 0.022069717),
 ('TV(2.0) Loss', 0.19181906)], overall loss: -1.4147465229
Iteration: 1204, named_losses: [('ActivationMax Loss', -1.6251276),
 ('L-6.0 Norm Loss', 0.022068538),
 ('TV(2.0) Loss', 0.19097593)], overall loss: -1.41208314896
Iteration: 1205, named_losses: [('ActivationMax Loss', -1.634863),
 ('L-6.0 Norm Loss', 0.02206913),
 ('TV(2.0) Loss', 0.19213761)], overall loss: -1.42065632343
Iteration: 1206, named_losses: [('ActivationMax Loss', -1.6344546),
 ('L-6.0 Norm Loss', 0.022068283),
 ('TV(2.0) Loss', 0.19157359)], overall loss: -1.42081272602
Iteration: 1207, named_losses: [('ActivationMax Loss', -1.6178594),
 ('L-6.0 Norm Loss', 0.022066597),
 ('TV(2.0) Loss', 0.19184434)], overall loss: -1.40394842625
Iteration: 1208, named_losses: [('ActivationMax Loss', -1.5912188),
 ('L-6.0 Norm Loss', 0.022068767),
 ('TV(2.0) Loss', 0.19217831)], overall loss: -1.37697172165
Iteration: 1209, named_losses: [('ActivationMax Loss', -1.596715),
 ('L-6.0 Norm Loss', 0.022067264),
 ('TV(2.0) Loss', 0.19379422)], overall loss: -1.38085341454
Iteration: 1210, named_losses: [('ActivationMax Loss', -1.6190825),
 ('L-6.0 Norm Loss', 0.022066927),
 ('TV(2.0) Loss', 0.1935185)], overall loss: -1.40349698067
Iteration: 1211, named_losses: [('ActivationMax Loss', -1.5466515),
 ('L-6.0 Norm Loss', 0.022066923),
 ('TV(2.0) Loss', 0.19331013)], overall loss: -1.33127439022
Iteration: 1212, named_losses: [('ActivationMax Loss', -1.6032431),
 ('L-6.0 Norm Loss', 0.022068556),
 ('TV(2.0) Loss', 0.19441152)], overall loss: -1.38676309586
Iteration: 1213, named_losses: [('ActivationMax Loss', -1.5941339),
 ('L-6.0 Norm Loss', 0.022067724),
 ('TV(2.0) Loss', 0.19529457)], overall loss: -1.37677156925
Iteration: 1214, named_losses: [('ActivationMax Loss', -1.6137524),
 ('L-6.0 Norm Loss', 0.022068124),
 ('TV(2.0) Loss', 0.19537225)], overall loss: -1.39631199837
Iteration: 1215, named_losses: [('ActivationMax Loss', -1.5947137),
 ('L-6.0 Norm Loss', 0.022067681),
 ('TV(2.0) Loss', 0.19447298)], overall loss: -1.37817299366
Iteration: 1216, named_losses: [('ActivationMax Loss', -1.63986),
 ('L-6.0 Norm Loss', 0.022067383),
 ('TV(2.0) Loss', 0.19329806)], overall loss: -1.42449450493
Iteration: 1217, named_losses: [('ActivationMax Loss', -1.5985594),
 ('L-6.0 Norm Loss', 0.022067847),
 ('TV(2.0) Loss', 0.19385955)], overall loss: -1.38263189793
Iteration: 1218, named_losses: [('ActivationMax Loss', -1.6036706),
 ('L-6.0 Norm Loss', 0.022066189),
 ('TV(2.0) Loss', 0.19315149)], overall loss: -1.38845288754
Iteration: 1219, named_losses: [('ActivationMax Loss', -1.6391982),
 ('L-6.0 Norm Loss', 0.022067629),
 ('TV(2.0) Loss', 0.19255686)], overall loss: -1.4245736599
Iteration: 1220, named_losses: [('ActivationMax Loss', -1.6305707),
 ('L-6.0 Norm Loss', 0.022065667),
 ('TV(2.0) Loss', 0.19202776)], overall loss: -1.41647720337
Iteration: 1221, named_losses: [('ActivationMax Loss', -1.6254867),
 ('L-6.0 Norm Loss', 0.022065638),
 ('TV(2.0) Loss', 0.19257179)], overall loss: -1.41084933281
Iteration: 1222, named_losses: [('ActivationMax Loss', -1.5787836),
 ('L-6.0 Norm Loss', 0.022065455),
 ('TV(2.0) Loss', 0.19182311)], overall loss: -1.36489510536
Iteration: 1223, named_losses: [('ActivationMax Loss', -1.6032438),
 ('L-6.0 Norm Loss', 0.02206536),
 ('TV(2.0) Loss', 0.19209781)], overall loss: -1.38908064365
Iteration: 1224, named_losses: [('ActivationMax Loss', -1.6037567),
 ('L-6.0 Norm Loss', 0.02206444),
 ('TV(2.0) Loss', 0.19089943)], overall loss: -1.39079284668
Iteration: 1225, named_losses: [('ActivationMax Loss', -1.6373242),
 ('L-6.0 Norm Loss', 0.022065518),
 ('TV(2.0) Loss', 0.19124609)], overall loss: -1.42401266098
Iteration: 1226, named_losses: [('ActivationMax Loss', -1.6295333),
 ('L-6.0 Norm Loss', 0.022063961),
 ('TV(2.0) Loss', 0.19016589)], overall loss: -1.41730344296
Iteration: 1227, named_losses: [('ActivationMax Loss', -1.6247051),
 ('L-6.0 Norm Loss', 0.022063766),
 ('TV(2.0) Loss', 0.19021426)], overall loss: -1.41242706776
Iteration: 1228, named_losses: [('ActivationMax Loss', -1.6193479),
 ('L-6.0 Norm Loss', 0.022064008),
 ('TV(2.0) Loss', 0.19022529)], overall loss: -1.40705871582
Iteration: 1229, named_losses: [('ActivationMax Loss', -1.6292977),
 ('L-6.0 Norm Loss', 0.022062873),
 ('TV(2.0) Loss', 0.19014865)], overall loss: -1.41708612442
Iteration: 1230, named_losses: [('ActivationMax Loss', -1.6203383),
 ('L-6.0 Norm Loss', 0.022063978),
 ('TV(2.0) Loss', 0.18971398)], overall loss: -1.40856039524
Iteration: 1231, named_losses: [('ActivationMax Loss', -1.6287631),
 ('L-6.0 Norm Loss', 0.022063643),
 ('TV(2.0) Loss', 0.18968596)], overall loss: -1.41701352596
Iteration: 1232, named_losses: [('ActivationMax Loss', -1.6386758),
 ('L-6.0 Norm Loss', 0.022062052),
 ('TV(2.0) Loss', 0.18933842)], overall loss: -1.42727530003
Iteration: 1233, named_losses: [('ActivationMax Loss', -1.6202842),
 ('L-6.0 Norm Loss', 0.022062767),
 ('TV(2.0) Loss', 0.18941405)], overall loss: -1.40880739689
Iteration: 1234, named_losses: [('ActivationMax Loss', -1.6124187),
 ('L-6.0 Norm Loss', 0.022061966),
 ('TV(2.0) Loss', 0.19057541)], overall loss: -1.39978134632
Iteration: 1235, named_losses: [('ActivationMax Loss', -1.6236873),
 ('L-6.0 Norm Loss', 0.022061339),
 ('TV(2.0) Loss', 0.1900842)], overall loss: -1.41154170036
Iteration: 1236, named_losses: [('ActivationMax Loss', -1.5813655),
 ('L-6.0 Norm Loss', 0.022062792),
 ('TV(2.0) Loss', 0.19149886)], overall loss: -1.36780381203
Iteration: 1237, named_losses: [('ActivationMax Loss', -1.608233),
 ('L-6.0 Norm Loss', 0.022062099),
 ('TV(2.0) Loss', 0.1925523)], overall loss: -1.39361858368
Iteration: 1238, named_losses: [('ActivationMax Loss', -1.633526),
 ('L-6.0 Norm Loss', 0.022062946),
 ('TV(2.0) Loss', 0.1935057)], overall loss: -1.41795730591
Iteration: 1239, named_losses: [('ActivationMax Loss', -1.5987595),
 ('L-6.0 Norm Loss', 0.022062084),
 ('TV(2.0) Loss', 0.19280487)], overall loss: -1.38389253616
Iteration: 1240, named_losses: [('ActivationMax Loss', -1.5875655),
 ('L-6.0 Norm Loss', 0.02206267),
 ('TV(2.0) Loss', 0.19399209)], overall loss: -1.37151074409
Iteration: 1241, named_losses: [('ActivationMax Loss', -1.6034079),
 ('L-6.0 Norm Loss', 0.022061391),
 ('TV(2.0) Loss', 0.19395392)], overall loss: -1.38739264011
Iteration: 1242, named_losses: [('ActivationMax Loss', -1.6301298),
 ('L-6.0 Norm Loss', 0.022062434),
 ('TV(2.0) Loss', 0.19347173)], overall loss: -1.41459560394
Iteration: 1243, named_losses: [('ActivationMax Loss', -1.6123395),
 ('L-6.0 Norm Loss', 0.022061042),
 ('TV(2.0) Loss', 0.19241497)], overall loss: -1.39786350727
Iteration: 1244, named_losses: [('ActivationMax Loss', -1.6342899),
 ('L-6.0 Norm Loss', 0.022061029),
 ('TV(2.0) Loss', 0.1926512)], overall loss: -1.41957771778
Iteration: 1245, named_losses: [('ActivationMax Loss', -1.6316335),
 ('L-6.0 Norm Loss', 0.022060599),
 ('TV(2.0) Loss', 0.19214341)], overall loss: -1.41742944717
Iteration: 1246, named_losses: [('ActivationMax Loss', -1.6307325),
 ('L-6.0 Norm Loss', 0.022060985),
 ('TV(2.0) Loss', 0.19165227)], overall loss: -1.41701924801
Iteration: 1247, named_losses: [('ActivationMax Loss', -1.608856),
 ('L-6.0 Norm Loss', 0.022058517),
 ('TV(2.0) Loss', 0.19170347)], overall loss: -1.39509403706
Iteration: 1248, named_losses: [('ActivationMax Loss', -1.6212261),
 ('L-6.0 Norm Loss', 0.022058945),
 ('TV(2.0) Loss', 0.19277634)], overall loss: -1.40639078617
Iteration: 1249, named_losses: [('ActivationMax Loss', -1.6100094),
 ('L-6.0 Norm Loss', 0.022058368),
 ('TV(2.0) Loss', 0.19197924)], overall loss: -1.39597177505
Iteration: 1250, named_losses: [('ActivationMax Loss', -1.6239364),
 ('L-6.0 Norm Loss', 0.022059735),
 ('TV(2.0) Loss', 0.19297178)], overall loss: -1.40890491009
Iteration: 1251, named_losses: [('ActivationMax Loss', -1.6256871),
 ('L-6.0 Norm Loss', 0.022059351),
 ('TV(2.0) Loss', 0.19326247)], overall loss: -1.41036534309
Iteration: 1252, named_losses: [('ActivationMax Loss', -1.6259272),
 ('L-6.0 Norm Loss', 0.022058988),
 ('TV(2.0) Loss', 0.192665)], overall loss: -1.41120326519
Iteration: 1253, named_losses: [('ActivationMax Loss', -1.6082373),
 ('L-6.0 Norm Loss', 0.022059795),
 ('TV(2.0) Loss', 0.19217767)], overall loss: -1.39399981499
Iteration: 1254, named_losses: [('ActivationMax Loss', -1.6077313),
 ('L-6.0 Norm Loss', 0.022059428),
 ('TV(2.0) Loss', 0.1916254)], overall loss: -1.39404654503
Iteration: 1255, named_losses: [('ActivationMax Loss', -1.5748138),
 ('L-6.0 Norm Loss', 0.022058843),
 ('TV(2.0) Loss', 0.19284752)], overall loss: -1.3599075079
Iteration: 1256, named_losses: [('ActivationMax Loss', -1.6436796),
 ('L-6.0 Norm Loss', 0.022059221),
 ('TV(2.0) Loss', 0.19235961)], overall loss: -1.42926084995
Iteration: 1257, named_losses: [('ActivationMax Loss', -1.6434947),
 ('L-6.0 Norm Loss', 0.022057716),
 ('TV(2.0) Loss', 0.19087)], overall loss: -1.43056690693
Iteration: 1258, named_losses: [('ActivationMax Loss', -1.6268559),
 ('L-6.0 Norm Loss', 0.022057669),
 ('TV(2.0) Loss', 0.19071445)], overall loss: -1.41408371925
Iteration: 1259, named_losses: [('ActivationMax Loss', -1.6402413),
 ('L-6.0 Norm Loss', 0.022056114),
 ('TV(2.0) Loss', 0.19054869)], overall loss: -1.42763650417
Iteration: 1260, named_losses: [('ActivationMax Loss', -1.6267492),
 ('L-6.0 Norm Loss', 0.022056494),
 ('TV(2.0) Loss', 0.19048502)], overall loss: -1.41420769691
Iteration: 1261, named_losses: [('ActivationMax Loss', -1.6384603),
 ('L-6.0 Norm Loss', 0.022056423),
 ('TV(2.0) Loss', 0.19107644)], overall loss: -1.42532742023
Iteration: 1262, named_losses: [('ActivationMax Loss', -1.600805),
 ('L-6.0 Norm Loss', 0.022055045),
 ('TV(2.0) Loss', 0.18968974)], overall loss: -1.38906025887
Iteration: 1263, named_losses: [('ActivationMax Loss', -1.648049),
 ('L-6.0 Norm Loss', 0.022055356),
 ('TV(2.0) Loss', 0.19045717)], overall loss: -1.43553638458
Iteration: 1264, named_losses: [('ActivationMax Loss', -1.5986227),
 ('L-6.0 Norm Loss', 0.022053491),
 ('TV(2.0) Loss', 0.19087335)], overall loss: -1.38569581509
Iteration: 1265, named_losses: [('ActivationMax Loss', -1.6449685),
 ('L-6.0 Norm Loss', 0.022053264),
 ('TV(2.0) Loss', 0.18992737)], overall loss: -1.43298792839
Iteration: 1266, named_losses: [('ActivationMax Loss', -1.6215777),
 ('L-6.0 Norm Loss', 0.022052482),
 ('TV(2.0) Loss', 0.19109303)], overall loss: -1.40843224525
Iteration: 1267, named_losses: [('ActivationMax Loss', -1.6420008),
 ('L-6.0 Norm Loss', 0.022053709),
 ('TV(2.0) Loss', 0.19009435)], overall loss: -1.42985272408
Iteration: 1268, named_losses: [('ActivationMax Loss', -1.631837),
 ('L-6.0 Norm Loss', 0.022052843),
 ('TV(2.0) Loss', 0.19054681)], overall loss: -1.41923737526
Iteration: 1269, named_losses: [('ActivationMax Loss', -1.6240366),
 ('L-6.0 Norm Loss', 0.022051428),
 ('TV(2.0) Loss', 0.19016753)], overall loss: -1.41181755066
Iteration: 1270, named_losses: [('ActivationMax Loss', -1.6469054),
 ('L-6.0 Norm Loss', 0.022052698),
 ('TV(2.0) Loss', 0.19098119)], overall loss: -1.43387162685
Iteration: 1271, named_losses: [('ActivationMax Loss', -1.6306144),
 ('L-6.0 Norm Loss', 0.022051163),
 ('TV(2.0) Loss', 0.19103424)], overall loss: -1.41752898693
Iteration: 1272, named_losses: [('ActivationMax Loss', -1.6517138),
 ('L-6.0 Norm Loss', 0.022051819),
 ('TV(2.0) Loss', 0.19185142)], overall loss: -1.43781065941
Iteration: 1273, named_losses: [('ActivationMax Loss', -1.5657455),
 ('L-6.0 Norm Loss', 0.022051234),
 ('TV(2.0) Loss', 0.19116622)], overall loss: -1.35252809525
Iteration: 1274, named_losses: [('ActivationMax Loss', -1.6111128),
 ('L-6.0 Norm Loss', 0.022049973),
 ('TV(2.0) Loss', 0.19079021)], overall loss: -1.39827263355
Iteration: 1275, named_losses: [('ActivationMax Loss', -1.6159711),
 ('L-6.0 Norm Loss', 0.022050697),
 ('TV(2.0) Loss', 0.18917052)], overall loss: -1.4047498703
Iteration: 1276, named_losses: [('ActivationMax Loss', -1.6205995),
 ('L-6.0 Norm Loss', 0.022050424),
 ('TV(2.0) Loss', 0.18972529)], overall loss: -1.40882384777
Iteration: 1277, named_losses: [('ActivationMax Loss', -1.6137943),
 ('L-6.0 Norm Loss', 0.022049977),
 ('TV(2.0) Loss', 0.19077888)], overall loss: -1.40096545219
Iteration: 1278, named_losses: [('ActivationMax Loss', -1.5631471),
 ('L-6.0 Norm Loss', 0.022049502),
 ('TV(2.0) Loss', 0.1913617)], overall loss: -1.34973585606
Iteration: 1279, named_losses: [('ActivationMax Loss', -1.5683713),
 ('L-6.0 Norm Loss', 0.022051834),
 ('TV(2.0) Loss', 0.19309951)], overall loss: -1.35321998596
Iteration: 1280, named_losses: [('ActivationMax Loss', -1.6205828),
 ('L-6.0 Norm Loss', 0.022051344),
 ('TV(2.0) Loss', 0.19432683)], overall loss: -1.40420460701
Iteration: 1281, named_losses: [('ActivationMax Loss', -1.6164873),
 ('L-6.0 Norm Loss', 0.022049189),
 ('TV(2.0) Loss', 0.19246493)], overall loss: -1.40197312832
Iteration: 1282, named_losses: [('ActivationMax Loss', -1.591205),
 ('L-6.0 Norm Loss', 0.022050014),
 ('TV(2.0) Loss', 0.19406159)], overall loss: -1.37509334087
Iteration: 1283, named_losses: [('ActivationMax Loss', -1.601099),
 ('L-6.0 Norm Loss', 0.022050096),
 ('TV(2.0) Loss', 0.19473948)], overall loss: -1.38430941105
Iteration: 1284, named_losses: [('ActivationMax Loss', -1.6265165),
 ('L-6.0 Norm Loss', 0.022049218),
 ('TV(2.0) Loss', 0.19471222)], overall loss: -1.40975499153
Iteration: 1285, named_losses: [('ActivationMax Loss', -1.6059594),
 ('L-6.0 Norm Loss', 0.022051306),
 ('TV(2.0) Loss', 0.19425747)], overall loss: -1.38965058327
Iteration: 1286, named_losses: [('ActivationMax Loss', -1.6083963),
 ('L-6.0 Norm Loss', 0.022048691),
 ('TV(2.0) Loss', 0.1927529)], overall loss: -1.39359474182
Iteration: 1287, named_losses: [('ActivationMax Loss', -1.6036719),
 ('L-6.0 Norm Loss', 0.022049583),
 ('TV(2.0) Loss', 0.19268444)], overall loss: -1.38893795013
Iteration: 1288, named_losses: [('ActivationMax Loss', -1.6274973),
 ('L-6.0 Norm Loss', 0.022048576),
 ('TV(2.0) Loss', 0.19116831)], overall loss: -1.41428041458
Iteration: 1289, named_losses: [('ActivationMax Loss', -1.6305978),
 ('L-6.0 Norm Loss', 0.022047911),
 ('TV(2.0) Loss', 0.19247301)], overall loss: -1.41607689857
Iteration: 1290, named_losses: [('ActivationMax Loss', -1.6242144),
 ('L-6.0 Norm Loss', 0.022048529),
 ('TV(2.0) Loss', 0.19177887)], overall loss: -1.41038703918
Iteration: 1291, named_losses: [('ActivationMax Loss', -1.6332636),
 ('L-6.0 Norm Loss', 0.022046546),
 ('TV(2.0) Loss', 0.19180633)], overall loss: -1.41941070557
Iteration: 1292, named_losses: [('ActivationMax Loss', -1.5945141),
 ('L-6.0 Norm Loss', 0.022047872),
 ('TV(2.0) Loss', 0.19010571)], overall loss: -1.38236057758
Iteration: 1293, named_losses: [('ActivationMax Loss', -1.5917367),
 ('L-6.0 Norm Loss', 0.022047803),
 ('TV(2.0) Loss', 0.18970661)], overall loss: -1.37998235226
Iteration: 1294, named_losses: [('ActivationMax Loss', -1.6162801),
 ('L-6.0 Norm Loss', 0.022046985),
 ('TV(2.0) Loss', 0.19024976)], overall loss: -1.40398323536
Iteration: 1295, named_losses: [('ActivationMax Loss', -1.6415697),
 ('L-6.0 Norm Loss', 0.022048116),
 ('TV(2.0) Loss', 0.19130063)], overall loss: -1.42822098732
Iteration: 1296, named_losses: [('ActivationMax Loss', -1.5801506),
 ('L-6.0 Norm Loss', 0.022047322),
 ('TV(2.0) Loss', 0.1910904)], overall loss: -1.3670129776
Iteration: 1297, named_losses: [('ActivationMax Loss', -1.5815502),
 ('L-6.0 Norm Loss', 0.022048052),
 ('TV(2.0) Loss', 0.19230933)], overall loss: -1.36719286442
Iteration: 1298, named_losses: [('ActivationMax Loss', -1.6456679),
 ('L-6.0 Norm Loss', 0.022046916),
 ('TV(2.0) Loss', 0.19228528)], overall loss: -1.43133568764
Iteration: 1299, named_losses: [('ActivationMax Loss', -1.5727648),
 ('L-6.0 Norm Loss', 0.022045879),
 ('TV(2.0) Loss', 0.19130728)], overall loss: -1.35941159725
Iteration: 1300, named_losses: [('ActivationMax Loss', -1.6037748),
 ('L-6.0 Norm Loss', 0.022045303),
 ('TV(2.0) Loss', 0.19127427)], overall loss: -1.39045524597
Iteration: 1301, named_losses: [('ActivationMax Loss', -1.5279028),
 ('L-6.0 Norm Loss', 0.02204513),
 ('TV(2.0) Loss', 0.18935987)], overall loss: -1.31649780273
Iteration: 1302, named_losses: [('ActivationMax Loss', -1.60373),
 ('L-6.0 Norm Loss', 0.02204562),
 ('TV(2.0) Loss', 0.19141963)], overall loss: -1.39026474953
Iteration: 1303, named_losses: [('ActivationMax Loss', -1.6247498),
 ('L-6.0 Norm Loss', 0.02204575),
 ('TV(2.0) Loss', 0.19092324)], overall loss: -1.4117808342
Iteration: 1304, named_losses: [('ActivationMax Loss', -1.6084049),
 ('L-6.0 Norm Loss', 0.022045542),
 ('TV(2.0) Loss', 0.19201076)], overall loss: -1.39434862137
Iteration: 1305, named_losses: [('ActivationMax Loss', -1.5988404),
 ('L-6.0 Norm Loss', 0.022043845),
 ('TV(2.0) Loss', 0.19200245)], overall loss: -1.38479411602
Iteration: 1306, named_losses: [('ActivationMax Loss', -1.6223925),
 ('L-6.0 Norm Loss', 0.022045266),
 ('TV(2.0) Loss', 0.1921187)], overall loss: -1.40822863579
Iteration: 1307, named_losses: [('ActivationMax Loss', -1.6303287),
 ('L-6.0 Norm Loss', 0.02204394),
 ('TV(2.0) Loss', 0.19250607)], overall loss: -1.41577863693
Iteration: 1308, named_losses: [('ActivationMax Loss', -1.638101),
 ('L-6.0 Norm Loss', 0.022044489),
 ('TV(2.0) Loss', 0.19130048)], overall loss: -1.4247559309
Iteration: 1309, named_losses: [('ActivationMax Loss', -1.6293796),
 ('L-6.0 Norm Loss', 0.02204367),
 ('TV(2.0) Loss', 0.19031969)], overall loss: -1.41701626778
Iteration: 1310, named_losses: [('ActivationMax Loss', -1.5856183),
 ('L-6.0 Norm Loss', 0.022042943),
 ('TV(2.0) Loss', 0.19037819)], overall loss: -1.3731970787
Iteration: 1311, named_losses: [('ActivationMax Loss', -1.6024169),
 ('L-6.0 Norm Loss', 0.022042789),
 ('TV(2.0) Loss', 0.1907116)], overall loss: -1.3896625042
Iteration: 1312, named_losses: [('ActivationMax Loss', -1.6051221),
 ('L-6.0 Norm Loss', 0.022040438),
 ('TV(2.0) Loss', 0.18904619)], overall loss: -1.39403545856
Iteration: 1313, named_losses: [('ActivationMax Loss', -1.6257362),
 ('L-6.0 Norm Loss', 0.022041555),
 ('TV(2.0) Loss', 0.18933786)], overall loss: -1.41435682774
Iteration: 1314, named_losses: [('ActivationMax Loss', -1.6336951),
 ('L-6.0 Norm Loss', 0.02203997),
 ('TV(2.0) Loss', 0.18904823)], overall loss: -1.42260694504
Iteration: 1315, named_losses: [('ActivationMax Loss', -1.6378372),
 ('L-6.0 Norm Loss', 0.02204043),
 ('TV(2.0) Loss', 0.18907458)], overall loss: -1.42672204971
Iteration: 1316, named_losses: [('ActivationMax Loss', -1.6297126),
 ('L-6.0 Norm Loss', 0.022041423),
 ('TV(2.0) Loss', 0.18886426)], overall loss: -1.41880691051
Iteration: 1317, named_losses: [('ActivationMax Loss', -1.6362342),
 ('L-6.0 Norm Loss', 0.022039901),
 ('TV(2.0) Loss', 0.18897651)], overall loss: -1.42521774769
Iteration: 1318, named_losses: [('ActivationMax Loss', -1.652771),
 ('L-6.0 Norm Loss', 0.022040186),
 ('TV(2.0) Loss', 0.18878938)], overall loss: -1.44194149971
Iteration: 1319, named_losses: [('ActivationMax Loss', -1.5983386),
 ('L-6.0 Norm Loss', 0.022039175),
 ('TV(2.0) Loss', 0.18876214)], overall loss: -1.38753724098
Iteration: 1320, named_losses: [('ActivationMax Loss', -1.6282794),
 ('L-6.0 Norm Loss', 0.022037961),
 ('TV(2.0) Loss', 0.18839516)], overall loss: -1.41784632206
Iteration: 1321, named_losses: [('ActivationMax Loss', -1.6066689),
 ('L-6.0 Norm Loss', 0.022039235),
 ('TV(2.0) Loss', 0.19006641)], overall loss: -1.3945633173
Iteration: 1322, named_losses: [('ActivationMax Loss', -1.6250641),
 ('L-6.0 Norm Loss', 0.022038558),
 ('TV(2.0) Loss', 0.18910201)], overall loss: -1.41392350197
Iteration: 1323, named_losses: [('ActivationMax Loss', -1.6144472),
 ('L-6.0 Norm Loss', 0.022039205),
 ('TV(2.0) Loss', 0.18959093)], overall loss: -1.40281713009
Iteration: 1324, named_losses: [('ActivationMax Loss', -1.64539),
 ('L-6.0 Norm Loss', 0.022037659),
 ('TV(2.0) Loss', 0.18895857)], overall loss: -1.43439388275
Iteration: 1325, named_losses: [('ActivationMax Loss', -1.6140181),
 ('L-6.0 Norm Loss', 0.022037987),
 ('TV(2.0) Loss', 0.18943985)], overall loss: -1.40254020691
Iteration: 1326, named_losses: [('ActivationMax Loss', -1.6184309),
 ('L-6.0 Norm Loss', 0.022037745),
 ('TV(2.0) Loss', 0.18876344)], overall loss: -1.40762972832
Iteration: 1327, named_losses: [('ActivationMax Loss', -1.6143274),
 ('L-6.0 Norm Loss', 0.022037432),
 ('TV(2.0) Loss', 0.18976793)], overall loss: -1.4025220871
Iteration: 1328, named_losses: [('ActivationMax Loss', -1.6198752),
 ('L-6.0 Norm Loss', 0.022037717),
 ('TV(2.0) Loss', 0.18943439)], overall loss: -1.40840303898
Iteration: 1329, named_losses: [('ActivationMax Loss', -1.5970712),
 ('L-6.0 Norm Loss', 0.022037765),
 ('TV(2.0) Loss', 0.19154584)], overall loss: -1.38348758221
Iteration: 1330, named_losses: [('ActivationMax Loss', -1.6273044),
 ('L-6.0 Norm Loss', 0.022036791),
 ('TV(2.0) Loss', 0.19134721)], overall loss: -1.41392040253
Iteration: 1331, named_losses: [('ActivationMax Loss', -1.6162664),
 ('L-6.0 Norm Loss', 0.022037815),
 ('TV(2.0) Loss', 0.19162637)], overall loss: -1.40260219574
Iteration: 1332, named_losses: [('ActivationMax Loss', -1.6115084),
 ('L-6.0 Norm Loss', 0.02203726),
 ('TV(2.0) Loss', 0.19178924)], overall loss: -1.39768183231
Iteration: 1333, named_losses: [('ActivationMax Loss', -1.6046469),
 ('L-6.0 Norm Loss', 0.022037571),
 ('TV(2.0) Loss', 0.19172589)], overall loss: -1.39088344574
Iteration: 1334, named_losses: [('ActivationMax Loss', -1.6092327),
 ('L-6.0 Norm Loss', 0.022037478),
 ('TV(2.0) Loss', 0.19100368)], overall loss: -1.39619147778
Iteration: 1335, named_losses: [('ActivationMax Loss', -1.6014531),
 ('L-6.0 Norm Loss', 0.022036666),
 ('TV(2.0) Loss', 0.19043051)], overall loss: -1.38898587227
Iteration: 1336, named_losses: [('ActivationMax Loss', -1.6405094),
 ('L-6.0 Norm Loss', 0.022037087),
 ('TV(2.0) Loss', 0.19065431)], overall loss: -1.42781805992
Iteration: 1337, named_losses: [('ActivationMax Loss', -1.6041707),
 ('L-6.0 Norm Loss', 0.022034833),
 ('TV(2.0) Loss', 0.18989144)], overall loss: -1.39224433899
Iteration: 1338, named_losses: [('ActivationMax Loss', -1.633208),
 ('L-6.0 Norm Loss', 0.022035111),
 ('TV(2.0) Loss', 0.19067883)], overall loss: -1.42049407959
Iteration: 1339, named_losses: [('ActivationMax Loss', -1.6214049),
 ('L-6.0 Norm Loss', 0.02203526),
 ('TV(2.0) Loss', 0.19119157)], overall loss: -1.40817809105
Iteration: 1340, named_losses: [('ActivationMax Loss', -1.6056314),
 ('L-6.0 Norm Loss', 0.022035912),
 ('TV(2.0) Loss', 0.19105764)], overall loss: -1.39253771305
Iteration: 1341, named_losses: [('ActivationMax Loss', -1.629153),
 ('L-6.0 Norm Loss', 0.022035455),
 ('TV(2.0) Loss', 0.19191036)], overall loss: -1.4152071476
Iteration: 1342, named_losses: [('ActivationMax Loss', -1.6121867),
 ('L-6.0 Norm Loss', 0.022035107),
 ('TV(2.0) Loss', 0.19171968)], overall loss: -1.39843189716
Iteration: 1343, named_losses: [('ActivationMax Loss', -1.6560441),
 ('L-6.0 Norm Loss', 0.022034712),
 ('TV(2.0) Loss', 0.1919356)], overall loss: -1.44207382202
Iteration: 1344, named_losses: [('ActivationMax Loss', -1.6368628),
 ('L-6.0 Norm Loss', 0.022034256),
 ('TV(2.0) Loss', 0.19007601)], overall loss: -1.42475247383
Iteration: 1345, named_losses: [('ActivationMax Loss', -1.6678406),
 ('L-6.0 Norm Loss', 0.022034377),
 ('TV(2.0) Loss', 0.19000578)], overall loss: -1.45580041409
Iteration: 1346, named_losses: [('ActivationMax Loss', -1.5916607),
 ('L-6.0 Norm Loss', 0.022032473),
 ('TV(2.0) Loss', 0.18774815)], overall loss: -1.38188004494
Iteration: 1347, named_losses: [('ActivationMax Loss', -1.6490513),
 ('L-6.0 Norm Loss', 0.022032011),
 ('TV(2.0) Loss', 0.18988064)], overall loss: -1.43713867664
Iteration: 1348, named_losses: [('ActivationMax Loss', -1.6478854),
 ('L-6.0 Norm Loss', 0.022031814),
 ('TV(2.0) Loss', 0.18944211)], overall loss: -1.43641149998
Iteration: 1349, named_losses: [('ActivationMax Loss', -1.63915),
 ('L-6.0 Norm Loss', 0.022031488),
 ('TV(2.0) Loss', 0.19009788)], overall loss: -1.42702054977
Iteration: 1350, named_losses: [('ActivationMax Loss', -1.6046532),
 ('L-6.0 Norm Loss', 0.022029795),
 ('TV(2.0) Loss', 0.1893272)], overall loss: -1.39329624176
Iteration: 1351, named_losses: [('ActivationMax Loss', -1.6284708),
 ('L-6.0 Norm Loss', 0.022030661),
 ('TV(2.0) Loss', 0.19226514)], overall loss: -1.41417491436
Iteration: 1352, named_losses: [('ActivationMax Loss', -1.6163105),
 ('L-6.0 Norm Loss', 0.022031467),
 ('TV(2.0) Loss', 0.19116853)], overall loss: -1.40311050415
Iteration: 1353, named_losses: [('ActivationMax Loss', -1.6155342),
 ('L-6.0 Norm Loss', 0.022030849),
 ('TV(2.0) Loss', 0.19228618)], overall loss: -1.40121722221
Iteration: 1354, named_losses: [('ActivationMax Loss', -1.6455715),
 ('L-6.0 Norm Loss', 0.02203111),
 ('TV(2.0) Loss', 0.19182324)], overall loss: -1.43171715736
Iteration: 1355, named_losses: [('ActivationMax Loss', -1.6278318),
 ('L-6.0 Norm Loss', 0.022028364),
 ('TV(2.0) Loss', 0.18931051)], overall loss: -1.416492939
Iteration: 1356, named_losses: [('ActivationMax Loss', -1.6355371),
 ('L-6.0 Norm Loss', 0.022028888),
 ('TV(2.0) Loss', 0.1886263)], overall loss: -1.42488193512
Iteration: 1357, named_losses: [('ActivationMax Loss', -1.625791),
 ('L-6.0 Norm Loss', 0.0220295),
 ('TV(2.0) Loss', 0.18855639)], overall loss: -1.41520500183
Iteration: 1358, named_losses: [('ActivationMax Loss', -1.6182392),
 ('L-6.0 Norm Loss', 0.022028506),
 ('TV(2.0) Loss', 0.18820196)], overall loss: -1.40800881386
Iteration: 1359, named_losses: [('ActivationMax Loss', -1.5562251),
 ('L-6.0 Norm Loss', 0.022026885),
 ('TV(2.0) Loss', 0.18793102)], overall loss: -1.34626710415
Iteration: 1360, named_losses: [('ActivationMax Loss', -1.5998319),
 ('L-6.0 Norm Loss', 0.022028353),
 ('TV(2.0) Loss', 0.18819073)], overall loss: -1.38961291313
Iteration: 1361, named_losses: [('ActivationMax Loss', -1.6278728),
 ('L-6.0 Norm Loss', 0.022027489),
 ('TV(2.0) Loss', 0.18905394)], overall loss: -1.41679143906
Iteration: 1362, named_losses: [('ActivationMax Loss', -1.6162387),
 ('L-6.0 Norm Loss', 0.022027241),
 ('TV(2.0) Loss', 0.18798153)], overall loss: -1.40622997284
Iteration: 1363, named_losses: [('ActivationMax Loss', -1.5662618),
 ('L-6.0 Norm Loss', 0.022026774),
 ('TV(2.0) Loss', 0.18920536)], overall loss: -1.35502958298
Iteration: 1364, named_losses: [('ActivationMax Loss', -1.6308925),
 ('L-6.0 Norm Loss', 0.022027297),
 ('TV(2.0) Loss', 0.18911862)], overall loss: -1.41974663734
Iteration: 1365, named_losses: [('ActivationMax Loss', -1.613435),
 ('L-6.0 Norm Loss', 0.022026144),
 ('TV(2.0) Loss', 0.18996684)], overall loss: -1.40144205093
Iteration: 1366, named_losses: [('ActivationMax Loss', -1.6004406),
 ('L-6.0 Norm Loss', 0.022026815),
 ('TV(2.0) Loss', 0.18965848)], overall loss: -1.3887553215
Iteration: 1367, named_losses: [('ActivationMax Loss', -1.5899802),
 ('L-6.0 Norm Loss', 0.022027383),
 ('TV(2.0) Loss', 0.19088085)], overall loss: -1.37707197666
Iteration: 1368, named_losses: [('ActivationMax Loss', -1.5904827),
 ('L-6.0 Norm Loss', 0.022027025),
 ('TV(2.0) Loss', 0.1908572)], overall loss: -1.37759852409
Iteration: 1369, named_losses: [('ActivationMax Loss', -1.6254791),
 ('L-6.0 Norm Loss', 0.022025678),
 ('TV(2.0) Loss', 0.19064423)], overall loss: -1.41280913353
Iteration: 1370, named_losses: [('ActivationMax Loss', -1.65062),
 ('L-6.0 Norm Loss', 0.022026012),
 ('TV(2.0) Loss', 0.19056951)], overall loss: -1.43802440166
Iteration: 1371, named_losses: [('ActivationMax Loss', -1.6412401),
 ('L-6.0 Norm Loss', 0.02202454),
 ('TV(2.0) Loss', 0.18913515)], overall loss: -1.43008041382
Iteration: 1372, named_losses: [('ActivationMax Loss', -1.6264026),
 ('L-6.0 Norm Loss', 0.022025),
 ('TV(2.0) Loss', 0.18993068)], overall loss: -1.41444694996
Iteration: 1373, named_losses: [('ActivationMax Loss', -1.5936631),
 ('L-6.0 Norm Loss', 0.022023547),
 ('TV(2.0) Loss', 0.18869251)], overall loss: -1.38294696808
Iteration: 1374, named_losses: [('ActivationMax Loss', -1.6247684),
 ('L-6.0 Norm Loss', 0.022022776),
 ('TV(2.0) Loss', 0.18920034)], overall loss: -1.4135453701
Iteration: 1375, named_losses: [('ActivationMax Loss', -1.5569491),
 ('L-6.0 Norm Loss', 0.022022294),
 ('TV(2.0) Loss', 0.18904842)], overall loss: -1.34587848186
Iteration: 1376, named_losses: [('ActivationMax Loss', -1.5396442),
 ('L-6.0 Norm Loss', 0.022022057),
 ('TV(2.0) Loss', 0.19032086)], overall loss: -1.32730138302
Iteration: 1377, named_losses: [('ActivationMax Loss', -1.5832417),
 ('L-6.0 Norm Loss', 0.022021683),
 ('TV(2.0) Loss', 0.19019952)], overall loss: -1.3710205555
Iteration: 1378, named_losses: [('ActivationMax Loss', -1.6272391),
 ('L-6.0 Norm Loss', 0.022021063),
 ('TV(2.0) Loss', 0.19004889)], overall loss: -1.41516911983
Iteration: 1379, named_losses: [('ActivationMax Loss', -1.590416),
 ('L-6.0 Norm Loss', 0.022023914),
 ('TV(2.0) Loss', 0.18994215)], overall loss: -1.37844991684
Iteration: 1380, named_losses: [('ActivationMax Loss', -1.6013314),
 ('L-6.0 Norm Loss', 0.022021031),
 ('TV(2.0) Loss', 0.19079414)], overall loss: -1.38851618767
Iteration: 1381, named_losses: [('ActivationMax Loss', -1.5898848),
 ('L-6.0 Norm Loss', 0.022022732),
 ('TV(2.0) Loss', 0.18944483)], overall loss: -1.37841725349
Iteration: 1382, named_losses: [('ActivationMax Loss', -1.6110263),
 ('L-6.0 Norm Loss', 0.022021566),
 ('TV(2.0) Loss', 0.19036327)], overall loss: -1.39864146709
Iteration: 1383, named_losses: [('ActivationMax Loss', -1.5956475),
 ('L-6.0 Norm Loss', 0.022023488),
 ('TV(2.0) Loss', 0.19144031)], overall loss: -1.382183671
Iteration: 1384, named_losses: [('ActivationMax Loss', -1.6017278),
 ('L-6.0 Norm Loss', 0.02202186),
 ('TV(2.0) Loss', 0.19262254)], overall loss: -1.38708341122
Iteration: 1385, named_losses: [('ActivationMax Loss', -1.5783769),
 ('L-6.0 Norm Loss', 0.02202349),
 ('TV(2.0) Loss', 0.19279721)], overall loss: -1.36355626583
Iteration: 1386, named_losses: [('ActivationMax Loss', -1.6351454),
 ('L-6.0 Norm Loss', 0.022023205),
 ('TV(2.0) Loss', 0.19306207)], overall loss: -1.42006015778
Iteration: 1387, named_losses: [('ActivationMax Loss', -1.6224337),
 ('L-6.0 Norm Loss', 0.02202221),
 ('TV(2.0) Loss', 0.19153236)], overall loss: -1.40887904167
Iteration: 1388, named_losses: [('ActivationMax Loss', -1.6133506),
 ('L-6.0 Norm Loss', 0.022021661),
 ('TV(2.0) Loss', 0.19158782)], overall loss: -1.39974117279
Iteration: 1389, named_losses: [('ActivationMax Loss', -1.597645),
 ('L-6.0 Norm Loss', 0.022021702),
 ('TV(2.0) Loss', 0.19094902)], overall loss: -1.38467431068
Iteration: 1390, named_losses: [('ActivationMax Loss', -1.6059549),
 ('L-6.0 Norm Loss', 0.022020901),
 ('TV(2.0) Loss', 0.19121484)], overall loss: -1.39271914959
Iteration: 1391, named_losses: [('ActivationMax Loss', -1.604776),
 ('L-6.0 Norm Loss', 0.022020392),
 ('TV(2.0) Loss', 0.19112153)], overall loss: -1.39163410664
Iteration: 1392, named_losses: [('ActivationMax Loss', -1.590839),
 ('L-6.0 Norm Loss', 0.02201979),
 ('TV(2.0) Loss', 0.18992634)], overall loss: -1.37889289856
Iteration: 1393, named_losses: [('ActivationMax Loss', -1.5829089),
 ('L-6.0 Norm Loss', 0.022020999),
 ('TV(2.0) Loss', 0.19079089)], overall loss: -1.37009692192
Iteration: 1394, named_losses: [('ActivationMax Loss', -1.6101332),
 ('L-6.0 Norm Loss', 0.022021201),
 ('TV(2.0) Loss', 0.18986426)], overall loss: -1.39824771881
Iteration: 1395, named_losses: [('ActivationMax Loss', -1.6116297),
 ('L-6.0 Norm Loss', 0.02202037),
 ('TV(2.0) Loss', 0.19024794)], overall loss: -1.3993614912
Iteration: 1396, named_losses: [('ActivationMax Loss', -1.6054521),
 ('L-6.0 Norm Loss', 0.022019345),
 ('TV(2.0) Loss', 0.18763034)], overall loss: -1.39580237865
Iteration: 1397, named_losses: [('ActivationMax Loss', -1.599347),
 ('L-6.0 Norm Loss', 0.022018932),
 ('TV(2.0) Loss', 0.18714884)], overall loss: -1.39017927647
Iteration: 1398, named_losses: [('ActivationMax Loss', -1.6158588),
 ('L-6.0 Norm Loss', 0.022019481),
 ('TV(2.0) Loss', 0.18624137)], overall loss: -1.40759789944
Iteration: 1399, named_losses: [('ActivationMax Loss', -1.5952797),
 ('L-6.0 Norm Loss', 0.022017092),
 ('TV(2.0) Loss', 0.18737698)], overall loss: -1.38588559628
Iteration: 1400, named_losses: [('ActivationMax Loss', -1.5933908),
 ('L-6.0 Norm Loss', 0.022018233),
 ('TV(2.0) Loss', 0.18820612)], overall loss: -1.38316655159
Iteration: 1401, named_losses: [('ActivationMax Loss', -1.6164613),
 ('L-6.0 Norm Loss', 0.022018047),
 ('TV(2.0) Loss', 0.18874007)], overall loss: -1.40570306778
Iteration: 1402, named_losses: [('ActivationMax Loss', -1.6535271),
 ('L-6.0 Norm Loss', 0.022017628),
 ('TV(2.0) Loss', 0.18886268)], overall loss: -1.44264686108
Iteration: 1403, named_losses: [('ActivationMax Loss', -1.627018),
 ('L-6.0 Norm Loss', 0.022016494),
 ('TV(2.0) Loss', 0.18829894)], overall loss: -1.41670250893
Iteration: 1404, named_losses: [('ActivationMax Loss', -1.6143),
 ('L-6.0 Norm Loss', 0.022016598),
 ('TV(2.0) Loss', 0.1883954)], overall loss: -1.40388798714
Iteration: 1405, named_losses: [('ActivationMax Loss', -1.6133771),
 ('L-6.0 Norm Loss', 0.022015542),
 ('TV(2.0) Loss', 0.18893249)], overall loss: -1.40242898464
Iteration: 1406, named_losses: [('ActivationMax Loss', -1.6514246),
 ('L-6.0 Norm Loss', 0.022016555),
 ('TV(2.0) Loss', 0.18959472)], overall loss: -1.43981337547
Iteration: 1407, named_losses: [('ActivationMax Loss', -1.5913496),
 ('L-6.0 Norm Loss', 0.022014396),
 ('TV(2.0) Loss', 0.18915296)], overall loss: -1.38018226624
Iteration: 1408, named_losses: [('ActivationMax Loss', -1.6476617),
 ('L-6.0 Norm Loss', 0.022014465),
 ('TV(2.0) Loss', 0.19030353)], overall loss: -1.43534362316
Iteration: 1409, named_losses: [('ActivationMax Loss', -1.5971713),
 ('L-6.0 Norm Loss', 0.022015411),
 ('TV(2.0) Loss', 0.18815145)], overall loss: -1.38700437546
Iteration: 1410, named_losses: [('ActivationMax Loss', -1.62052),
 ('L-6.0 Norm Loss', 0.022015171),
 ('TV(2.0) Loss', 0.18811287)], overall loss: -1.41039192677
Iteration: 1411, named_losses: [('ActivationMax Loss', -1.5232295),
 ('L-6.0 Norm Loss', 0.022013469),
 ('TV(2.0) Loss', 0.18786509)], overall loss: -1.31335091591
Iteration: 1412, named_losses: [('ActivationMax Loss', -1.5761333),
 ('L-6.0 Norm Loss', 0.022015002),
 ('TV(2.0) Loss', 0.18815908)], overall loss: -1.36595916748
Iteration: 1413, named_losses: [('ActivationMax Loss', -1.5849574),
 ('L-6.0 Norm Loss', 0.022014624),
 ('TV(2.0) Loss', 0.18833612)], overall loss: -1.37460660934
Iteration: 1414, named_losses: [('ActivationMax Loss', -1.6383234),
 ('L-6.0 Norm Loss', 0.022013912),
 ('TV(2.0) Loss', 0.18819356)], overall loss: -1.42811596394
Iteration: 1415, named_losses: [('ActivationMax Loss', -1.6155612),
 ('L-6.0 Norm Loss', 0.022013497),
 ('TV(2.0) Loss', 0.18767297)], overall loss: -1.40587472916
Iteration: 1416, named_losses: [('ActivationMax Loss', -1.6247797),
 ('L-6.0 Norm Loss', 0.022013154),
 ('TV(2.0) Loss', 0.18736808)], overall loss: -1.41539847851
Iteration: 1417, named_losses: [('ActivationMax Loss', -1.6120269),
 ('L-6.0 Norm Loss', 0.022012949),
 ('TV(2.0) Loss', 0.18860602)], overall loss: -1.40140795708
Iteration: 1418, named_losses: [('ActivationMax Loss', -1.6383351),
 ('L-6.0 Norm Loss', 0.022012886),
 ('TV(2.0) Loss', 0.18791519)], overall loss: -1.42840707302
Iteration: 1419, named_losses: [('ActivationMax Loss', -1.5787102),
 ('L-6.0 Norm Loss', 0.022011794),
 ('TV(2.0) Loss', 0.18713026)], overall loss: -1.36956822872
Iteration: 1420, named_losses: [('ActivationMax Loss', -1.6483755),
 ('L-6.0 Norm Loss', 0.022011723),
 ('TV(2.0) Loss', 0.1871562)], overall loss: -1.43920755386
Iteration: 1421, named_losses: [('ActivationMax Loss', -1.5761639),
 ('L-6.0 Norm Loss', 0.02201196),
 ('TV(2.0) Loss', 0.18754533)], overall loss: -1.36660659313
Iteration: 1422, named_losses: [('ActivationMax Loss', -1.6098666),
 ('L-6.0 Norm Loss', 0.022009796),
 ('TV(2.0) Loss', 0.18733986)], overall loss: -1.40051686764
Iteration: 1423, named_losses: [('ActivationMax Loss', -1.584368),
 ('L-6.0 Norm Loss', 0.022011399),
 ('TV(2.0) Loss', 0.18943088)], overall loss: -1.37292575836
Iteration: 1424, named_losses: [('ActivationMax Loss', -1.6422212),
 ('L-6.0 Norm Loss', 0.022010807),
 ('TV(2.0) Loss', 0.18848409)], overall loss: -1.43172633648
Iteration: 1425, named_losses: [('ActivationMax Loss', -1.6159341),
 ('L-6.0 Norm Loss', 0.022011174),
 ('TV(2.0) Loss', 0.18867929)], overall loss: -1.40524363518
Iteration: 1426, named_losses: [('ActivationMax Loss', -1.6345634),
 ('L-6.0 Norm Loss', 0.02200973),
 ('TV(2.0) Loss', 0.18885995)], overall loss: -1.42369377613
Iteration: 1427, named_losses: [('ActivationMax Loss', -1.5983269),
 ('L-6.0 Norm Loss', 0.02200946),
 ('TV(2.0) Loss', 0.18978755)], overall loss: -1.38652992249
Iteration: 1428, named_losses: [('ActivationMax Loss', -1.6099952),
 ('L-6.0 Norm Loss', 0.022007992),
 ('TV(2.0) Loss', 0.18909553)], overall loss: -1.3988918066
Iteration: 1429, named_losses: [('ActivationMax Loss', -1.6518846),
 ('L-6.0 Norm Loss', 0.022009183),
 ('TV(2.0) Loss', 0.19086942)], overall loss: -1.43900597095
Iteration: 1430, named_losses: [('ActivationMax Loss', -1.6211452),
 ('L-6.0 Norm Loss', 0.022008564),
 ('TV(2.0) Loss', 0.18989654)], overall loss: -1.40924012661
Iteration: 1431, named_losses: [('ActivationMax Loss', -1.6123416),
 ('L-6.0 Norm Loss', 0.022008216),
 ('TV(2.0) Loss', 0.19049056)], overall loss: -1.39984285831
Iteration: 1432, named_losses: [('ActivationMax Loss', -1.6287199),
 ('L-6.0 Norm Loss', 0.022009294),
 ('TV(2.0) Loss', 0.19032985)], overall loss: -1.41638088226
Iteration: 1433, named_losses: [('ActivationMax Loss', -1.6318277),
 ('L-6.0 Norm Loss', 0.022008492),
 ('TV(2.0) Loss', 0.1906141)], overall loss: -1.41920506954
Iteration: 1434, named_losses: [('ActivationMax Loss', -1.6470072),
 ('L-6.0 Norm Loss', 0.022007825),
 ('TV(2.0) Loss', 0.19030333)], overall loss: -1.4346960783
Iteration: 1435, named_losses: [('ActivationMax Loss', -1.6124229),
 ('L-6.0 Norm Loss', 0.022007918),
 ('TV(2.0) Loss', 0.18925469)], overall loss: -1.40116035938
Iteration: 1436, named_losses: [('ActivationMax Loss', -1.6295173),
 ('L-6.0 Norm Loss', 0.02200903),
 ('TV(2.0) Loss', 0.19033182)], overall loss: -1.41717648506
Iteration: 1437, named_losses: [('ActivationMax Loss', -1.6378388),
 ('L-6.0 Norm Loss', 0.022007542),
 ('TV(2.0) Loss', 0.18863913)], overall loss: -1.42719209194
Iteration: 1438, named_losses: [('ActivationMax Loss', -1.618452),
 ('L-6.0 Norm Loss', 0.022006877),
 ('TV(2.0) Loss', 0.18898471)], overall loss: -1.40746033192
Iteration: 1439, named_losses: [('ActivationMax Loss', -1.5904059),
 ('L-6.0 Norm Loss', 0.022008359),
 ('TV(2.0) Loss', 0.18966705)], overall loss: -1.37873053551
Iteration: 1440, named_losses: [('ActivationMax Loss', -1.6486121),
 ('L-6.0 Norm Loss', 0.02200726),
 ('TV(2.0) Loss', 0.19033207)], overall loss: -1.43627285957
Iteration: 1441, named_losses: [('ActivationMax Loss', -1.6012846),
 ('L-6.0 Norm Loss', 0.022006156),
 ('TV(2.0) Loss', 0.18955319)], overall loss: -1.38972532749
Iteration: 1442, named_losses: [('ActivationMax Loss', -1.626511),
 ('L-6.0 Norm Loss', 0.022006409),
 ('TV(2.0) Loss', 0.19110259)], overall loss: -1.41340196133
Iteration: 1443, named_losses: [('ActivationMax Loss', -1.6251671),
 ('L-6.0 Norm Loss', 0.022006491),
 ('TV(2.0) Loss', 0.18893187)], overall loss: -1.41422879696
Iteration: 1444, named_losses: [('ActivationMax Loss', -1.6232688),
 ('L-6.0 Norm Loss', 0.022005683),
 ('TV(2.0) Loss', 0.18924947)], overall loss: -1.41201364994
Iteration: 1445, named_losses: [('ActivationMax Loss', -1.6529959),
 ('L-6.0 Norm Loss', 0.02200556),
 ('TV(2.0) Loss', 0.18801303)], overall loss: -1.44297730923
Iteration: 1446, named_losses: [('ActivationMax Loss', -1.6404293),
 ('L-6.0 Norm Loss', 0.022004561),
 ('TV(2.0) Loss', 0.18729988)], overall loss: -1.4311248064
Iteration: 1447, named_losses: [('ActivationMax Loss', -1.5827638),
 ('L-6.0 Norm Loss', 0.022003669),
 ('TV(2.0) Loss', 0.18741266)], overall loss: -1.37334752083
Iteration: 1448, named_losses: [('ActivationMax Loss', -1.6501122),
 ('L-6.0 Norm Loss', 0.022004504),
 ('TV(2.0) Loss', 0.18734673)], overall loss: -1.44076097012
Iteration: 1449, named_losses: [('ActivationMax Loss', -1.645391),
 ('L-6.0 Norm Loss', 0.022003461),
 ('TV(2.0) Loss', 0.18687809)], overall loss: -1.43650949001
Iteration: 1450, named_losses: [('ActivationMax Loss', -1.569963),
 ('L-6.0 Norm Loss', 0.022002053),
 ('TV(2.0) Loss', 0.18702947)], overall loss: -1.36093139648
Iteration: 1451, named_losses: [('ActivationMax Loss', -1.6370393),
 ('L-6.0 Norm Loss', 0.022001693),
 ('TV(2.0) Loss', 0.18713601)], overall loss: -1.42790150642
Iteration: 1452, named_losses: [('ActivationMax Loss', -1.6269052),
 ('L-6.0 Norm Loss', 0.022001754),
 ('TV(2.0) Loss', 0.18637699)], overall loss: -1.41852641106
Iteration: 1453, named_losses: [('ActivationMax Loss', -1.6161981),
 ('L-6.0 Norm Loss', 0.022000911),
 ('TV(2.0) Loss', 0.18804508)], overall loss: -1.40615200996
Iteration: 1454, named_losses: [('ActivationMax Loss', -1.5672166),
 ('L-6.0 Norm Loss', 0.022001846),
 ('TV(2.0) Loss', 0.18655276)], overall loss: -1.35866200924
Iteration: 1455, named_losses: [('ActivationMax Loss', -1.6170399),
 ('L-6.0 Norm Loss', 0.022001568),
 ('TV(2.0) Loss', 0.18747672)], overall loss: -1.4075615406
Iteration: 1456, named_losses: [('ActivationMax Loss', -1.6250409),
 ('L-6.0 Norm Loss', 0.022002097),
 ('TV(2.0) Loss', 0.18584248)], overall loss: -1.4171962738
Iteration: 1457, named_losses: [('ActivationMax Loss', -1.6249347),
 ('L-6.0 Norm Loss', 0.022001239),
 ('TV(2.0) Loss', 0.18682654)], overall loss: -1.41610682011
Iteration: 1458, named_losses: [('ActivationMax Loss', -1.6201962),
 ('L-6.0 Norm Loss', 0.022001015),
 ('TV(2.0) Loss', 0.18625954)], overall loss: -1.41193568707
Iteration: 1459, named_losses: [('ActivationMax Loss', -1.6607199),
 ('L-6.0 Norm Loss', 0.022000901),
 ('TV(2.0) Loss', 0.18652572)], overall loss: -1.45219326019
Iteration: 1460, named_losses: [('ActivationMax Loss', -1.6221081),
 ('L-6.0 Norm Loss', 0.022000996),
 ('TV(2.0) Loss', 0.18654513)], overall loss: -1.41356194019
Iteration: 1461, named_losses: [('ActivationMax Loss', -1.6003104),
 ('L-6.0 Norm Loss', 0.022000615),
 ('TV(2.0) Loss', 0.18569347)], overall loss: -1.39261627197
Iteration: 1462, named_losses: [('ActivationMax Loss', -1.6384932),
 ('L-6.0 Norm Loss', 0.022000775),
 ('TV(2.0) Loss', 0.18691383)], overall loss: -1.42957854271
Iteration: 1463, named_losses: [('ActivationMax Loss', -1.5815172),
 ('L-6.0 Norm Loss', 0.021999387),
 ('TV(2.0) Loss', 0.18517837)], overall loss: -1.37433946133
Iteration: 1464, named_losses: [('ActivationMax Loss', -1.5758033),
 ('L-6.0 Norm Loss', 0.021999363),
 ('TV(2.0) Loss', 0.18657072)], overall loss: -1.36723315716
Iteration: 1465, named_losses: [('ActivationMax Loss', -1.6343611),
 ('L-6.0 Norm Loss', 0.021999985),
 ('TV(2.0) Loss', 0.18676221)], overall loss: -1.425598979
Iteration: 1466, named_losses: [('ActivationMax Loss', -1.6358263),
 ('L-6.0 Norm Loss', 0.021999873),
 ('TV(2.0) Loss', 0.1870077)], overall loss: -1.42681884766
Iteration: 1467, named_losses: [('ActivationMax Loss', -1.5885094),
 ('L-6.0 Norm Loss', 0.021999052),
 ('TV(2.0) Loss', 0.18645737)], overall loss: -1.38005304337
Iteration: 1468, named_losses: [('ActivationMax Loss', -1.6246275),
 ('L-6.0 Norm Loss', 0.021998361),
 ('TV(2.0) Loss', 0.18731192)], overall loss: -1.41531717777
Iteration: 1469, named_losses: [('ActivationMax Loss', -1.6390023),
 ('L-6.0 Norm Loss', 0.02199886),
 ('TV(2.0) Loss', 0.18775104)], overall loss: -1.42925238609
Iteration: 1470, named_losses: [('ActivationMax Loss', -1.6629854),
 ('L-6.0 Norm Loss', 0.021999266),
 ('TV(2.0) Loss', 0.1884336)], overall loss: -1.45255255699
Iteration: 1471, named_losses: [('ActivationMax Loss', -1.6190495),
 ('L-6.0 Norm Loss', 0.021999061),
 ('TV(2.0) Loss', 0.18726069)], overall loss: -1.40978980064
Iteration: 1472, named_losses: [('ActivationMax Loss', -1.6274568),
 ('L-6.0 Norm Loss', 0.02199767),
 ('TV(2.0) Loss', 0.18750532)], overall loss: -1.41795372963
Iteration: 1473, named_losses: [('ActivationMax Loss', -1.6513313),
 ('L-6.0 Norm Loss', 0.021997949),
 ('TV(2.0) Loss', 0.18792391)], overall loss: -1.44140946865
Iteration: 1474, named_losses: [('ActivationMax Loss', -1.6210694),
 ('L-6.0 Norm Loss', 0.021996994),
 ('TV(2.0) Loss', 0.18751247)], overall loss: -1.41155993938
Iteration: 1475, named_losses: [('ActivationMax Loss', -1.626569),
 ('L-6.0 Norm Loss', 0.021996086),
 ('TV(2.0) Loss', 0.18607263)], overall loss: -1.41850030422
Iteration: 1476, named_losses: [('ActivationMax Loss', -1.6354598),
 ('L-6.0 Norm Loss', 0.021997057),
 ('TV(2.0) Loss', 0.18760151)], overall loss: -1.42586112022
Iteration: 1477, named_losses: [('ActivationMax Loss', -1.5906695),
 ('L-6.0 Norm Loss', 0.021996042),
 ('TV(2.0) Loss', 0.18688945)], overall loss: -1.38178408146
Iteration: 1478, named_losses: [('ActivationMax Loss', -1.636935),
 ('L-6.0 Norm Loss', 0.021996899),
 ('TV(2.0) Loss', 0.18942854)], overall loss: -1.42550957203
Iteration: 1479, named_losses: [('ActivationMax Loss', -1.6272694),
 ('L-6.0 Norm Loss', 0.02199471),
 ('TV(2.0) Loss', 0.1866308)], overall loss: -1.41864383221
Iteration: 1480, named_losses: [('ActivationMax Loss', -1.6337386),
 ('L-6.0 Norm Loss', 0.021995582),
 ('TV(2.0) Loss', 0.18654674)], overall loss: -1.42519640923
Iteration: 1481, named_losses: [('ActivationMax Loss', -1.6108189),
 ('L-6.0 Norm Loss', 0.02199509),
 ('TV(2.0) Loss', 0.18754525)], overall loss: -1.40127849579
Iteration: 1482, named_losses: [('ActivationMax Loss', -1.6368344),
 ('L-6.0 Norm Loss', 0.021994913),
 ('TV(2.0) Loss', 0.1880295)], overall loss: -1.42680990696
Iteration: 1483, named_losses: [('ActivationMax Loss', -1.6010789),
 ('L-6.0 Norm Loss', 0.021994092),
 ('TV(2.0) Loss', 0.18827704)], overall loss: -1.39080774784
Iteration: 1484, named_losses: [('ActivationMax Loss', -1.6121992),
 ('L-6.0 Norm Loss', 0.021994272),
 ('TV(2.0) Loss', 0.18998779)], overall loss: -1.40021717548
Iteration: 1485, named_losses: [('ActivationMax Loss', -1.6372784),
 ('L-6.0 Norm Loss', 0.021994429),
 ('TV(2.0) Loss', 0.19167998)], overall loss: -1.42360401154
Iteration: 1486, named_losses: [('ActivationMax Loss', -1.6358843),
 ('L-6.0 Norm Loss', 0.021994073),
 ('TV(2.0) Loss', 0.1898884)], overall loss: -1.42400181293
Iteration: 1487, named_losses: [('ActivationMax Loss', -1.6462574),
 ('L-6.0 Norm Loss', 0.021993708),
 ('TV(2.0) Loss', 0.19107623)], overall loss: -1.43318736553
Iteration: 1488, named_losses: [('ActivationMax Loss', -1.6303951),
 ('L-6.0 Norm Loss', 0.021992851),
 ('TV(2.0) Loss', 0.19004692)], overall loss: -1.41835534573
Iteration: 1489, named_losses: [('ActivationMax Loss', -1.6467642),
 ('L-6.0 Norm Loss', 0.02199218),
 ('TV(2.0) Loss', 0.18919128)], overall loss: -1.43558073044
Iteration: 1490, named_losses: [('ActivationMax Loss', -1.6600134),
 ('L-6.0 Norm Loss', 0.021993566),
 ('TV(2.0) Loss', 0.19015777)], overall loss: -1.44786214828
Iteration: 1491, named_losses: [('ActivationMax Loss', -1.5886757),
 ('L-6.0 Norm Loss', 0.021990109),
 ('TV(2.0) Loss', 0.18888876)], overall loss: -1.37779688835
Iteration: 1492, named_losses: [('ActivationMax Loss', -1.6233134),
 ('L-6.0 Norm Loss', 0.021990964),
 ('TV(2.0) Loss', 0.19093658)], overall loss: -1.41038584709
Iteration: 1493, named_losses: [('ActivationMax Loss', -1.5847161),
 ('L-6.0 Norm Loss', 0.021990605),
 ('TV(2.0) Loss', 0.1903886)], overall loss: -1.37233686447
Iteration: 1494, named_losses: [('ActivationMax Loss', -1.6273313),
 ('L-6.0 Norm Loss', 0.021991618),
 ('TV(2.0) Loss', 0.19168517)], overall loss: -1.4136544466
Iteration: 1495, named_losses: [('ActivationMax Loss', -1.5983429),
 ('L-6.0 Norm Loss', 0.021990951),
 ('TV(2.0) Loss', 0.19091411)], overall loss: -1.38543784618
Iteration: 1496, named_losses: [('ActivationMax Loss', -1.601747),
 ('L-6.0 Norm Loss', 0.021990368),
 ('TV(2.0) Loss', 0.19186123)], overall loss: -1.38789534569
Iteration: 1497, named_losses: [('ActivationMax Loss', -1.6126304),
 ('L-6.0 Norm Loss', 0.021990707),
 ('TV(2.0) Loss', 0.19229291)], overall loss: -1.39834678173
Iteration: 1498, named_losses: [('ActivationMax Loss', -1.6269586),
 ('L-6.0 Norm Loss', 0.021990828),
 ('TV(2.0) Loss', 0.19285499)], overall loss: -1.41211283207
Iteration: 1499, named_losses: [('ActivationMax Loss', -1.6266135),
 ('L-6.0 Norm Loss', 0.021989405),
 ('TV(2.0) Loss', 0.19262724)], overall loss: -1.41199684143
Iteration: 1500, named_losses: [('ActivationMax Loss', -1.5972265),
 ('L-6.0 Norm Loss', 0.021989418),
 ('TV(2.0) Loss', 0.19226654)], overall loss: -1.38297045231
Iteration: 1501, named_losses: [('ActivationMax Loss', -1.5897921),
 ('L-6.0 Norm Loss', 0.021987798),
 ('TV(2.0) Loss', 0.19222511)], overall loss: -1.37557923794
Iteration: 1502, named_losses: [('ActivationMax Loss', -1.5911188),
 ('L-6.0 Norm Loss', 0.021989033),
 ('TV(2.0) Loss', 0.19189289)], overall loss: -1.37723696232
Iteration: 1503, named_losses: [('ActivationMax Loss', -1.634654),
 ('L-6.0 Norm Loss', 0.021987606),
 ('TV(2.0) Loss', 0.19077203)], overall loss: -1.42189443111
Iteration: 1504, named_losses: [('ActivationMax Loss', -1.5818294),
 ('L-6.0 Norm Loss', 0.021987159),
 ('TV(2.0) Loss', 0.18997373)], overall loss: -1.36986851692
Iteration: 1505, named_losses: [('ActivationMax Loss', -1.6020892),
 ('L-6.0 Norm Loss', 0.021988995),
 ('TV(2.0) Loss', 0.19062072)], overall loss: -1.38947939873
Iteration: 1506, named_losses: [('ActivationMax Loss', -1.6297538),
 ('L-6.0 Norm Loss', 0.021987986),
 ('TV(2.0) Loss', 0.1899299)], overall loss: -1.41783595085
Iteration: 1507, named_losses: [('ActivationMax Loss', -1.614308),
 ('L-6.0 Norm Loss', 0.021987557),
 ('TV(2.0) Loss', 0.19086376)], overall loss: -1.40145671368
Iteration: 1508, named_losses: [('ActivationMax Loss', -1.6287252),
 ('L-6.0 Norm Loss', 0.021989025),
 ('TV(2.0) Loss', 0.19026814)], overall loss: -1.41646802425
Iteration: 1509, named_losses: [('ActivationMax Loss', -1.6315296),
 ('L-6.0 Norm Loss', 0.021987878),
 ('TV(2.0) Loss', 0.1902035)], overall loss: -1.41933810711
Iteration: 1510, named_losses: [('ActivationMax Loss', -1.6245775),
 ('L-6.0 Norm Loss', 0.021986455),
 ('TV(2.0) Loss', 0.18909195)], overall loss: -1.4134991169
Iteration: 1511, named_losses: [('ActivationMax Loss', -1.6012303),
 ('L-6.0 Norm Loss', 0.021987164),
 ('TV(2.0) Loss', 0.18958659)], overall loss: -1.38965642452
Iteration: 1512, named_losses: [('ActivationMax Loss', -1.6196183),
 ('L-6.0 Norm Loss', 0.021985635),
 ('TV(2.0) Loss', 0.18911622)], overall loss: -1.40851640701
Iteration: 1513, named_losses: [('ActivationMax Loss', -1.5952821),
 ('L-6.0 Norm Loss', 0.021986274),
 ('TV(2.0) Loss', 0.18818435)], overall loss: -1.38511145115
Iteration: 1514, named_losses: [('ActivationMax Loss', -1.6215234),
 ('L-6.0 Norm Loss', 0.021985138),
 ('TV(2.0) Loss', 0.18622419)], overall loss: -1.41331398487
Iteration: 1515, named_losses: [('ActivationMax Loss', -1.5986221),
 ('L-6.0 Norm Loss', 0.02198419),
 ('TV(2.0) Loss', 0.1866667)], overall loss: -1.38997113705
Iteration: 1516, named_losses: [('ActivationMax Loss', -1.6223495),
 ('L-6.0 Norm Loss', 0.021984898),
 ('TV(2.0) Loss', 0.18719806)], overall loss: -1.41316652298
Iteration: 1517, named_losses: [('ActivationMax Loss', -1.6219146),
 ('L-6.0 Norm Loss', 0.021984885),
 ('TV(2.0) Loss', 0.18790512)], overall loss: -1.4120246172
Iteration: 1518, named_losses: [('ActivationMax Loss', -1.5936537),
 ('L-6.0 Norm Loss', 0.021984594),
 ('TV(2.0) Loss', 0.18774737)], overall loss: -1.38392174244
Iteration: 1519, named_losses: [('ActivationMax Loss', -1.6199714),
 ('L-6.0 Norm Loss', 0.021984892),
 ('TV(2.0) Loss', 0.1877576)], overall loss: -1.41022884846
Iteration: 1520, named_losses: [('ActivationMax Loss', -1.6274554),
 ('L-6.0 Norm Loss', 0.021984147),
 ('TV(2.0) Loss', 0.18732545)], overall loss: -1.41814577579
Iteration: 1521, named_losses: [('ActivationMax Loss', -1.6165545),
 ('L-6.0 Norm Loss', 0.021984493),
 ('TV(2.0) Loss', 0.1881934)], overall loss: -1.40637660027
Iteration: 1522, named_losses: [('ActivationMax Loss', -1.6427238),
 ('L-6.0 Norm Loss', 0.02198413),
 ('TV(2.0) Loss', 0.18737835)], overall loss: -1.43336129189
Iteration: 1523, named_losses: [('ActivationMax Loss', -1.604385),
 ('L-6.0 Norm Loss', 0.021984171),
 ('TV(2.0) Loss', 0.18612543)], overall loss: -1.39627540112
Iteration: 1524, named_losses: [('ActivationMax Loss', -1.6433115),
 ('L-6.0 Norm Loss', 0.021983834),
 ('TV(2.0) Loss', 0.18769707)], overall loss: -1.43363058567
Iteration: 1525, named_losses: [('ActivationMax Loss', -1.6343623),
 ('L-6.0 Norm Loss', 0.021982761),
 ('TV(2.0) Loss', 0.18750374)], overall loss: -1.42487585545
Iteration: 1526, named_losses: [('ActivationMax Loss', -1.6158929),
 ('L-6.0 Norm Loss', 0.021983307),
 ('TV(2.0) Loss', 0.18671189)], overall loss: -1.40719771385
Iteration: 1527, named_losses: [('ActivationMax Loss', -1.6478446),
 ('L-6.0 Norm Loss', 0.021982407),
 ('TV(2.0) Loss', 0.18756682)], overall loss: -1.43829536438
Iteration: 1528, named_losses: [('ActivationMax Loss', -1.652096),
 ('L-6.0 Norm Loss', 0.021982033),
 ('TV(2.0) Loss', 0.18642054)], overall loss: -1.44369339943
Iteration: 1529, named_losses: [('ActivationMax Loss', -1.6082377),
 ('L-6.0 Norm Loss', 0.021981888),
 ('TV(2.0) Loss', 0.18654282)], overall loss: -1.3997130394
Iteration: 1530, named_losses: [('ActivationMax Loss', -1.6564679),
 ('L-6.0 Norm Loss', 0.021981446),
 ('TV(2.0) Loss', 0.18734442)], overall loss: -1.44714200497
Iteration: 1531, named_losses: [('ActivationMax Loss', -1.6578828),
 ('L-6.0 Norm Loss', 0.021980738),
 ('TV(2.0) Loss', 0.18616632)], overall loss: -1.44973576069
Iteration: 1532, named_losses: [('ActivationMax Loss', -1.6589375),
 ('L-6.0 Norm Loss', 0.021980347),
 ('TV(2.0) Loss', 0.18652375)], overall loss: -1.45043325424
Iteration: 1533, named_losses: [('ActivationMax Loss', -1.6531096),
 ('L-6.0 Norm Loss', 0.021980135),
 ('TV(2.0) Loss', 0.18509977)], overall loss: -1.44602966309
Iteration: 1534, named_losses: [('ActivationMax Loss', -1.6562381),
 ('L-6.0 Norm Loss', 0.021979485),
 ('TV(2.0) Loss', 0.18590686)], overall loss: -1.44835174084
Iteration: 1535, named_losses: [('ActivationMax Loss', -1.6512562),
 ('L-6.0 Norm Loss', 0.021979388),
 ('TV(2.0) Loss', 0.185202)], overall loss: -1.44407486916
Iteration: 1536, named_losses: [('ActivationMax Loss', -1.6620344),
 ('L-6.0 Norm Loss', 0.021979406),
 ('TV(2.0) Loss', 0.18663526)], overall loss: -1.45341968536
Iteration: 1537, named_losses: [('ActivationMax Loss', -1.6064487),
 ('L-6.0 Norm Loss', 0.021977749),
 ('TV(2.0) Loss', 0.18606247)], overall loss: -1.39840841293
Iteration: 1538, named_losses: [('ActivationMax Loss', -1.6670612),
 ('L-6.0 Norm Loss', 0.021979),
 ('TV(2.0) Loss', 0.18720903)], overall loss: -1.45787322521
Iteration: 1539, named_losses: [('ActivationMax Loss', -1.6262455),
 ('L-6.0 Norm Loss', 0.021978293),
 ('TV(2.0) Loss', 0.18711391)], overall loss: -1.41715335846
Iteration: 1540, named_losses: [('ActivationMax Loss', -1.6403587),
 ('L-6.0 Norm Loss', 0.021977687),
 ('TV(2.0) Loss', 0.18690035)], overall loss: -1.43148064613
Iteration: 1541, named_losses: [('ActivationMax Loss', -1.6091218),
 ('L-6.0 Norm Loss', 0.021978132),
 ('TV(2.0) Loss', 0.18744095)], overall loss: -1.39970266819
Iteration: 1542, named_losses: [('ActivationMax Loss', -1.6182401),
 ('L-6.0 Norm Loss', 0.021977721),
 ('TV(2.0) Loss', 0.18823564)], overall loss: -1.40802681446
Iteration: 1543, named_losses: [('ActivationMax Loss', -1.5671405),
 ('L-6.0 Norm Loss', 0.021977453),
 ('TV(2.0) Loss', 0.18814756)], overall loss: -1.35701549053
Iteration: 1544, named_losses: [('ActivationMax Loss', -1.6341132),
 ('L-6.0 Norm Loss', 0.021977348),
 ('TV(2.0) Loss', 0.189996)], overall loss: -1.42213988304
Iteration: 1545, named_losses: [('ActivationMax Loss', -1.626844),
 ('L-6.0 Norm Loss', 0.021976363),
 ('TV(2.0) Loss', 0.18860558)], overall loss: -1.41626214981
Iteration: 1546, named_losses: [('ActivationMax Loss', -1.6343532),
 ('L-6.0 Norm Loss', 0.021976514),
 ('TV(2.0) Loss', 0.1880133)], overall loss: -1.42436337471
Iteration: 1547, named_losses: [('ActivationMax Loss', -1.6128023),
 ('L-6.0 Norm Loss', 0.021975946),
 ('TV(2.0) Loss', 0.18889198)], overall loss: -1.40193426609
Iteration: 1548, named_losses: [('ActivationMax Loss', -1.567198),
 ('L-6.0 Norm Loss', 0.021975301),
 ('TV(2.0) Loss', 0.19034809)], overall loss: -1.3548746109
Iteration: 1549, named_losses: [('ActivationMax Loss', -1.6015427),
 ('L-6.0 Norm Loss', 0.021975029),
 ('TV(2.0) Loss', 0.19204052)], overall loss: -1.38752710819
Iteration: 1550, named_losses: [('ActivationMax Loss', -1.6305134),
 ('L-6.0 Norm Loss', 0.021974267),
 ('TV(2.0) Loss', 0.19061844)], overall loss: -1.41792070866
Iteration: 1551, named_losses: [('ActivationMax Loss', -1.6291246),
 ('L-6.0 Norm Loss', 0.021975297),
 ('TV(2.0) Loss', 0.19107616)], overall loss: -1.41607320309
Iteration: 1552, named_losses: [('ActivationMax Loss', -1.6484423),
 ('L-6.0 Norm Loss', 0.021974824),
 ('TV(2.0) Loss', 0.1879677)], overall loss: -1.43849980831
Iteration: 1553, named_losses: [('ActivationMax Loss', -1.6174778),
 ('L-6.0 Norm Loss', 0.02197342),
 ('TV(2.0) Loss', 0.18857498)], overall loss: -1.40692937374
Iteration: 1554, named_losses: [('ActivationMax Loss', -1.6378233),
 ('L-6.0 Norm Loss', 0.021974374),
 ('TV(2.0) Loss', 0.18895502)], overall loss: -1.42689394951
Iteration: 1555, named_losses: [('ActivationMax Loss', -1.6414428),
 ('L-6.0 Norm Loss', 0.021972431),
 ('TV(2.0) Loss', 0.18880399)], overall loss: -1.43066632748
Iteration: 1556, named_losses: [('ActivationMax Loss', -1.6127425),
 ('L-6.0 Norm Loss', 0.021973345),
 ('TV(2.0) Loss', 0.18931313)], overall loss: -1.40145599842
Iteration: 1557, named_losses: [('ActivationMax Loss', -1.570056),
 ('L-6.0 Norm Loss', 0.021974433),
 ('TV(2.0) Loss', 0.189211)], overall loss: -1.35887050629
Iteration: 1558, named_losses: [('ActivationMax Loss', -1.6342385),
 ('L-6.0 Norm Loss', 0.021972891),
 ('TV(2.0) Loss', 0.18922952)], overall loss: -1.42303609848
Iteration: 1559, named_losses: [('ActivationMax Loss', -1.640239),
 ('L-6.0 Norm Loss', 0.021972619),
 ('TV(2.0) Loss', 0.18970853)], overall loss: -1.42855787277
Iteration: 1560, named_losses: [('ActivationMax Loss', -1.6352172),
 ('L-6.0 Norm Loss', 0.021972034),
 ('TV(2.0) Loss', 0.18865676)], overall loss: -1.42458832264
Iteration: 1561, named_losses: [('ActivationMax Loss', -1.6339519),
 ('L-6.0 Norm Loss', 0.021971337),
 ('TV(2.0) Loss', 0.1891716)], overall loss: -1.42280900478
Iteration: 1562, named_losses: [('ActivationMax Loss', -1.6206203),
 ('L-6.0 Norm Loss', 0.021972362),
 ('TV(2.0) Loss', 0.18810444)], overall loss: -1.41054344177
Iteration: 1563, named_losses: [('ActivationMax Loss', -1.6315519),
 ('L-6.0 Norm Loss', 0.021971388),
 ('TV(2.0) Loss', 0.18961968)], overall loss: -1.41996085644
Iteration: 1564, named_losses: [('ActivationMax Loss', -1.6230092),
 ('L-6.0 Norm Loss', 0.021970605),
 ('TV(2.0) Loss', 0.18915367)], overall loss: -1.41188490391
Iteration: 1565, named_losses: [('ActivationMax Loss', -1.6281663),
 ('L-6.0 Norm Loss', 0.021969939),
 ('TV(2.0) Loss', 0.18725105)], overall loss: -1.4189453125
Iteration: 1566, named_losses: [('ActivationMax Loss', -1.5922346),
 ('L-6.0 Norm Loss', 0.02197087),
 ('TV(2.0) Loss', 0.18885772)], overall loss: -1.3814060688
Iteration: 1567, named_losses: [('ActivationMax Loss', -1.644884),
 ('L-6.0 Norm Loss', 0.021969294),
 ('TV(2.0) Loss', 0.18731801)], overall loss: -1.43559670448
Iteration: 1568, named_losses: [('ActivationMax Loss', -1.6403527),
 ('L-6.0 Norm Loss', 0.021969959),
 ('TV(2.0) Loss', 0.18794563)], overall loss: -1.43043720722
Iteration: 1569, named_losses: [('ActivationMax Loss', -1.6572884),
 ('L-6.0 Norm Loss', 0.021969009),
 ('TV(2.0) Loss', 0.18643183)], overall loss: -1.44888758659
Iteration: 1570, named_losses: [('ActivationMax Loss', -1.5840549),
 ('L-6.0 Norm Loss', 0.021969808),
 ('TV(2.0) Loss', 0.1882934)], overall loss: -1.37379169464
Iteration: 1571, named_losses: [('ActivationMax Loss', -1.6360489),
 ('L-6.0 Norm Loss', 0.021970805),
 ('TV(2.0) Loss', 0.18812379)], overall loss: -1.42595434189
Iteration: 1572, named_losses: [('ActivationMax Loss', -1.6148038),
 ('L-6.0 Norm Loss', 0.021969395),
 ('TV(2.0) Loss', 0.18778013)], overall loss: -1.40505421162
Iteration: 1573, named_losses: [('ActivationMax Loss', -1.607749),
 ('L-6.0 Norm Loss', 0.021967761),
 ('TV(2.0) Loss', 0.18608528)], overall loss: -1.39969587326
Iteration: 1574, named_losses: [('ActivationMax Loss', -1.6009055),
 ('L-6.0 Norm Loss', 0.021968991),
 ('TV(2.0) Loss', 0.18705137)], overall loss: -1.3918851614
Iteration: 1575, named_losses: [('ActivationMax Loss', -1.6318539),
 ('L-6.0 Norm Loss', 0.02196837),
 ('TV(2.0) Loss', 0.18602875)], overall loss: -1.42385685444
Iteration: 1576, named_losses: [('ActivationMax Loss', -1.6527565),
 ('L-6.0 Norm Loss', 0.021967208),
 ('TV(2.0) Loss', 0.18543744)], overall loss: -1.44535183907
Iteration: 1577, named_losses: [('ActivationMax Loss', -1.6539013),
 ('L-6.0 Norm Loss', 0.02196613),
 ('TV(2.0) Loss', 0.18494403)], overall loss: -1.44699120522
Iteration: 1578, named_losses: [('ActivationMax Loss', -1.6485047),
 ('L-6.0 Norm Loss', 0.021965597),
 ('TV(2.0) Loss', 0.18494129)], overall loss: -1.44159781933
Iteration: 1579, named_losses: [('ActivationMax Loss', -1.6276006),
 ('L-6.0 Norm Loss', 0.021965243),
 ('TV(2.0) Loss', 0.18620232)], overall loss: -1.4194329977
Iteration: 1580, named_losses: [('ActivationMax Loss', -1.62598),
 ('L-6.0 Norm Loss', 0.02196439),
 ('TV(2.0) Loss', 0.18576142)], overall loss: -1.41825413704
Iteration: 1581, named_losses: [('ActivationMax Loss', -1.6101861),
 ('L-6.0 Norm Loss', 0.021964068),
 ('TV(2.0) Loss', 0.18699741)], overall loss: -1.40122461319
Iteration: 1582, named_losses: [('ActivationMax Loss', -1.5961307),
 ('L-6.0 Norm Loss', 0.021965813),
 ('TV(2.0) Loss', 0.18736738)], overall loss: -1.38679742813
Iteration: 1583, named_losses: [('ActivationMax Loss', -1.649213),
 ('L-6.0 Norm Loss', 0.02196439),
 ('TV(2.0) Loss', 0.18843828)], overall loss: -1.4388102293
Iteration: 1584, named_losses: [('ActivationMax Loss', -1.6455878),
 ('L-6.0 Norm Loss', 0.021963693),
 ('TV(2.0) Loss', 0.18725371)], overall loss: -1.43637037277
Iteration: 1585, named_losses: [('ActivationMax Loss', -1.6220822),
 ('L-6.0 Norm Loss', 0.021963865),
 ('TV(2.0) Loss', 0.18699558)], overall loss: -1.41312277317
Iteration: 1586, named_losses: [('ActivationMax Loss', -1.670151),
 ('L-6.0 Norm Loss', 0.021963798),
 ('TV(2.0) Loss', 0.1873838)], overall loss: -1.46080338955
Iteration: 1587, named_losses: [('ActivationMax Loss', -1.6114494),
 ('L-6.0 Norm Loss', 0.021963563),
 ('TV(2.0) Loss', 0.18667541)], overall loss: -1.40281033516
Iteration: 1588, named_losses: [('ActivationMax Loss', -1.6347845),
 ('L-6.0 Norm Loss', 0.021965135),
 ('TV(2.0) Loss', 0.18723573)], overall loss: -1.425583601
Iteration: 1589, named_losses: [('ActivationMax Loss', -1.6242703),
 ('L-6.0 Norm Loss', 0.02196274),
 ('TV(2.0) Loss', 0.18836187)], overall loss: -1.4139456749
Iteration: 1590, named_losses: [('ActivationMax Loss', -1.6510607),
 ('L-6.0 Norm Loss', 0.021962292),
 ('TV(2.0) Loss', 0.18669264)], overall loss: -1.44240581989
Iteration: 1591, named_losses: [('ActivationMax Loss', -1.5963689),
 ('L-6.0 Norm Loss', 0.021962848),
 ('TV(2.0) Loss', 0.18790415)], overall loss: -1.3865019083
Iteration: 1592, named_losses: [('ActivationMax Loss', -1.6206297),
 ('L-6.0 Norm Loss', 0.021961465),
 ('TV(2.0) Loss', 0.18859878)], overall loss: -1.41006946564
Iteration: 1593, named_losses: [('ActivationMax Loss', -1.6559277),
 ('L-6.0 Norm Loss', 0.021962613),
 ('TV(2.0) Loss', 0.18839103)], overall loss: -1.44557404518
Iteration: 1594, named_losses: [('ActivationMax Loss', -1.6272049),
 ('L-6.0 Norm Loss', 0.021960588),
 ('TV(2.0) Loss', 0.1890875)], overall loss: -1.4161567688
Iteration: 1595, named_losses: [('ActivationMax Loss', -1.5837731),
 ('L-6.0 Norm Loss', 0.021959551),
 ('TV(2.0) Loss', 0.18766955)], overall loss: -1.3741440773
Iteration: 1596, named_losses: [('ActivationMax Loss', -1.6203333),
 ('L-6.0 Norm Loss', 0.021960186),
 ('TV(2.0) Loss', 0.18835026)], overall loss: -1.41002297401
Iteration: 1597, named_losses: [('ActivationMax Loss', -1.6380093),
 ('L-6.0 Norm Loss', 0.021958239),
 ('TV(2.0) Loss', 0.18819438)], overall loss: -1.42785668373
Iteration: 1598, named_losses: [('ActivationMax Loss', -1.6350691),
 ('L-6.0 Norm Loss', 0.021958627),
 ('TV(2.0) Loss', 0.18720378)], overall loss: -1.42590677738
Iteration: 1599, named_losses: [('ActivationMax Loss', -1.6683871),
 ('L-6.0 Norm Loss', 0.021957729),
 ('TV(2.0) Loss', 0.18750988)], overall loss: -1.45891940594
Iteration: 1600, named_losses: [('ActivationMax Loss', -1.6564295),
 ('L-6.0 Norm Loss', 0.021957086),
 ('TV(2.0) Loss', 0.18634458)], overall loss: -1.44812786579
Using TensorFlow backend.
2017-10-26 12:50:26.694069: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-10-26 12:50:26.694104: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-10-26 12:50:26.694114: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-10-26 12:50:26.694122: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-10-26 12:50:26.694129: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-10-26 12:50:26.795888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-10-26 12:50:26.796166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: GeForce GTX 1080
major: 6 minor: 1 memoryClockRate (GHz) 1.7335
pciBusID 0000:01:00.0
Total memory: 7.92GiB
Free memory: 7.54GiB
2017-10-26 12:50:26.796184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 
2017-10-26 12:50:26.796194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y 
2017-10-26 12:50:26.796204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)
